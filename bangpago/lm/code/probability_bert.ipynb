{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/bert_electra/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import ElectraModel, ElectraTokenizer\n",
    "from transformers import ElectraForSequenceClassification\n",
    "from transformers import AutoTokenizer, AutoModelForSemanticSegmentation, TrainingArguments, Trainer\n",
    "\n",
    "import torch\n",
    "\n",
    "import pandas as pd\n",
    "from konlpy.tag import Mecab\n",
    "import re\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from kiwipiepy import Kiwi\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, classification_report\n",
    "\n",
    "kiwi = Kiwi()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1차 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_59884/960858573.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  probability_data['content_id'] = probability_data['content_id'].apply(lambda x: x.split(',')[0] if len(str(x)) > 6 else x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probability\n",
      " 0    4818\n",
      "-1     145\n",
      " 1      60\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "train_data probability\n",
      " 0    3857\n",
      "-1     110\n",
      " 1      51\n",
      "Name: count, dtype: int64\n",
      "\n",
      " test_data probability\n",
      " 0    984\n",
      "-1     18\n",
      " 1      3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "중복 제거 전 학습 데이터셋: 4018\n",
      "중복 제거 전 테스트 데이터셋: 1005\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "중복 제거 후 학습 데이터셋: 4003\n",
      "중복 제거 후 테스트 데이터셋: 1001\n"
     ]
    }
   ],
   "source": [
    "# labeling 된 데이터 불러오기\n",
    "survey = pd.read_csv(\"./data/survey.csv\", index_col=0)\n",
    "survey.fillna(0, inplace=True)\n",
    "survey = survey.reset_index()\n",
    "\n",
    "# 데이터 중에서 작업을 하고자 하는 라벨만 가져오기\n",
    "probability_data = survey[['content_id', 'probability']]\n",
    "\n",
    "# content_id 중에서 댓글이 같이 추가된 데이터 정리\n",
    "probability_data['content_id'] = probability_data['content_id'].apply(lambda x: x.split(',')[0] if len(str(x)) > 6 else x)\n",
    "\n",
    "# content_id 가 0인 데이터 제외 -> content_id 모두 int type 으로 변경 (추후 Merge 를 위함)\n",
    "probability_data = probability_data[probability_data['content_id'] != 0].reset_index().drop(columns=['index'])\n",
    "probability_data['content_id'] = probability_data['content_id'].astype(int)\n",
    "\n",
    "# 전체 review data 불러오기\n",
    "review_all = pd.read_csv(\"./data/reviews.csv\", index_col=0)\n",
    "\n",
    "# 전체 review data 중에서 survey data에 있는 댓글만 가져오기\n",
    "survey_content = review_all.loc[review_all['id'].isin(probability_data['content_id'])][['id', 'content']]\n",
    "# merge 를 위해서 id 컬럼명 통일하기\n",
    "survey_content.columns=['content_id', 'content']\n",
    "\n",
    "# 통일된 content_id 를 기반으로 데이터 merge\n",
    "probability_data = pd.merge(probability_data, survey_content)\n",
    "\n",
    "# 추후 원활한 계산을 위해서 숫자 부분은 모두 int 로 바꿔줌\n",
    "probability_data['probability'] = probability_data['probability'].astype(int)\n",
    "\n",
    "# 최소한의 전처리\n",
    "def cleaned_content(text):\n",
    "    d = re.sub('\\n', '. ', text) # 줄바꿈 > .\n",
    "    d = re.sub('[^가-힣0-9a-zA-Z ]{2,}', \".\", d) # 특수문자 두개 이상인거 .으로 변경\n",
    "    return d\n",
    "\n",
    "probability_data['content'] = probability_data['content'].apply(cleaned_content)\n",
    "\n",
    "final_df = probability_data[['content', 'probability']]\n",
    "\n",
    "# 라벨별 개수 확인\n",
    "print(final_df['probability'].value_counts())\n",
    "print('\\n')\n",
    "train_data = final_df.sample(frac=0.8, random_state=42).reset_index().drop(columns='index')\n",
    "print('train_data', train_data['probability'].value_counts())\n",
    "test_data = final_df.drop(train_data.index).reset_index().drop(columns='index')\n",
    "print('\\n', 'test_data', test_data['probability'].value_counts())\n",
    "print('\\n')\n",
    "# 중복 데이터 제거(데이터 분리 후 중복이 생길 수 있어서 데이터 분리 후 중복 데이터 처리 진행)\n",
    "\n",
    "# 데이터셋 개수 확인\n",
    "print('중복 제거 전 학습 데이터셋: {}'.format(len(train_data)))\n",
    "print('중복 제거 전 테스트 데이터셋: {}'.format(len(test_data)))\n",
    "print('\\n')\n",
    "# 중복 데이터 제거\n",
    "train_data.drop_duplicates(subset=['content'], inplace=True)\n",
    "test_data.drop_duplicates(subset=['content'], inplace=True)\n",
    "print('\\n')\n",
    "# 데이터셋 개수 확인\n",
    "print('중복 제거 후 학습 데이터셋: {}'.format(len(train_data)))\n",
    "print('중복 제거 후 테스트 데이터셋: {}'.format(len(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-small-v3-discriminator and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(35080, 128)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 토큰에 추가할 단어 -> '방탈출'이라는 도메인 지시기에 근거한 용어, 분리되어서는 안 되기 때문에 별도로 추가 작업 진행\n",
    "addword = ['공테', '약공테', '감테', '창공', '갑툭튀', '삐딱', '삑', '꽝', '삑딱쾅', '삑딱쾅', '삑딱', '쫄', '극쫄',\n",
    "            '극극쫄', '쫄팟', '쫄탱', '쫄보', '극', '약탱', '탱쫄', '극극극', '뉴비', '하드캐리', '극혐', '피지컬',\n",
    "            '어거지', '뚝배기', '뚝문', '셀뚝', '억까', '트롤링', '트롤짓', '흙길', '풀길', '꽃길', '풀꽃', '꽃다발',\n",
    "            '꽃밭', '웰메이드', '인생테마', '머글', '방린이', '방유아', '방세포', '방태아', '방탈러', '과몰입러', '옵저버',\n",
    "            '리트', '연방', '혼방', '혼불', '워킹', '워크인', '장치방', '문제방', '직렬', '병렬', '육각형', '볼드', '볼드충', '에바',\n",
    "            '가이드', '조도', '조명', '밝기', '어두움', '인테리어', '비주얼', '소품', '디자인',\n",
    "            '스토리','기승전결','흐름도','결말','서사','이야기','유니버스','전개','시나리오', '개연성', '명료',\n",
    "            '창의성','창의','신선','독특','참신','발상', '연출','짜임','사실감','구현','현실감','현장감', '활동성','활동력','활동량','움직임','반경',\n",
    "            '규모','스케일','볼륨','사이즈','크기','넓이','공간감','분량', '공포','공테','무서움','담력','스릴러',\n",
    "            '문제', '장치', '기계', '센서', '기구', '불친절',\n",
    "            '메르헨', '커튼콜', '카르텔', '소우주', '풀문', '도고', '플래시', '나우히어', '나비효과', '몽중', '가이드라인',\n",
    "            '연출력', '짜임새', '공포도', '공포감', '공포심', '약공테', '문제퀄']\n",
    "\n",
    "# 사전학습된 bert 모델 사용\n",
    "# num_labels 클래스에 대해서 훈련을 하기 위해서 num_labels=3 할당함, problem_type=\"multi_label_classification\" 를 통해서 모델이 다중 레이블 분류에 해당함을 명시\n",
    "model = ElectraForSequenceClassification.from_pretrained(\"monologg/koelectra-small-v3-discriminator\", num_labels=3, problem_type=\"multi_label_classification\")\n",
    "tokenizer = ElectraTokenizer.from_pretrained(\"monologg/koelectra-base-v3-discriminator\")\n",
    "\n",
    "# token에 새로운 단어 추가 \n",
    "tokenizer.add_tokens(addword)\n",
    "# token에 단어 추가후 기존 모델의 임베딩 레이어에 추가한 단어에 대한 임베딩 벡터가 없을 수 있기 때문\n",
    "# 아래 코드를 통해서 토큰의 개수가 변했음을 모델에 알리고 모델의 임베딩 레이어를 조정하여 새로운 토큰을 수용할 수 있게 함\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train content 토큰화\n",
    "tokenized_train_sentences = tokenizer(\n",
    "    list(train_data['content']),\n",
    "    return_tensors=\"pt\",\n",
    "    max_length=128,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    add_special_tokens=True\n",
    ")\n",
    "\n",
    "# test content 토큰화\n",
    "tokenized_test_sentences = tokenizer(\n",
    "    list(test_data['content']),\n",
    "    return_tensors=\"pt\",\n",
    "    max_length=128,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    add_special_tokens=True\n",
    ")\n",
    "\n",
    "# 분류 모델에 넣기 위해서 1차원으로 구성된 세 개의 클래스를 2차원으로 재구성 후 label 로 투입\n",
    "# -1(부정)=0, 0(중립)=1, 1(긍정)=2\n",
    "\n",
    "train_label = []\n",
    "for label in train_data[\"probability\"].values:\n",
    "    if label == -1:\n",
    "        train_label.append([1., 0., 0.])\n",
    "    elif label == 0:\n",
    "        train_label.append([0., 1., 0.])\n",
    "    elif label == 1:\n",
    "        train_label.append([0., 0., 1.])\n",
    "\n",
    "test_label = []\n",
    "for label in test_data['probability'].values:\n",
    "    if label == 0:\n",
    "        test_label.append([0., 1., 0.])\n",
    "    elif label == -1:\n",
    "        test_label.append([1., 0., 0.])\n",
    "    elif label == 1:\n",
    "        test_label.append([0., 0., 1.])\n",
    "\n",
    "# model 에 넣기 위한 dataset 생성 class\n",
    "class CurseDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "        \n",
    "# bert 모델에 데이터가 들어갈 수 있게 만들어 둔 class를 활용하여 train, test dataset 생성\n",
    "train_dataset = CurseDataset(tokenized_train_sentences, train_label)\n",
    "test_dataset = CurseDataset(tokenized_test_sentences, test_label)\n",
    "\n",
    "# hugging face 의 trasformers 라이브러리를 사용하여 모델 훈련시킬 때 사용되는 객체 설정 부분\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = './probability_model/check_point/try_1',    # 모델과 훈련 중 생성되는 파일이 저장될 디렉토리 경로\n",
    "    num_train_epochs = 10,              # 훈련 epoch 수\n",
    "    per_device_train_batch_size = 16,    # 장치에 할당된 훈련 배치 크기\n",
    "    per_device_eval_batch_size = 64,    # 장치에 할당된 평가 배치 크기, 모델을 평가할 때 사용되는 배치 크기\n",
    "    logging_dir = './logs',             # 훈련 중 로그 파일이 저장될 디렉토리\n",
    "    logging_steps = 500,                # 로그 출력 빈도, 500 step에 한 번씩 출력 예정\n",
    "    save_total_limit = 2,               # 체크포인트 파일 저장 제한 수\n",
    ")\n",
    "\n",
    "# hugging face 의 trasformers 라이브러리를 사용하여 모델 훈련하고 관리하는 객체 설정 부분\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2510 [00:00<?, ?it/s]/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_59884/1626568691.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 20%|█▉        | 500/2510 [01:28<05:50,  5.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1988, 'learning_rate': 4.00398406374502e-05, 'epoch': 1.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_59884/1626568691.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 40%|███▉      | 1000/2510 [02:58<04:16,  5.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1136, 'learning_rate': 3.00796812749004e-05, 'epoch': 3.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_59884/1626568691.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 60%|█████▉    | 1500/2510 [04:26<02:53,  5.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1059, 'learning_rate': 2.01195219123506e-05, 'epoch': 5.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_59884/1626568691.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 80%|███████▉  | 2000/2510 [05:54<01:27,  5.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0872, 'learning_rate': 1.0159362549800798e-05, 'epoch': 7.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_59884/1626568691.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "100%|█████████▉| 2500/2510 [07:21<00:01,  5.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0632, 'learning_rate': 1.99203187250996e-07, 'epoch': 9.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_59884/1626568691.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "100%|██████████| 2510/2510 [07:23<00:00,  5.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 443.1997, 'train_samples_per_second': 90.32, 'train_steps_per_second': 5.663, 'train_loss': 0.11354910736064987, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2510, training_loss=0.11354910736064987, metrics={'train_runtime': 443.1997, 'train_samples_per_second': 90.32, 'train_steps_per_second': 5.663, 'train_loss': 0.11354910736064987, 'epoch': 10.0})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train 진행\n",
    "trainer.train() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./probability_model/try_1/probability_tokenizer1/tokenizer_config.json',\n",
       " './probability_model/try_1/probability_tokenizer1/special_tokens_map.json',\n",
       " './probability_model/try_1/probability_tokenizer1/vocab.txt',\n",
       " './probability_model/try_1/probability_tokenizer1/added_tokens.json')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.save_model(\"./probability_model/try_1/probability_model1\")\n",
    "tokenizer.save_pretrained(\"./probability_model/try_1/probability_tokenizer1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# 저장된 모델과 토크나이저를 불러오기\n",
    "\n",
    "model_path = \"./probability_model/try_1/probability_model1\"\n",
    "tokenizer_path = \"./probability_model/try_1/probability_tokenizer1\"\n",
    "\n",
    "model = ElectraForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer = ElectraTokenizer.from_pretrained(tokenizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1001/1001 [00:11<00:00, 87.63it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>probability</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#1415_20221128_3인. 흐음.잘 열어보지 않으면</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>난.바보야.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>들어가자마자 커피향이 씨게 낫다 좋앗다 하지만 인테리어는 그냥그랫다. 풀정도 되는듯.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3인. 스토리가 잘 감이 안 잡힌다!</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.5/3인. 활동성 있음.추락조심</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>나에겐 너무 어려웠던. 방탈짬바 있는 분들에게 추천</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>2021. 12. 26. (3인) 각자 1인분씩 하고 뿌듯했던 테마.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>첫방 디버프로 초반에 절어버림. 볼것도 못보고 힌트썼는데 잘꾸며놓았다 . 살짝 장치...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>#5 - 2인 - 볼륨에 압도됨 - 히터도 방마다 빵빵함 - 다른 테마도 궁금해짐</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>265, 2인, 장치. 그걸 왜 몰랐냐. 장치에 속지 말자</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1001 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content  probability  pred\n",
       "0                      #1415_20221128_3인. 흐음.잘 열어보지 않으면            0     0\n",
       "1                                                난.바보야.            0     0\n",
       "2       들어가자마자 커피향이 씨게 낫다 좋앗다 하지만 인테리어는 그냥그랫다. 풀정도 되는듯.            0     0\n",
       "3                                  3인. 스토리가 잘 감이 안 잡힌다!            0     0\n",
       "4                                   1.5/3인. 활동성 있음.추락조심            0     0\n",
       "...                                                 ...          ...   ...\n",
       "999                        나에겐 너무 어려웠던. 방탈짬바 있는 분들에게 추천            0     0\n",
       "1000             2021. 12. 26. (3인) 각자 1인분씩 하고 뿌듯했던 테마.            0     0\n",
       "1001  첫방 디버프로 초반에 절어버림. 볼것도 못보고 힌트썼는데 잘꾸며놓았다 . 살짝 장치...            0     0\n",
       "1002      #5 - 2인 - 볼륨에 압도됨 - 히터도 방마다 빵빵함 - 다른 테마도 궁금해짐            0     0\n",
       "1003                   265, 2인, 장치. 그걸 왜 몰랐냐. 장치에 속지 말자            0     0\n",
       "\n",
       "[1001 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문장을 입력했을 때, 예측 값을 도출해주는 함수\n",
    "\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "# 함수 정의\n",
    "def classify_text(text):\n",
    "    # 문장을 토큰화하고 모델에 입력으로 전달\n",
    "    text = cleaned_content(text)\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "    # 소프트맥스 함수를 사용하여 확률값 계산\n",
    "    probabilities = softmax(outputs.logits, dim=1)\n",
    "\n",
    "    # 가장 높은 확률값에 해당하는 클래스 선택\n",
    "    predicted_class = torch.argmax(probabilities).item()\n",
    "\n",
    "    return predicted_class, probabilities\n",
    "\n",
    "def change_num(num):\n",
    "    if num == 0:\n",
    "        return (-1)\n",
    "    elif num == 1:\n",
    "        return 0\n",
    "    elif num == 2:\n",
    "        return 1\n",
    "\n",
    "pred_list = []\n",
    "for sent in tqdm(test_data['content']):\n",
    "    pred, _ = classify_text(sent)\n",
    "    pred_list.append(pred)\n",
    "\n",
    "test_data['pred'] = pred_list\n",
    "test_data['pred'] = test_data['pred'].apply(change_num)\n",
    "test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probability\n",
      " 0    4818\n",
      "-1     145\n",
      " 1      60\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(final_df['probability'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probability\n",
      " 0    3842\n",
      "-1     110\n",
      " 1      51\n",
      "Name: count, dtype: int64\n",
      "probability\n",
      " 0    980\n",
      "-1     18\n",
      " 1      3\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_data['probability'].value_counts())\n",
    "print(test_data['probability'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.69      0.61      0.65        18\n",
      "           0       0.99      1.00      1.00       980\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.99      1001\n",
      "   macro avg       0.56      0.54      0.55      1001\n",
      "weighted avg       0.98      0.99      0.99      1001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/bert_electra/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/bert_electra/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/bert_electra/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_data['probability'], test_data['pred']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.69      0.61      0.65        18\n",
      "           0       0.99      1.00      1.00       980\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.99      1001\n",
      "   macro avg       0.56      0.54      0.55      1001\n",
      "weighted avg       0.98      0.99      0.99      1001\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.79      0.61      0.69        18\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.52        21\n",
      "   macro avg       0.26      0.20      0.23        21\n",
      "weighted avg       0.67      0.52      0.59        21\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/bert_electra/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/bert_electra/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/bert_electra/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/bert_electra/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/bert_electra/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/bert_electra/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/bert_electra/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/bert_electra/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/bert_electra/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_data['probability'], test_data['pred']))\n",
    "test_data2 = test_data[test_data['probability'] != 0]\n",
    "print(classification_report(test_data2['probability'], test_data2['pred']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장: 예측 하나도 안 됨, 평가: 1\n",
      "---------- \n",
      "\n",
      "문장: 예측 다 됨, 평가: 1\n",
      "---------- \n",
      "\n",
      "문장: 예측성 대박, 평가: 1\n",
      "---------- \n",
      "\n",
      "문장: 예측성 최악, 평가: 1\n",
      "---------- \n",
      "\n",
      "문장: 예측성 최악, 평가: 1\n",
      "---------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test = [\n",
    "    '예측 하나도 안 됨',\n",
    "    '예측 다 됨',\n",
    "    '예측성 대박',\n",
    "    '예측성 최악',\n",
    "    '예측성 최악',\n",
    "]\n",
    "\n",
    "for sent in test:\n",
    "    pred, _ = classify_text(sent)\n",
    "    print(f'문장: {sent}, 평가: {pred}')\n",
    "    print(\"-\"*10, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1차 결과\n",
    "- 그냥 학습 데이터가 너무 없어서\n",
    "- 전반적으로 결과 박살남"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2차 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_12682/237546230.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  probability_data['content_id'] = probability_data['content_id'].apply(lambda x: x.split(',')[0] if len(str(x)) > 6 else x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probability\n",
      " 0    4686\n",
      "-1     179\n",
      " 1      97\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "train_data probability\n",
      " 0    3756\n",
      "-1     144\n",
      " 1      70\n",
      "Name: count, dtype: int64\n",
      "\n",
      " test_data probability\n",
      " 0    901\n",
      "-1     51\n",
      " 1     40\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# labeling 된 데이터 불러오기\n",
    "survey = pd.read_csv(\"./_data/survey.csv\", index_col=0)\n",
    "survey.fillna(0, inplace=True)\n",
    "survey = survey.reset_index()\n",
    "\n",
    "# 데이터 중에서 작업을 하고자 하는 라벨만 가져오기\n",
    "probability_data = survey[['content_id', 'probability']]\n",
    "\n",
    "# content_id 중에서 댓글이 같이 추가된 데이터 정리\n",
    "probability_data['content_id'] = probability_data['content_id'].apply(lambda x: x.split(',')[0] if len(str(x)) > 6 else x)\n",
    "\n",
    "# content_id 가 0인 데이터 제외 -> content_id 모두 int type 으로 변경 (추후 Merge 를 위함)\n",
    "probability_data = probability_data[probability_data['content_id'] != 0].reset_index().drop(columns=['index'])\n",
    "probability_data['content_id'] = probability_data['content_id'].astype(int)\n",
    "\n",
    "# 전체 review data 불러오기\n",
    "review_all = pd.read_csv(\"./_data/reviews.csv\", index_col=0)\n",
    "\n",
    "# 전체 review data 중에서 survey data에 있는 댓글만 가져오기\n",
    "survey_content = review_all.loc[review_all['id'].isin(probability_data['content_id'])][['id', 'content']]\n",
    "# merge 를 위해서 id 컬럼명 통일하기\n",
    "survey_content.columns=['content_id', 'content']\n",
    "\n",
    "# 통일된 content_id 를 기반으로 데이터 merge\n",
    "probability_data = pd.merge(probability_data, survey_content)\n",
    "\n",
    "# 추후 원활한 계산을 위해서 숫자 부분은 모두 int 로 바꿔줌\n",
    "probability_data['probability'] = probability_data['probability'].astype(int)\n",
    "final_df = probability_data[['content', 'probability']]\n",
    "\n",
    "# 데이터 추가\n",
    "new_data = [\n",
    "    ('개연성 적당함', 1), ('개연성 아주 딱이었음', 1), ('개연성이 알맞아요.', 1),\n",
    "    ('개연성 완벽했음', 1), ('온도 습도 밝기 서비스 개연성 다 완벽했다', 1), ('개연성 굳', 1),\n",
    "    ('문제와 스토리와 개연성이 멋짐', 1), ('스토리와 개연성이 끝내줌', 1), ('생각보다 스토리와 개연성이 있었다.', 1), ('스토리도 잘 만들었고 개연성도 좋았다', 1),\n",
    "    ('개연성 있는 스토리 넘 재밌당', 1), ('스토리와 개연성이 좋은 짱잼 방탈출', 1), ('장치나 자물쇠가 개연성있게 잘 배치되었다.', 1), ('스케일, 개연성, 문제 모든 게 완벽', 1),\n",
    "    ('개연성이 마땅해서 좋았습니다', 1), ('문제 해결 과정이 개연성 있어서 좋았습니다', 1), ('방 안의 모든 상황이 개연성 있게 이어져서 좋았습니다', 1),\n",
    "    ('스케일과 개연성이 동시에 완벽하게 구현돼 있어서 감탄했어요', 1), ('전체적으로 방의 구성과 이야기가 완벽한 개연성을 지니고 있었어요', 1),\n",
    "    ('문제와 스토리가 자연스럽게 이어져서 개연성이 뛰어났습니다', 1), ('스토리의 흐름과 방의 구성이 매끄럽게 이어져서 좋았어요', 1), ('전개가 예상 가능한데도 불구하고 개연성 있는 스토리에 매료됐어요', 1), \n",
    "    ('스토리의 전개가 개연성 있게 진행돼서 매우 만족스러웠어요', 1), ('전반적으로 개연성이 높은 방탈출이었습니다', 1),\n",
    "    ('스케일과 개연성이 동시에 갖춰진 방탈출이었습니다', 1), ('개연성 있는 이야기와 방이 만나 매우 흥미로운 경험이었어요', 1), \n",
    "    ('개연성이 뛰어난 스토리에 매료돼서 즐거운 방탈출이었어요', 1), ('방의 각 요소들이 개연성 있게 어울려서 흥미진진한 경험을 했습니다', 1),\n",
    "    ('이야기와 방이 개연성 있게 이어져서 매우 만족스러웠어요', 1), ('스케일과 개연성이 동시에 완벽하게 표현돼 있어서 감탄했어요', 1),\n",
    "    ('전개가 예상 가능한데도 불구하고 개연성 있는 스토리에 몰입했습니다', 1), ('스토리의 전개가 개연성 있게 진행돼서 매우 만족스러웠어요', 1),\n",
    "    ('방탈출 중에도 이야기의 개연성이 높아서 흥미로운 경험이었어요', 1), ('스케일과 개연성이 동시에 갖춰진 방탈출이 기억에 남는 경험이었습니다', 1),\n",
    "    ('이야기와 방이 끊임없이 개연성 있게 이어져서 기분 좋게 즐겼습니다', 1), ('방의 각 부분이 개연성 있게 설계돼어서 좋은 방탈출이었습니다', 1),\n",
    "\n",
    "    ('개연성이 없다.', 0),\n",
    "\n",
    "    ('개연성 개쓰레기임', -1), ('개연성 실화냐', -1), ('말이 전혀 안 되는 시나리오라 다시는 안 가고 싶음', -1), ('돈 받고 이러는 거 아니지', -1),\n",
    "    ('개연성 개실망.', -1), ('개연성 대실망', -1), ('개연성 최악', -1), ('개연성 무슨 일?', -1), \n",
    "    ('개연성 별로임', -1), ('이야기가 안 이어짐', -1), ('개연성 너무 별로임', -1), ('개연성 개별로', -1), ('개연성 정말 쓰레기같아', -1),\n",
    "    ('개연성 너무 더러움', 1), ('개연성 이상하다 생각함', 1), ('개연성이 살짝 의문', -1), ('문제의 개연성이나 가이드가 부족하다는 느낌을 받음', -1), ('개연성 떨어짐', -1),\n",
    "    ('개연성을 찾기 어려웠다.', -1),\n",
    "    ('개연성이 완전히 무너진 상태에서 방을 탈출하는 게 너무 실망스러웠어요', -1), ('이야기가 너무 허술해서 방에서 탈출하는 과정이 하나도 이해 안 갔어요', -1),\n",
    "    ('돈을 내고 이런 퀄리티의 개연성 없는 시나리오를 본 건 정말 후회스러웠어요', -1), ('개연성이 전혀 없어서 돈주고 입장했다는 게 믿기지 않아요', -1), \n",
    "    ('방 전체의 개연성이 너무 부족해서 정말 실망스러웠어요', -1), ('개연성이 전체적으로 대실망 수준이었어요', -1), ('이야기의 흐름이 전혀 이어지지 않아서 개연성이 최악이었어요', -1),\n",
    "    ('개연성이 너무 부실해서 방에서 벗어나는 게 불가능한 느낌이었어요', -1), ('방 전체의 개연성이 무슨 일이 벌어지는지 이해할 수 없었어요', -1), \n",
    "    ('이야기가 전개되지 않아서 개연성이 매우 부족했어요', -1), ('개연성이 전혀 갖춰져 있지 않아서 정말 실망스러웠어요', -1),\n",
    "    ('방 안의 상황이 전혀 이어지지 않아서 개연성이 정말 쓰레기같았어요', -1), ('개연성이 이상해서 방에서 탈출하는 과정이 이상하게 느껴졌어요', -1),\n",
    "    ('문제의 개연성이나 가이드가 전혀 부족해서 방탈출이 힘들었어요', -1), ('개연성이 너무 떨어져서 방탈출이 즐거운 경험이 아니었어요', -1), ('개연성을 찾기 어려워서 방에서 탈출하는 데 많이 힘들었어요', -1),\n",
    "    ('이야기의 전개가 개연성이 없어서 정말 별로였어요', -1), ('방탈출 중에 개연성이 떨어져서 전반적으로 실망스러웠어요', -1)\n",
    "]\n",
    "\n",
    "new_df = pd.DataFrame(new_data, columns=['content', 'probability'])\n",
    "final_df = pd.concat([final_df, new_df])\n",
    "\n",
    "\n",
    "\n",
    "# 최소한의 전처리\n",
    "def cleaned_content(text):\n",
    "    d = re.sub('\\n', '. ', text) # 줄바꿈 > .\n",
    "    d = re.sub('[^가-힣0-9a-zA-Z ]{2,}', \".\", d) # 특수문자 두개 이상인거 .으로 변경\n",
    "    return d\n",
    "\n",
    "def kiwi_clean(text):\n",
    "    get_kiwi_pos = ['NNG', 'NP', 'NNP', 'MM', 'VV', 'VV-I', 'VV-R', 'VA', 'VA-I', 'VA-R', 'VCP', 'VCN', 'MAG', 'MAJ', 'XR']\n",
    "    kiwi_lem = []\n",
    "    for word in kiwi.tokenize(text):\n",
    "        if word.tag in get_kiwi_pos:\n",
    "            kiwi_lem.append(word.lemma)\n",
    "    return ' '.join(kiwi_lem)\n",
    "\n",
    "final_df['content'] = final_df['content'].apply(cleaned_content)\n",
    "final_df['content'] = final_df['content'].apply(kiwi_clean)\n",
    "\n",
    "\n",
    "final_df = final_df.drop_duplicates()\n",
    "final_df = final_df.reset_index().drop(columns = ['index'])\n",
    "\n",
    "# 라벨별 개수 확인\n",
    "print(final_df['probability'].value_counts())\n",
    "print('\\n')\n",
    "train_data = final_df.sample(frac=0.8, random_state=42).reset_index().drop(columns='index')\n",
    "print('train_data', train_data['probability'].value_counts())\n",
    "test_data = final_df.drop(train_data.index).reset_index().drop(columns='index')\n",
    "print('\\n', 'test_data', test_data['probability'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-small-v3-discriminator and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(35080, 128)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 토큰에 추가할 단어 -> '방탈출'이라는 도메인 지시기에 근거한 용어, 분리되어서는 안 되기 때문에 별도로 추가 작업 진행\n",
    "addword = ['공테', '약공테', '감테', '창공', '갑툭튀', '삐딱', '삑', '꽝', '삑딱쾅', '삑딱쾅', '삑딱', '쫄', '극쫄',\n",
    "            '극극쫄', '쫄팟', '쫄탱', '쫄보', '극', '약탱', '탱쫄', '극극극', '뉴비', '하드캐리', '극혐', '피지컬',\n",
    "            '어거지', '뚝배기', '뚝문', '셀뚝', '억까', '트롤링', '트롤짓', '흙길', '풀길', '꽃길', '풀꽃', '꽃다발',\n",
    "            '꽃밭', '웰메이드', '인생테마', '머글', '방린이', '방유아', '방세포', '방태아', '방탈러', '과몰입러', '옵저버',\n",
    "            '리트', '연방', '혼방', '혼불', '워킹', '워크인', '장치방', '문제방', '직렬', '병렬', '육각형', '볼드', '볼드충', '에바',\n",
    "            '가이드', '조도', '조명', '밝기', '어두움', '인테리어', '비주얼', '소품', '디자인',\n",
    "            '스토리','기승전결','흐름도','결말','서사','이야기','유니버스','전개','시나리오', '개연성', '명료',\n",
    "            '창의성','창의','신선','독특','참신','발상', '연출','짜임','사실감','구현','현실감','현장감', '활동성','활동력','활동량','움직임','반경',\n",
    "            '규모','스케일','볼륨','사이즈','크기','넓이','공간감','분량', '공포','공테','무서움','담력','스릴러',\n",
    "            '문제', '장치', '기계', '센서', '기구', '불친절',\n",
    "            '메르헨', '커튼콜', '카르텔', '소우주', '풀문', '도고', '플래시', '나우히어', '나비효과', '몽중', '가이드라인',\n",
    "            '연출력', '짜임새', '공포도', '공포감', '공포심', '약공테', '문제퀄']\n",
    "\n",
    "# 사전학습된 bert 모델 사용\n",
    "# num_labels 클래스에 대해서 훈련을 하기 위해서 num_labels=3 할당함, problem_type=\"multi_label_classification\" 를 통해서 모델이 다중 레이블 분류에 해당함을 명시\n",
    "model = ElectraForSequenceClassification.from_pretrained(\"monologg/koelectra-small-v3-discriminator\", num_labels=3, problem_type=\"multi_label_classification\")\n",
    "tokenizer = ElectraTokenizer.from_pretrained(\"monologg/koelectra-base-v3-discriminator\")\n",
    "\n",
    "# token에 새로운 단어 추가 \n",
    "tokenizer.add_tokens(addword)\n",
    "# token에 단어 추가후 기존 모델의 임베딩 레이어에 추가한 단어에 대한 임베딩 벡터가 없을 수 있기 때문\n",
    "# 아래 코드를 통해서 토큰의 개수가 변했음을 모델에 알리고 모델의 임베딩 레이어를 조정하여 새로운 토큰을 수용할 수 있게 함\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train content 토큰화\n",
    "tokenized_train_sentences = tokenizer(\n",
    "    list(train_data['content']),\n",
    "    return_tensors=\"pt\",\n",
    "    max_length=128,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    add_special_tokens=True\n",
    ")\n",
    "\n",
    "# test content 토큰화\n",
    "tokenized_test_sentences = tokenizer(\n",
    "    list(test_data['content']),\n",
    "    return_tensors=\"pt\",\n",
    "    max_length=128,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    add_special_tokens=True\n",
    ")\n",
    "\n",
    "# 분류 모델에 넣기 위해서 1차원으로 구성된 세 개의 클래스를 2차원으로 재구성 후 label 로 투입\n",
    "# -1(부정)=0, 0(중립)=1, 1(긍정)=2\n",
    "\n",
    "train_label = []\n",
    "for label in train_data[\"probability\"].values:\n",
    "    if label == -1:\n",
    "        train_label.append([1., 0., 0.])\n",
    "    elif label == 0:\n",
    "        train_label.append([0., 1., 0.])\n",
    "    elif label == 1:\n",
    "        train_label.append([0., 0., 1.])\n",
    "\n",
    "test_label = []\n",
    "for label in test_data['probability'].values:\n",
    "    if label == 0:\n",
    "        test_label.append([0., 1., 0.])\n",
    "    elif label == -1:\n",
    "        test_label.append([1., 0., 0.])\n",
    "    elif label == 1:\n",
    "        test_label.append([0., 0., 1.])\n",
    "\n",
    "# model 에 넣기 위한 dataset 생성 class\n",
    "class CurseDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "        \n",
    "# bert 모델에 데이터가 들어갈 수 있게 만들어 둔 class를 활용하여 train, test dataset 생성\n",
    "train_dataset = CurseDataset(tokenized_train_sentences, train_label)\n",
    "test_dataset = CurseDataset(tokenized_test_sentences, test_label)\n",
    "\n",
    "# hugging face 의 trasformers 라이브러리를 사용하여 모델 훈련시킬 때 사용되는 객체 설정 부분\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = './probability_model/check_point/try_2',    # 모델과 훈련 중 생성되는 파일이 저장될 디렉토리 경로\n",
    "    num_train_epochs = 30,              # 훈련 epoch 수\n",
    "    per_device_train_batch_size = 16,    # 장치에 할당된 훈련 배치 크기\n",
    "    per_device_eval_batch_size = 64,    # 장치에 할당된 평가 배치 크기, 모델을 평가할 때 사용되는 배치 크기\n",
    "    logging_dir = './logs',             # 훈련 중 로그 파일이 저장될 디렉토리\n",
    "    logging_steps = 500,                # 로그 출력 빈도, 500 step에 한 번씩 출력 예정\n",
    "    save_total_limit = 2,               # 체크포인트 파일 저장 제한 수\n",
    ")\n",
    "\n",
    "# hugging face 의 trasformers 라이브러리를 사용하여 모델 훈련하고 관리하는 객체 설정 부분\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7470 [00:00<?, ?it/s]/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_258/3605136916.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "  7%|▋         | 500/7470 [01:27<20:13,  5.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2209, 'learning_rate': 4.6653279785809906e-05, 'epoch': 2.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_258/3605136916.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 13%|█▎        | 1000/7470 [02:54<18:17,  5.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1234, 'learning_rate': 4.3306559571619816e-05, 'epoch': 4.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_258/3605136916.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 20%|██        | 1500/7470 [04:20<18:13,  5.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1233, 'learning_rate': 3.995983935742972e-05, 'epoch': 6.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_258/3605136916.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 27%|██▋       | 2000/7470 [05:48<15:56,  5.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.112, 'learning_rate': 3.661311914323963e-05, 'epoch': 8.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_258/3605136916.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 33%|███▎      | 2500/7470 [07:15<14:12,  5.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0841, 'learning_rate': 3.326639892904953e-05, 'epoch': 10.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_258/3605136916.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 40%|████      | 3000/7470 [08:41<13:08,  5.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0585, 'learning_rate': 2.991967871485944e-05, 'epoch': 12.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_258/3605136916.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 47%|████▋     | 3500/7470 [10:08<11:50,  5.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0485, 'learning_rate': 2.6572958500669343e-05, 'epoch': 14.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_258/3605136916.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 54%|█████▎    | 4000/7470 [11:34<10:18,  5.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0413, 'learning_rate': 2.322623828647925e-05, 'epoch': 16.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_258/3605136916.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 60%|██████    | 4500/7470 [13:00<08:38,  5.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0416, 'learning_rate': 1.9879518072289157e-05, 'epoch': 18.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_258/3605136916.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 67%|██████▋   | 5000/7470 [14:26<06:59,  5.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0374, 'learning_rate': 1.6532797858099064e-05, 'epoch': 20.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_258/3605136916.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 74%|███████▎  | 5500/7470 [15:52<05:38,  5.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0364, 'learning_rate': 1.318607764390897e-05, 'epoch': 22.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_258/3605136916.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 80%|████████  | 6000/7470 [17:19<04:16,  5.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0352, 'learning_rate': 9.839357429718876e-06, 'epoch': 24.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_258/3605136916.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 87%|████████▋ | 6500/7470 [18:46<02:48,  5.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0299, 'learning_rate': 6.492637215528783e-06, 'epoch': 26.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_258/3605136916.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 94%|█████████▎| 7000/7470 [20:12<01:20,  5.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0245, 'learning_rate': 3.1459170013386886e-06, 'epoch': 28.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_258/3605136916.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "100%|██████████| 7470/7470 [21:33<00:00,  5.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1293.3794, 'train_samples_per_second': 92.084, 'train_steps_per_second': 5.776, 'train_loss': 0.0695962799919976, 'epoch': 30.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=7470, training_loss=0.0695962799919976, metrics={'train_runtime': 1293.3794, 'train_samples_per_second': 92.084, 'train_steps_per_second': 5.776, 'train_loss': 0.0695962799919976, 'epoch': 30.0})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train 진행\n",
    "trainer.train() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./probability_model/try_2/probability_tokenizer2/tokenizer_config.json',\n",
       " './probability_model/try_2/probability_tokenizer2/special_tokens_map.json',\n",
       " './probability_model/try_2/probability_tokenizer2/vocab.txt',\n",
       " './probability_model/try_2/probability_tokenizer2/added_tokens.json')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.save_model(\"./probability_model/try_2/probability_model2\")\n",
    "tokenizer.save_pretrained(\"./probability_model/try_2/probability_tokenizer2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# 저장된 모델과 토크나이저를 불러오기\n",
    "\n",
    "model_path = \"./probability_model/try_2/probability_model2\"\n",
    "tokenizer_path = \"./probability_model/try_2/probability_tokenizer2\"\n",
    "\n",
    "model = ElectraForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer = ElectraTokenizer.from_pretrained(tokenizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 992/992 [00:10<00:00, 94.61it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>probability</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>탱쫄 판별 가다 가다 판별 메모리 가다 어쨌든 탱으 판별 나다 좋다</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>인 마지막 방 좋다</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>인 쏘이다 너무 귀엽다 연출 마지막 연출 인상 깊다 딱 세 가다 좋다 인테리어 너무...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>감테 공테 경계선 있다 테마 창공 많다 진짜 무섭다</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>인생 테마</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>문제 개연 가이드 전혀 부족 방 탈출 힘들다</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>개연 너무 떨어지다 방 탈출 즐겁다 경험 아니다</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>개연 찾다 어렵다 방 탈출 많이 힘들다</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>이야기 전개 개연 없다 정말 별로 이다</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>방 탈출 개연 떨어지다 전반 실망</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>992 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               content  probability  pred\n",
       "0                탱쫄 판별 가다 가다 판별 메모리 가다 어쨌든 탱으 판별 나다 좋다            0     0\n",
       "1                                           인 마지막 방 좋다            0     0\n",
       "2    인 쏘이다 너무 귀엽다 연출 마지막 연출 인상 깊다 딱 세 가다 좋다 인테리어 너무...            0     0\n",
       "3                         감테 공테 경계선 있다 테마 창공 많다 진짜 무섭다            0     0\n",
       "4                                                인생 테마            0     0\n",
       "..                                                 ...          ...   ...\n",
       "987                           문제 개연 가이드 전혀 부족 방 탈출 힘들다           -1    -1\n",
       "988                         개연 너무 떨어지다 방 탈출 즐겁다 경험 아니다           -1     1\n",
       "989                              개연 찾다 어렵다 방 탈출 많이 힘들다           -1     1\n",
       "990                              이야기 전개 개연 없다 정말 별로 이다           -1    -1\n",
       "991                                 방 탈출 개연 떨어지다 전반 실망           -1    -1\n",
       "\n",
       "[992 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문장을 입력했을 때, 예측 값을 도출해주는 함수\n",
    "\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "# 함수 정의\n",
    "def classify_text(text):\n",
    "    # 문장을 토큰화하고 모델에 입력으로 전달\n",
    "    text = cleaned_content(text)\n",
    "    text = kiwi_clean(text)\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "    # 소프트맥스 함수를 사용하여 확률값 계산\n",
    "    probabilities = softmax(outputs.logits, dim=1)\n",
    "\n",
    "    # 가장 높은 확률값에 해당하는 클래스 선택\n",
    "    predicted_class = torch.argmax(probabilities).item()\n",
    "\n",
    "    return predicted_class, probabilities\n",
    "\n",
    "def change_num(num):\n",
    "    if num == 0:\n",
    "        return (-1)\n",
    "    elif num == 1:\n",
    "        return 0\n",
    "    elif num == 2:\n",
    "        return 1\n",
    "\n",
    "pred_list = []\n",
    "for sent in tqdm(test_data['content']):\n",
    "    pred, _ = classify_text(sent)\n",
    "    pred_list.append(pred)\n",
    "\n",
    "test_data['pred'] = pred_list\n",
    "test_data['pred'] = test_data['pred'].apply(change_num)\n",
    "test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0포함 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.91      0.82      0.87        51\n",
      "           0       0.99      1.00      1.00       901\n",
      "           1       0.86      0.90      0.88        40\n",
      "\n",
      "    accuracy                           0.98       992\n",
      "   macro avg       0.92      0.91      0.91       992\n",
      "weighted avg       0.98      0.98      0.98       992\n",
      "\n",
      "0 제외 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.98      0.82      0.89        51\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.86      0.90      0.88        40\n",
      "\n",
      "    accuracy                           0.86        91\n",
      "   macro avg       0.61      0.57      0.59        91\n",
      "weighted avg       0.92      0.86      0.89        91\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/bert_electra/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/bert_electra/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/bert_electra/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('0포함', '\\n', classification_report(test_data['probability'], test_data['pred']))\n",
    "test_data2 = test_data[test_data['probability'] != 0]\n",
    "print('0 제외', '\\n', classification_report(test_data2['probability'], test_data2['pred']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장: 개연성 말이 되는 게 없다., 평가: 0\n",
      "---------- \n",
      "\n",
      "문장: 개연성 무슨 일이지..., 평가: 0\n",
      "---------- \n",
      "\n",
      "문장: 개연성이 있어서 방탈출이 재미있었어여, 평가: 2\n",
      "---------- \n",
      "\n",
      "문장: 개연성 최악, 평가: 0\n",
      "---------- \n",
      "\n",
      "문장: 스토리 진짜 좋다., 평가: 1\n",
      "---------- \n",
      "\n",
      "문장: 여기 인테리어 짱이네요, 평가: 1\n",
      "---------- \n",
      "\n",
      "문장: 개연성 스레기같아., 평가: 0\n",
      "---------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test = [\n",
    "    '개연성 말이 되는 게 없다.',\n",
    "    '개연성 무슨 일이지...',\n",
    "    '개연성이 있어서 방탈출이 재미있었어여',\n",
    "    '개연성 최악',\n",
    "    '스토리 진짜 좋다.',\n",
    "    '여기 인테리어 짱이네요',\n",
    "    '개연성 스레기같아.',\n",
    "]\n",
    "\n",
    "for sent in test:\n",
    "    pred, _ = classify_text(sent)\n",
    "    print(f'문장: {sent}, 평가: {pred}')\n",
    "    print(\"-\"*10, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bert_electra",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
