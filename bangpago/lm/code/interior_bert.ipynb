{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 필요한 라이브러리 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/bert_electra/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import ElectraModel, ElectraTokenizer\n",
    "from transformers import ElectraForSequenceClassification\n",
    "from transformers import AutoTokenizer, AutoModelForSemanticSegmentation, TrainingArguments, Trainer\n",
    "\n",
    "import torch\n",
    "\n",
    "import pandas as pd\n",
    "from konlpy.tag import Mecab\n",
    "import re\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 불러오기 및 정제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_48442/1311105383.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  interior_data['content_id'] = interior_data['content_id'].apply(lambda x: x.split(',')[0] if len(str(x)) > 6 else x)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content_id</th>\n",
       "      <th>interior</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>361617</td>\n",
       "      <td>0</td>\n",
       "      <td>오류장치 ㅠㅠ\\n.\\n.\\n옵으로 다시 참여\\n그 땐 문제도 못 풀었지만 100방 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>424772</td>\n",
       "      <td>0</td>\n",
       "      <td>390. 조도 무슨일이야...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>430139</td>\n",
       "      <td>0</td>\n",
       "      <td>4인. 309번째 심연으로 떠납니다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>431064</td>\n",
       "      <td>0</td>\n",
       "      <td>4인. 극악의 조도. 그게 다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>432520</td>\n",
       "      <td>0</td>\n",
       "      <td>조도가 낮은게 아니라 없는 수준이라고 하던데, 확실히 느꼈다.. 조도도 낮은데 관찰...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5018</th>\n",
       "      <td>425802</td>\n",
       "      <td>0</td>\n",
       "      <td>2021. 12. 26. (3인) 각자 1인분씩 하고 뿌듯했던 테마^_^</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5019</th>\n",
       "      <td>428828</td>\n",
       "      <td>1</td>\n",
       "      <td>첫방 디버프로 초반에 절어버림..ㅋㅋ 볼것도 못보고 힌트썼는데 잘꾸며놓았다 ㅎㅎ 살...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5020</th>\n",
       "      <td>428930</td>\n",
       "      <td>0</td>\n",
       "      <td>#5 - 2인 - 볼륨에 압도됨 - 히터도 방마다 빵빵함 - 다른 테마도 궁금해짐</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5021</th>\n",
       "      <td>429009</td>\n",
       "      <td>0</td>\n",
       "      <td>265, 2인, 장치...ㅋㅋㅋㅋㅋㅋ 그걸 왜 몰랐냐... 장치에 속지 말자</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5022</th>\n",
       "      <td>429009</td>\n",
       "      <td>0</td>\n",
       "      <td>265, 2인, 장치...ㅋㅋㅋㅋㅋㅋ 그걸 왜 몰랐냐... 장치에 속지 말자</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5023 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      content_id  interior                                            content\n",
       "0         361617         0  오류장치 ㅠㅠ\\n.\\n.\\n옵으로 다시 참여\\n그 땐 문제도 못 풀었지만 100방 ...\n",
       "1         424772         0                                   390. 조도 무슨일이야...\n",
       "2         430139         0                                4인. 309번째 심연으로 떠납니다\n",
       "3         431064         0                                  4인. 극악의 조도. 그게 다.\n",
       "4         432520         0  조도가 낮은게 아니라 없는 수준이라고 하던데, 확실히 느꼈다.. 조도도 낮은데 관찰...\n",
       "...          ...       ...                                                ...\n",
       "5018      425802         0           2021. 12. 26. (3인) 각자 1인분씩 하고 뿌듯했던 테마^_^\n",
       "5019      428828         1  첫방 디버프로 초반에 절어버림..ㅋㅋ 볼것도 못보고 힌트썼는데 잘꾸며놓았다 ㅎㅎ 살...\n",
       "5020      428930         0      #5 - 2인 - 볼륨에 압도됨 - 히터도 방마다 빵빵함 - 다른 테마도 궁금해짐\n",
       "5021      429009         0         265, 2인, 장치...ㅋㅋㅋㅋㅋㅋ 그걸 왜 몰랐냐... 장치에 속지 말자\n",
       "5022      429009         0         265, 2인, 장치...ㅋㅋㅋㅋㅋㅋ 그걸 왜 몰랐냐... 장치에 속지 말자\n",
       "\n",
       "[5023 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# labeling 된 데이터 불러오기\n",
    "survey = pd.read_csv(\"./data/survey.csv\", index_col=0)\n",
    "survey.fillna(0, inplace=True)\n",
    "survey = survey.reset_index()\n",
    "\n",
    "# 데이터 중에서 작업을 하고자 하는 라벨만 가져오기\n",
    "interior_data = survey[['content_id', 'interior']]\n",
    "\n",
    "# content_id 중에서 댓글이 같이 추가된 데이터 정리\n",
    "interior_data['content_id'] = interior_data['content_id'].apply(lambda x: x.split(',')[0] if len(str(x)) > 6 else x)\n",
    "\n",
    "# content_id 가 0인 데이터 제외 -> content_id 모두 int type 으로 변경 (추후 Merge 를 위함)\n",
    "interior_data = interior_data[interior_data['content_id'] != 0].reset_index().drop(columns=['index'])\n",
    "interior_data['content_id'] = interior_data['content_id'].astype(int)\n",
    "\n",
    "# 전체 review data 불러오기\n",
    "review_all = pd.read_csv(\"./data/reviews.csv\", index_col=0)\n",
    "\n",
    "# 전체 review data 중에서 survey data에 있는 댓글만 가져오기\n",
    "survey_content = review_all.loc[review_all['id'].isin(interior_data['content_id'])][['id', 'content']]\n",
    "# merge 를 위해서 id 컬럼명 통일하기\n",
    "survey_content.columns=['content_id', 'content']\n",
    "\n",
    "# 통일된 content_id 를 기반으로 데이터 merge\n",
    "interior_content = pd.merge(interior_data, survey_content)\n",
    "\n",
    "# 추후 원활한 계산을 위해서 숫자 부분은 모두 int 로 바꿔줌\n",
    "interior_content['interior'] = interior_content['interior'].astype(int)\n",
    "interior_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>interior</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>오류장치 . . . 옵으로 다시 참여. 그 땐 문제도 못 풀었지만 100방 이상 쌓...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>390. 조도 무슨일이야.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4인. 309번째 심연으로 떠납니다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4인. 극악의 조도. 그게 다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>조도가 낮은게 아니라 없는 수준이라고 하던데, 확실히 느꼈다. 조도도 낮은데 관찰력...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5018</th>\n",
       "      <td>2021. 12. 26. (3인) 각자 1인분씩 하고 뿌듯했던 테마.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5019</th>\n",
       "      <td>첫방 디버프로 초반에 절어버림. 볼것도 못보고 힌트썼는데 잘꾸며놓았다 . 살짝 장치...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5020</th>\n",
       "      <td>#5 - 2인 - 볼륨에 압도됨 - 히터도 방마다 빵빵함 - 다른 테마도 궁금해짐</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5021</th>\n",
       "      <td>265, 2인, 장치. 그걸 왜 몰랐냐. 장치에 속지 말자</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5022</th>\n",
       "      <td>265, 2인, 장치. 그걸 왜 몰랐냐. 장치에 속지 말자</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5023 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content  interior\n",
       "0     오류장치 . . . 옵으로 다시 참여. 그 땐 문제도 못 풀었지만 100방 이상 쌓...         0\n",
       "1                                        390. 조도 무슨일이야.         0\n",
       "2                                   4인. 309번째 심연으로 떠납니다         0\n",
       "3                                     4인. 극악의 조도. 그게 다.         0\n",
       "4     조도가 낮은게 아니라 없는 수준이라고 하던데, 확실히 느꼈다. 조도도 낮은데 관찰력...         0\n",
       "...                                                 ...       ...\n",
       "5018             2021. 12. 26. (3인) 각자 1인분씩 하고 뿌듯했던 테마.         0\n",
       "5019  첫방 디버프로 초반에 절어버림. 볼것도 못보고 힌트썼는데 잘꾸며놓았다 . 살짝 장치...         1\n",
       "5020      #5 - 2인 - 볼륨에 압도됨 - 히터도 방마다 빵빵함 - 다른 테마도 궁금해짐         0\n",
       "5021                   265, 2인, 장치. 그걸 왜 몰랐냐. 장치에 속지 말자         0\n",
       "5022                   265, 2인, 장치. 그걸 왜 몰랐냐. 장치에 속지 말자         0\n",
       "\n",
       "[5023 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 최소한의 전처리\n",
    "def cleaned_content(text):\n",
    "    d = re.sub('\\n', '. ', text) # 줄바꿈 > .\n",
    "    d = re.sub('[^가-힣0-9a-zA-Z ]{2,}', \".\", d) # 특수문자 두개 이상인거 .으로 변경\n",
    "    return d\n",
    "\n",
    "interior_content['content'] = interior_content['content'].apply(cleaned_content)\n",
    "\n",
    "final_df = interior_content[['content', 'interior']]\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "interior\n",
       " 0    4548\n",
       " 1     450\n",
       "-1      25\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 라벨별 개수 확인\n",
    "final_df['interior'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modeling을 위해 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data interior\n",
      " 0    3639\n",
      " 1     359\n",
      "-1      20\n",
      "Name: count, dtype: int64\n",
      "\n",
      " test_data interior\n",
      " 0    899\n",
      " 1    100\n",
      "-1      6\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_data = final_df.sample(frac=0.8, random_state=42).reset_index().drop(columns='index')\n",
    "print('train_data', train_data['interior'].value_counts())\n",
    "test_data = final_df.drop(train_data.index).reset_index().drop(columns='index')\n",
    "print('\\n', 'test_data', test_data['interior'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 전 학습 데이터셋: 4018\n",
      "중복 제거 전 테스트 데이터셋: 1005\n",
      "\n",
      "\n",
      "중복 제거 후 학습 데이터셋: 4003\n",
      "중복 제거 후 테스트 데이터셋: 1001\n"
     ]
    }
   ],
   "source": [
    "# 중복 데이터 제거(데이터 분리 후 중복이 생길 수 있어서 데이터 분리 후 중복 데이터 처리 진행)\n",
    "\n",
    "# 데이터셋 개수 확인\n",
    "print('중복 제거 전 학습 데이터셋: {}'.format(len(train_data)))\n",
    "print('중복 제거 전 테스트 데이터셋: {}'.format(len(test_data)))\n",
    "\n",
    "# 중복 데이터 제거\n",
    "train_data.drop_duplicates(subset=['content'], inplace=True)\n",
    "test_data.drop_duplicates(subset=['content'], inplace=True)\n",
    "print('\\n')\n",
    "# 데이터셋 개수 확인\n",
    "print('중복 제거 후 학습 데이터셋: {}'.format(len(train_data)))\n",
    "print('중복 제거 후 테스트 데이터셋: {}'.format(len(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>interior</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>매장에서 가장 쉬웠던 테마 . . 마지막과 전 문제는 일행분의 캐리로 잘 넘어갔숨....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>낯선가족보단 낫다.스토리라도 낫잖아. 띠링에이트 졸업</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>232. 3인 역시 믿고하는 딤개님 테마</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#174. 2인 w/ DMC 입졸 4연방 중 마지막 내 정수리가 스플릿 될 뻔 ㅜ ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#384. 2인. 살짝 어렵다했는데 문제수가 많지 않아 나름 무난히 나올 수 있었다...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  interior\n",
       "0  매장에서 가장 쉬웠던 테마 . . 마지막과 전 문제는 일행분의 캐리로 잘 넘어갔숨....         0\n",
       "1                      낯선가족보단 낫다.스토리라도 낫잖아. 띠링에이트 졸업         0\n",
       "2                             232. 3인 역시 믿고하는 딤개님 테마         0\n",
       "3  #174. 2인 w/ DMC 입졸 4연방 중 마지막 내 정수리가 스플릿 될 뻔 ㅜ ...         0\n",
       "4  #384. 2인. 살짝 어렵다했는데 문제수가 많지 않아 나름 무난히 나올 수 있었다...         0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>interior</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#1415_20221128_3인. 흐음.잘 열어보지 않으면</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>난.바보야.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>들어가자마자 커피향이 씨게 낫다 좋앗다 하지만 인테리어는 그냥그랫다. 풀정도 되는듯.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3인. 스토리가 잘 감이 안 잡힌다!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.5/3인. 활동성 있음.추락조심</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           content  interior\n",
       "0                 #1415_20221128_3인. 흐음.잘 열어보지 않으면         0\n",
       "1                                           난.바보야.         0\n",
       "2  들어가자마자 커피향이 씨게 낫다 좋앗다 하지만 인테리어는 그냥그랫다. 풀정도 되는듯.         1\n",
       "3                             3인. 스토리가 잘 감이 안 잡힌다!         0\n",
       "4                              1.5/3인. 활동성 있음.추락조심         0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(train_data.head()), display(test_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modeling 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰에 추가할 단어 -> '방탈출'이라는 도메인 지시기에 근거한 용어, 분리되어서는 안 되기 때문에 별도로 추가 작업 진행\n",
    "addword = ['공테', '약공테', '감테', '창공', '갑툭튀', '삐딱', '삑', '꽝', '삑딱쾅', '삑딱쾅', '삑딱', '쫄', '극쫄',\n",
    "            '극극쫄', '쫄팟', '쫄탱', '쫄보', '극', '약탱', '탱쫄', '극극극', '뉴비', '하드캐리', '극혐', '피지컬',\n",
    "            '어거지', '뚝배기', '뚝문', '셀뚝', '억까', '트롤링', '트롤짓', '흙길', '풀길', '꽃길', '풀꽃', '꽃다발',\n",
    "            '꽃밭', '웰메이드', '인생테마', '머글', '방린이', '방유아', '방세포', '방태아', '방탈러', '과몰입러', '옵저버',\n",
    "            '리트', '연방', '혼방', '혼불', '워킹', '워크인', '장치방', '문제방', '직렬', '병렬', '육각형', '볼드', '볼드충', '에바',\n",
    "            '가이드', '조도', '조명', '밝기', '어두움', '인테리어', '비주얼', '소품', '디자인',\n",
    "            '스토리','기승전결','흐름도','결말','서사','이야기','유니버스','전개','시나리오', '개연성', '명료',\n",
    "            '창의성','창의','신선','독특','참신','발상', '연출','짜임','사실감','구현','현실감','현장감', '활동성','활동력','활동량','움직임','반경',\n",
    "            '규모','스케일','볼륨','사이즈','크기','넓이','공간감','분량', '공포','공테','무서움','담력','스릴러',\n",
    "            '문제', '장치', '기계', '센서', '기구', '불친절',\n",
    "            '메르헨', '커튼콜', '카르텔', '소우주', '풀문', '도고', '플래시', '나우히어', '나비효과', '몽중', '가이드라인',\n",
    "            '연출력', '짜임새', '공포도', '공포감', '공포심', '약공테', '문제퀄']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사전학습된 bert 모델 사용\n",
    "# num_labels 클래스에 대해서 훈련을 하기 위해서 num_labels=3 할당함, problem_type=\"multi_label_classification\" 를 통해서 모델이 다중 레이블 분류에 해당함을 명시\n",
    "model = ElectraForSequenceClassification.from_pretrained(\"monologg/koelectra-small-v3-discriminator\", num_labels=3, problem_type=\"multi_label_classification\")\n",
    "tokenizer = ElectraTokenizer.from_pretrained(\"monologg/koelectra-base-v3-discriminator\")\n",
    "\n",
    "# token에 새로운 단어 추가\n",
    "tokenizer.add_tokens(addword)\n",
    "# token에 단어 추가후 기존 모델의 임베딩 레이어에 추가한 단어에 대한 임베딩 벡터가 없을 수 있기 때문\n",
    "# 아래 코드를 통해서 토큰의 개수가 변했음을 모델에 알리고 모델의 임베딩 레이어를 조정하여 새로운 토큰을 수용할 수 있게 함\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 content 중 최대 문장 길이 확인\n",
    "content_len = []\n",
    "for num in final_df['content']:\n",
    "    content_len.append(len(num))\n",
    "max(content_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train content 토큰화\n",
    "tokenized_train_sentences = tokenizer(\n",
    "    list(train_data['content']),\n",
    "    return_tensors=\"pt\",\n",
    "    max_length=128,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    add_special_tokens=True\n",
    ")\n",
    "\n",
    "# test content 토큰화\n",
    "tokenized_test_sentences = tokenizer(\n",
    "    list(test_data['content']),\n",
    "    return_tensors=\"pt\",\n",
    "    max_length=128,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    add_special_tokens=True\n",
    ")\n",
    "\n",
    "# 분류 모델에 넣기 위해서 1차원으로 구성된 세 개의 클래스를 2차원으로 재구성 후 label 로 투입\n",
    "# -1(부정)=0, 0(중립)=1, 1(긍정)=2\n",
    "\n",
    "train_label = []\n",
    "for label in train_data[\"interior\"].values:\n",
    "    if label == -1:\n",
    "        train_label.append([1., 0., 0.])\n",
    "    elif label == 0:\n",
    "        train_label.append([0., 1., 0.])\n",
    "    elif label == 1:\n",
    "        train_label.append([0., 0., 1.])\n",
    "\n",
    "test_label = []\n",
    "for label in test_data['interior'].values:\n",
    "    if label == 0:\n",
    "        test_label.append([0., 1., 0.])\n",
    "    elif label == -1:\n",
    "        test_label.append([1., 0., 0.])\n",
    "    elif label == 1:\n",
    "        test_label.append([0., 0., 1.])\n",
    "\n",
    "# model 에 넣기 위한 dataset 생성 class\n",
    "class CurseDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "        \n",
    "# bert 모델에 데이터가 들어갈 수 있게 만들어 둔 class를 활용하여 train, test dataset 생성\n",
    "train_dataset = CurseDataset(tokenized_train_sentences, train_label)\n",
    "test_dataset = CurseDataset(tokenized_test_sentences, test_label)\n",
    "\n",
    "# hugging face 의 trasformers 라이브러리를 사용하여 모델 훈련시킬 때 사용되는 객체 설정 부분\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = './interior_model/check_point/try_2',    # 모델과 훈련 중 생성되는 파일이 저장될 디렉토리 경로\n",
    "    num_train_epochs = 10,              # 훈련 epoch 수\n",
    "    per_device_train_batch_size = 16,    # 장치에 할당된 훈련 배치 크기\n",
    "    per_device_eval_batch_size = 64,    # 장치에 할당된 평가 배치 크기, 모델을 평가할 때 사용되는 배치 크기\n",
    "    logging_dir = './logs',             # 훈련 중 로그 파일이 저장될 디렉토리\n",
    "    logging_steps = 500,                # 로그 출력 빈도, 500 step에 한 번씩 출력 예정\n",
    "    save_total_limit = 2,               # 체크포인트 파일 저장 제한 수\n",
    ")\n",
    "\n",
    "# hugging face 의 trasformers 라이브러리를 사용하여 모델 훈련하고 관리하는 객체 설정 부분\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 진행\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.save_model(\"./interior_model/try_3/interior_model3\")\n",
    "# tokenizer.save_pretrained(\"./interior_model/try_3/interior_tokenizer3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1차 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장된 모델과 토크나이저를 불러오기\n",
    "\n",
    "model_path = \"./interior_model/interior_model1/\"  \n",
    "tokenizer_path = \"./interior_model/interior_tokenizer1/\"\n",
    "\n",
    "model = ElectraForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer = ElectraTokenizer.from_pretrained(tokenizer_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장을 입력했을 때, 예측 값을 도출해주는 함수\n",
    "\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "# 함수 정의\n",
    "def classify_text(text):\n",
    "    # 문장을 토큰화하고 모델에 입력으로 전달\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "    # 소프트맥스 함수를 사용하여 확률값 계산\n",
    "    probabilities = softmax(outputs.logits, dim=1)\n",
    "\n",
    "    # 가장 높은 확률값에 해당하는 클래스 선택\n",
    "    predicted_class = torch.argmax(probabilities).item()\n",
    "\n",
    "    if predicted_class == 0:\n",
    "        pred == -1\n",
    "    if predicted_class == 1:\n",
    "        pred == 0\n",
    "    if predicted_class == 2:\n",
    "        pred == 1\n",
    "\n",
    "    return pred, probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data의 content를 예측하여 새로운 컬럼에 넣어 예측률 확인\n",
    "\n",
    "pred_list = []\n",
    "for sent in tqdm(test_data['content']):\n",
    "    pred, _ = classify_text(sent)\n",
    "    pred_list.append(pred)\n",
    "    \n",
    "test_data['pred'] = pred_list\n",
    "test_data['pred'] = test_data['pred'].apply(change_num)\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data['interior'].value_counts())\n",
    "print(test_data['interior'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test_data['interior'], test_data['pred']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data2 = test_data[test_data['interior'] != 0]\n",
    "test_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test_data2['interior'], test_data2['pred']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 한 문장에 대한 평가 (신규 문장에 대한 평가)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ['인테리어 최악이네', '인테리어 개쩔어', '인테리어가 안 좋지는 않았어요.', '스토리 구려', '활동성은 없는데, 인테리어는 좋네요.']\n",
    "\n",
    "for sent in test:\n",
    "    pred, _ = classify_text(sent)\n",
    "    print(f'문장: {sent}, 평가: {pred}')\n",
    "    print(\"-\"*10, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1차 결론\n",
    "- 부정 평가가 현저히 적어, 부정적인 반응에 대한 결과를 예측하지 못하고 있다고 판단.\n",
    "- 인테리어가 있다는 것도 없다는 것도 모두 긍정적인 평가를 도출 -> 실질적으로 사용이 힘들 정도의 정확도를 보여줌\n",
    "\n",
    "### 1차 결론에 대한 해결 방안\n",
    "- 에폭과 배치 사이즈 등 조절을 통해서 새롭게 학습 진행 필요\n",
    "- 부정적인 학습에 대한 증가를 위해 데이터 증강 진행\n",
    "\n",
    "### 1차 모델 기초 사항\n",
    "~~~\n",
    "tokenized_train_sentences = tokenizer(\n",
    "    list(train_data['content']),\n",
    "    return_tensors=\"pt\",\n",
    "    max_length=128,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    add_special_tokens=True\n",
    ")\n",
    "tokenized_test_sentences = tokenizer(\n",
    "    list(test_data['content']),\n",
    "    return_tensors=\"pt\",\n",
    "    max_length=128,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    add_special_tokens=True\n",
    ")\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = './interior_model',    # 모델과 훈련 중 생성되는 파일이 저장될 디렉토리 경로\n",
    "    num_train_epochs = 15,              # 훈련 epoch 수\n",
    "    per_device_train_batch_size = 4,    # 장치에 할당된 훈련 배치 크기\n",
    "    per_device_eval_batch_size = 16,    # 장치에 할당된 평가 배치 크기, 모델을 평가할 때 사용되는 배치 크기\n",
    "    logging_dir = './logs',             # 훈련 중 로그 파일이 저장될 디렉토리\n",
    "    logging_steps = 500,                # 로그 출력 빈도, 500 step에 한 번씩 출력 예정\n",
    "    save_total_limit = 2,               # 체크포인트 파일 저장 제한 수\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2차 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[달라진 점]\n",
    "- 과적합을 피하기 위해 에폭 수 조절 (15 -> 10)\n",
    "- 훈련 배치 크기 조절 (4 -> 16)\n",
    "- 평가 배치 크기 조절 (16 -> 64)     \n",
    "    => 배치 크기는 학습 속도에 영향을 준다. 보다 빠른 속도로 학습 마무리 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장된 모델과 토크나이저를 불러오기\n",
    "\n",
    "model_path = \"./interior_model/try_2/interior_model2\"  \n",
    "tokenizer_path = \"./interior_model/try_2/interior_tokenizer2\"\n",
    "\n",
    "model = ElectraForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer = ElectraTokenizer.from_pretrained(tokenizer_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장을 입력했을 때, 예측 값을 도출해주는 함수\n",
    "\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "# 함수 정의\n",
    "def classify_text(text):\n",
    "    # 문장을 토큰화하고 모델에 입력으로 전달\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "    # 소프트맥스 함수를 사용하여 확률값 계산\n",
    "    probabilities = softmax(outputs.logits, dim=1)\n",
    "\n",
    "    # 가장 높은 확률값에 해당하는 클래스 선택\n",
    "    predicted_class = torch.argmax(probabilities).item()\n",
    "\n",
    "    return predicted_class, probabilities\n",
    "\n",
    "def change_num(num):\n",
    "    if num == 0:\n",
    "        return (-1)\n",
    "    elif num == 1:\n",
    "        return 0\n",
    "    elif num == 2:\n",
    "        return 1\n",
    "\n",
    "pred_list = []\n",
    "for sent in tqdm(test_data['content']):\n",
    "    pred, _ = classify_text(sent)\n",
    "    pred_list.append(pred)\n",
    "\n",
    "test_data['pred'] = pred_list\n",
    "test_data['pred'] = test_data['pred'].apply(change_num)\n",
    "test_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data['interior'].value_counts())\n",
    "print(test_data['interior'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test_data['interior'], test_data['pred']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data2 = test_data[test_data['interior'] != 0]\n",
    "test_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test_data2['interior'], test_data2['pred']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 한 문장에 대한 평가 (신규 문장에 대한 평가)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ['인테리어 최악이네', '인테리어 개쩔어', '인테리어가 안 좋지는 않았어요.', '스토리 구려', '활동성은 없는데, 인테리어는 좋네요.']\n",
    "\n",
    "for sent in test:\n",
    "    pred, _ = classify_text(sent)\n",
    "    print(f'문장: {sent}, 평가: {pred}')\n",
    "    print(\"-\"*10, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2차 결론\n",
    "- 1차에 비해서 중립 결과에 대해서 잘 뽑아줌\n",
    "- 다만, 아직도 부정 표현에 대한 학습이 되지 않는 것으로 확인됨\n",
    "\n",
    "### 2차 결론에 대한 해결 방안\n",
    "- 데이터 증강을 통해 부정 표현이 충분히 학습될 수 있도록 진행\n",
    "\n",
    "### 2차 모델 기초 사항\n",
    "~~~\n",
    "tokenized_train_sentences = tokenizer(\n",
    "    list(train_data['content']),\n",
    "    return_tensors=\"pt\",\n",
    "    max_length=128,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    add_special_tokens=True\n",
    ")\n",
    "tokenized_test_sentences = tokenizer(\n",
    "    list(test_data['content']),\n",
    "    return_tensors=\"pt\",\n",
    "    max_length=128,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    add_special_tokens=True\n",
    ")\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = './interior_model/check_point/try_2',    # 모델과 훈련 중 생성되는 파일이 저장될 디렉토리 경로\n",
    "    num_train_epochs = 10,              # 훈련 epoch 수\n",
    "    per_device_train_batch_size = 16,    # 장치에 할당된 훈련 배치 크기\n",
    "    per_device_eval_batch_size = 64,    # 장치에 할당된 평가 배치 크기, 모델을 평가할 때 사용되는 배치 크기\n",
    "    logging_dir = './logs',             # 훈련 중 로그 파일이 저장될 디렉토리\n",
    "    logging_steps = 500,                # 로그 출력 빈도, 500 step에 한 번씩 출력 예정\n",
    "    save_total_limit = 2,               # 체크포인트 파일 저장 제한 수\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    ")\n",
    "\n",
    "TrainOutput(global_step=2510, training_loss=0.026810125591033008, metrics={'train_runtime': 447.08, 'train_samples_per_second': 89.537, 'train_steps_per_second': 5.614, 'train_loss': 0.026810125591033008, 'epoch': 10.0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3차 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[달라진 점]\n",
    "- 부정 표현 학습을 위해 부정어 데이터 증강\n",
    "\n",
    "** 그 외의 조건은 두 번째 모델과 똑같이 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>interior</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>매장에서 가장 쉬웠던 테마 . . 마지막과 전 문제는 일행분의 캐리로 잘 넘어갔숨....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>낯선가족보단 낫다.스토리라도 낫잖아. 띠링에이트 졸업</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>232. 3인 역시 믿고하는 딤개님 테마</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#174. 2인 w/ DMC 입졸 4연방 중 마지막 내 정수리가 스플릿 될 뻔 ㅜ ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#384. 2인. 살짝 어렵다했는데 문제수가 많지 않아 나름 무난히 나올 수 있었다...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>퍼즐을 푸는 도중에도 인테리어가 집중을 방해했다</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>방탈출 공간의 디자인이 지나치게 복잡해서 불편함을 느꼈다</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>방탈출에서의 인테리어는 혼란스럽게 설계돼 어려움을 더 키웠다</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>퍼즐 해결에 집중해야 하는데, 난해한 인테리어 때문에 쉽게 흐트러졌다</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>인테리어 디자인이 퍼즐 풀이를 방해하여 쾌적한 경험을 막았다</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4045 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              content  interior\n",
       "0   매장에서 가장 쉬웠던 테마 . . 마지막과 전 문제는 일행분의 캐리로 잘 넘어갔숨....         0\n",
       "1                       낯선가족보단 낫다.스토리라도 낫잖아. 띠링에이트 졸업         0\n",
       "2                              232. 3인 역시 믿고하는 딤개님 테마         0\n",
       "3   #174. 2인 w/ DMC 입졸 4연방 중 마지막 내 정수리가 스플릿 될 뻔 ㅜ ...         0\n",
       "4   #384. 2인. 살짝 어렵다했는데 문제수가 많지 않아 나름 무난히 나올 수 있었다...         0\n",
       "..                                                ...       ...\n",
       "37                         퍼즐을 푸는 도중에도 인테리어가 집중을 방해했다        -1\n",
       "38                    방탈출 공간의 디자인이 지나치게 복잡해서 불편함을 느꼈다        -1\n",
       "39                  방탈출에서의 인테리어는 혼란스럽게 설계돼 어려움을 더 키웠다        -1\n",
       "40             퍼즐 해결에 집중해야 하는데, 난해한 인테리어 때문에 쉽게 흐트러졌다        -1\n",
       "41                  인테리어 디자인이 퍼즐 풀이를 방해하여 쾌적한 경험을 막았다        -1\n",
       "\n",
       "[4045 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 부정 표현 학습을 위해 부정어 데이터 증강\n",
    "new_data = [('인테리어 최악', -1), ('인테리어 최악은 아님', 1), ('인테리어는 최악이다.', -1), ('인테리어 디자인 정말 최악 중에 최악이야.', -1),\n",
    "('인테리어 별로임', -1), ('인테리어 별로는 아니야.', 1), ('인테리어 개별로', -1),\n",
    "('인테리어 안 좋음', -1), ('인테리어 안 좋지 않음', 1), ('인테리어 개좋음', 1), ('인테리어 개쩐다', 1), ('인테리어 쩐다', 1),\n",
    "('인테리어 불호', -1), ('인테리어 극호', 1), ('인테리어 개빡침', -1),\n",
    "('인테리어 불유쾌함', -1), ('인테리어 안 유쾌함', -1), ('인테리어 극혐', -1), ('인테리어 유쾌하지 않음', -1),\n",
    "('인테리어 천상임', 1), ('인테리어 생각보다 괜찮음', 1), ('인테리어 단순함', -1), \n",
    "('인테리어 돈 아까움', -1), ('인테리어 그닥....', -1), ('인테리어 억지스러움', -1),\n",
    "('노후화', -1), ('노후화 대박', -1), ('노후화 쩐다', -1), ('노후화 너무 심함', -1),\n",
    "('이것도 인테리어라고 꾸며놓은 건가?', -1), ('무슨 생각으로 만든 인테리어인지 모르겠따.', -1),\n",
    "('색상 조합이 안 좋지 않아 전체적으로 어수선함', -1), ('디자인이 불호를 일으켜 공간이 쾌적하지 않음', -1),\n",
    "('인테리어가 개빡침을 일으키는 수준이다', -1), ('인테리어 스타일이 너무 특이해서 별로임', -1), ('인테리어가 지나치게 다양한 스타일을 혼합하여 일관성이 없음', -1),\n",
    "('인테리어가 공간을 혼란스럽게 만들어 퍼즐 해결이 더 어려웠다', -1), ('퍼즐을 푸는 도중에도 인테리어가 집중을 방해했다', -1),('방탈출 공간의 디자인이 지나치게 복잡해서 불편함을 느꼈다', -1),\n",
    "('방탈출에서의 인테리어는 혼란스럽게 설계돼 어려움을 더 키웠다', -1), ('퍼즐 해결에 집중해야 하는데, 난해한 인테리어 때문에 쉽게 흐트러졌다', -1), ('인테리어 디자인이 퍼즐 풀이를 방해하여 쾌적한 경험을 막았다', -1),\n",
    "]\n",
    "new_df = pd.DataFrame(new_data, columns=['content', 'interior'])\n",
    "train_data = pd.concat([train_data, new_df])\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>interior</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#1415_20221128_3인. 흐음.잘 열어보지 않으면</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>난.바보야.</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>들어가자마자 커피향이 씨게 낫다 좋앗다 하지만 인테리어는 그냥그랫다. 풀정도 되는듯.</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3인. 스토리가 잘 감이 안 잡힌다!</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.5/3인. 활동성 있음.추락조심</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>퍼즐을 푸는 도중에도 인테리어가 집중을 방해했다</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>방탈출 공간의 디자인이 지나치게 복잡해서 불편함을 느꼈다</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>방탈출에서의 인테리어는 혼란스럽게 설계돼 어려움을 더 키웠다</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>퍼즐 해결에 집중해야 하는데, 난해한 인테리어 때문에 쉽게 흐트러졌다</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>인테리어 디자인이 퍼즐 풀이를 방해하여 쾌적한 경험을 막았다</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1043 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            content  interior  pred\n",
       "0                  #1415_20221128_3인. 흐음.잘 열어보지 않으면         0   0.0\n",
       "1                                            난.바보야.         0   0.0\n",
       "2   들어가자마자 커피향이 씨게 낫다 좋앗다 하지만 인테리어는 그냥그랫다. 풀정도 되는듯.         1   1.0\n",
       "3                              3인. 스토리가 잘 감이 안 잡힌다!         0   0.0\n",
       "4                               1.5/3인. 활동성 있음.추락조심         0   0.0\n",
       "..                                              ...       ...   ...\n",
       "37                       퍼즐을 푸는 도중에도 인테리어가 집중을 방해했다        -1   NaN\n",
       "38                  방탈출 공간의 디자인이 지나치게 복잡해서 불편함을 느꼈다        -1   NaN\n",
       "39                방탈출에서의 인테리어는 혼란스럽게 설계돼 어려움을 더 키웠다        -1   NaN\n",
       "40           퍼즐 해결에 집중해야 하는데, 난해한 인테리어 때문에 쉽게 흐트러졌다        -1   NaN\n",
       "41                인테리어 디자인이 퍼즐 풀이를 방해하여 쾌적한 경험을 막았다        -1   NaN\n",
       "\n",
       "[1043 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_test_df = [('방탈출 공간의 인테리어는 과도하게 혼잡해 퍼즐 해결이 더욱 어려웠다', -1), ('가구의 선택이 퍼즐과 어울리지 않아 감각적인 불편함을 느꼈다', -1),\n",
    "('디자인이 복잡해서 방탈출에서 효과적으로 협력하는 데 어려움을 겪었다', -1), ('퍼즐 해결을 위한 힌트가 인테리어에 묻혀서 찾기가 까다로웠다', -1), ('방탈출 공간의 가구가 공간을 지루하게 만들어 흥미를 잃었다', -1)\n",
    "]\n",
    "new_test_df = pd.DataFrame(new_test_df, columns=['content', 'interior'])\n",
    "test_data = pd.concat([test_data, new_df])\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사전학습된 bert 모델 사용\n",
    "# num_labels 클래스에 대해서 훈련을 하기 위해서 num_labels=3 할당함, problem_type=\"multi_label_classification\" 를 통해서 모델이 다중 레이블 분류에 해당함을 명시\n",
    "model = ElectraForSequenceClassification.from_pretrained(\"monologg/koelectra-small-v3-discriminator\", num_labels=3, problem_type=\"multi_label_classification\")\n",
    "tokenizer = ElectraTokenizer.from_pretrained(\"monologg/koelectra-base-v3-discriminator\")\n",
    "\n",
    "# token에 새로운 단어 추가\n",
    "tokenizer.add_tokens(addword)\n",
    "# token에 단어 추가후 기존 모델의 임베딩 레이어에 추가한 단어에 대한 임베딩 벡터가 없을 수 있기 때문\n",
    "# 아래 코드를 통해서 토큰의 개수가 변했음을 모델에 알리고 모델의 임베딩 레이어를 조정하여 새로운 토큰을 수용할 수 있게 함\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train content 토큰화\n",
    "tokenized_train_sentences = tokenizer(\n",
    "    list(train_data['content']),\n",
    "    return_tensors=\"pt\",\n",
    "    max_length=128,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    add_special_tokens=True\n",
    ")\n",
    "\n",
    "# test content 토큰화\n",
    "tokenized_test_sentences = tokenizer(\n",
    "    list(test_data['content']),\n",
    "    return_tensors=\"pt\",\n",
    "    max_length=128,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    add_special_tokens=True\n",
    ")\n",
    "\n",
    "# 분류 모델에 넣기 위해서 1차원으로 구성된 세 개의 클래스를 2차원으로 재구성 후 label 로 투입\n",
    "# -1(부정)=0, 0(중립)=1, 1(긍정)=2\n",
    "\n",
    "train_label = []\n",
    "for label in train_data[\"interior\"].values:\n",
    "    if label == -1:\n",
    "        train_label.append([1., 0., 0.])\n",
    "    elif label == 0:\n",
    "        train_label.append([0., 1., 0.])\n",
    "    elif label == 1:\n",
    "        train_label.append([0., 0., 1.])\n",
    "\n",
    "test_label = []\n",
    "for label in test_data['interior'].values:\n",
    "    if label == 0:\n",
    "        test_label.append([0., 1., 0.])\n",
    "    elif label == -1:\n",
    "        test_label.append([1., 0., 0.])\n",
    "    elif label == 1:\n",
    "        test_label.append([0., 0., 1.])\n",
    "\n",
    "# model 에 넣기 위한 dataset 생성 class\n",
    "class CurseDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "        \n",
    "# bert 모델에 데이터가 들어갈 수 있게 만들어 둔 class를 활용하여 train, test dataset 생성\n",
    "train_dataset = CurseDataset(tokenized_train_sentences, train_label)\n",
    "test_dataset = CurseDataset(tokenized_test_sentences, test_label)\n",
    "\n",
    "# hugging face 의 trasformers 라이브러리를 사용하여 모델 훈련시킬 때 사용되는 객체 설정 부분\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = './interior_model/check_point/try_3',    # 모델과 훈련 중 생성되는 파일이 저장될 디렉토리 경로\n",
    "    num_train_epochs = 10,              # 훈련 epoch 수\n",
    "    per_device_train_batch_size = 8,    # 장치에 할당된 훈련 배치 크기\n",
    "    per_device_eval_batch_size = 32,    # 장치에 할당된 평가 배치 크기, 모델을 평가할 때 사용되는 배치 크기\n",
    "    logging_dir = './logs',             # 훈련 중 로그 파일이 저장될 디렉토리\n",
    "    logging_steps = 500,                # 로그 출력 빈도, 500 step에 한 번씩 출력 예정\n",
    "    save_total_limit = 2,               # 체크포인트 파일 저장 제한 수\n",
    ")\n",
    "\n",
    "# hugging face 의 trasformers 라이브러리를 사용하여 모델 훈련하고 관리하는 객체 설정 부분\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 진행\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"./interior_model/try_3/interior_model3\")\n",
    "tokenizer.save_pretrained(\"./interior_model/try_3/interior_tokenizer3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# 저장된 모델과 토크나이저를 불러오기\n",
    "\n",
    "model_path = \"./interior_model/try_3/interior_model3\"  \n",
    "tokenizer_path = \"./interior_model/try_3/interior_tokenizer3\"\n",
    "\n",
    "model = ElectraForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer = ElectraTokenizer.from_pretrained(tokenizer_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1043/1043 [00:12<00:00, 85.78it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>interior</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#1415_20221128_3인. 흐음.잘 열어보지 않으면</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>난.바보야.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>들어가자마자 커피향이 씨게 낫다 좋앗다 하지만 인테리어는 그냥그랫다. 풀정도 되는듯.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3인. 스토리가 잘 감이 안 잡힌다!</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.5/3인. 활동성 있음.추락조심</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>퍼즐을 푸는 도중에도 인테리어가 집중을 방해했다</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>방탈출 공간의 디자인이 지나치게 복잡해서 불편함을 느꼈다</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>방탈출에서의 인테리어는 혼란스럽게 설계돼 어려움을 더 키웠다</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>퍼즐 해결에 집중해야 하는데, 난해한 인테리어 때문에 쉽게 흐트러졌다</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>인테리어 디자인이 퍼즐 풀이를 방해하여 쾌적한 경험을 막았다</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1043 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            content  interior  pred\n",
       "0                  #1415_20221128_3인. 흐음.잘 열어보지 않으면         0     0\n",
       "1                                            난.바보야.         0     0\n",
       "2   들어가자마자 커피향이 씨게 낫다 좋앗다 하지만 인테리어는 그냥그랫다. 풀정도 되는듯.         1     1\n",
       "3                              3인. 스토리가 잘 감이 안 잡힌다!         0     0\n",
       "4                               1.5/3인. 활동성 있음.추락조심         0     0\n",
       "..                                              ...       ...   ...\n",
       "37                       퍼즐을 푸는 도중에도 인테리어가 집중을 방해했다        -1     1\n",
       "38                  방탈출 공간의 디자인이 지나치게 복잡해서 불편함을 느꼈다        -1     1\n",
       "39                방탈출에서의 인테리어는 혼란스럽게 설계돼 어려움을 더 키웠다        -1     1\n",
       "40           퍼즐 해결에 집중해야 하는데, 난해한 인테리어 때문에 쉽게 흐트러졌다        -1     1\n",
       "41                인테리어 디자인이 퍼즐 풀이를 방해하여 쾌적한 경험을 막았다        -1     1\n",
       "\n",
       "[1043 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문장을 입력했을 때, 예측 값을 도출해주는 함수\n",
    "\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "# 함수 정의\n",
    "def classify_text(text):\n",
    "    # 문장을 토큰화하고 모델에 입력으로 전달\n",
    "    text = cleaned_content(text)\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "    # 소프트맥스 함수를 사용하여 확률값 계산\n",
    "    probabilities = softmax(outputs.logits, dim=1)\n",
    "\n",
    "    # 가장 높은 확률값에 해당하는 클래스 선택\n",
    "    predicted_class = torch.argmax(probabilities).item()\n",
    "\n",
    "    return predicted_class, probabilities\n",
    "\n",
    "def change_num(num):\n",
    "    if num == 0:\n",
    "        return (-1)\n",
    "    elif num == 1:\n",
    "        return 0\n",
    "    elif num == 2:\n",
    "        return 1\n",
    "\n",
    "pred_list = []\n",
    "for sent in tqdm(test_data['content']):\n",
    "    pred, _ = classify_text(sent)\n",
    "    pred_list.append(pred)\n",
    "\n",
    "test_data['pred'] = pred_list\n",
    "test_data['pred'] = test_data['pred'].apply(change_num)\n",
    "test_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interior\n",
      " 0    3624\n",
      " 1     368\n",
      "-1      53\n",
      "Name: count, dtype: int64\n",
      "interior\n",
      " 0    895\n",
      " 1    109\n",
      "-1     39\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_data['interior'].value_counts())\n",
    "print(test_data['interior'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.83      0.38      0.53        39\n",
      "           0       0.99      0.99      0.99       895\n",
      "           1       0.76      0.93      0.83       109\n",
      "\n",
      "    accuracy                           0.96      1043\n",
      "   macro avg       0.86      0.77      0.78      1043\n",
      "weighted avg       0.96      0.96      0.96      1043\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_data['interior'], test_data['pred']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>interior</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>들어가자마자 커피향이 씨게 낫다 좋앗다 하지만 인테리어는 그냥그랫다. 풀정도 되는듯.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>인테리어 향기 굿 문제 전반적으로 쉬운 문제였던거 같은데 내 능지가 얼마나 낮은지 ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>인테리러가 아름답네요. 카페 차리셔도 될듯.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2인 흥미롭게 잠수함 잘 구현 꽃길이나 세팅미스</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>#2인. 문제가 쉽고 재밌고, 인테리어가 이쁘다. 가볍게 즐길 수 있는 테마이고. ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>퍼즐을 푸는 도중에도 인테리어가 집중을 방해했다</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>방탈출 공간의 디자인이 지나치게 복잡해서 불편함을 느꼈다</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>방탈출에서의 인테리어는 혼란스럽게 설계돼 어려움을 더 키웠다</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>퍼즐 해결에 집중해야 하는데, 난해한 인테리어 때문에 쉽게 흐트러졌다</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>인테리어 디자인이 퍼즐 풀이를 방해하여 쾌적한 경험을 막았다</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>148 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              content  interior  pred\n",
       "2     들어가자마자 커피향이 씨게 낫다 좋앗다 하지만 인테리어는 그냥그랫다. 풀정도 되는듯.         1     1\n",
       "6   인테리어 향기 굿 문제 전반적으로 쉬운 문제였던거 같은데 내 능지가 얼마나 낮은지 ...         1     1\n",
       "9                            인테리러가 아름답네요. 카페 차리셔도 될듯.         1     1\n",
       "10                         2인 흥미롭게 잠수함 잘 구현 꽃길이나 세팅미스         1     0\n",
       "11  #2인. 문제가 쉽고 재밌고, 인테리어가 이쁘다. 가볍게 즐길 수 있는 테마이고. ...         1     1\n",
       "..                                                ...       ...   ...\n",
       "37                         퍼즐을 푸는 도중에도 인테리어가 집중을 방해했다        -1     1\n",
       "38                    방탈출 공간의 디자인이 지나치게 복잡해서 불편함을 느꼈다        -1     1\n",
       "39                  방탈출에서의 인테리어는 혼란스럽게 설계돼 어려움을 더 키웠다        -1     1\n",
       "40             퍼즐 해결에 집중해야 하는데, 난해한 인테리어 때문에 쉽게 흐트러졌다        -1     1\n",
       "41                  인테리어 디자인이 퍼즐 풀이를 방해하여 쾌적한 경험을 막았다        -1     1\n",
       "\n",
       "[148 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data2 = test_data[test_data['interior'] != 0]\n",
    "test_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.83      0.38      0.53        39\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.81      0.93      0.86       109\n",
      "\n",
      "    accuracy                           0.78       148\n",
      "   macro avg       0.55      0.44      0.46       148\n",
      "weighted avg       0.81      0.78      0.77       148\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/bert_electra/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/bert_electra/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/bert_electra/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_data2['interior'], test_data2['pred']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 한 문장에 대한 평가 (신규 문장에 대한 평가)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장: 인테리어 최악이네, 평가: 0\n",
      "---------- \n",
      "\n",
      "문장: 인테리어 개쩔어, 평가: 0\n",
      "---------- \n",
      "\n",
      "문장: 인테리어가 안 좋지는 않았어요., 평가: 2\n",
      "---------- \n",
      "\n",
      "문장: 스토리 구려, 평가: 1\n",
      "---------- \n",
      "\n",
      "문장: 활동성은 없는데, 인테리어는 좋네요., 평가: 2\n",
      "---------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test = ['인테리어 최악이네', '인테리어 개쩔어', '인테리어가 안 좋지는 않았어요.', '스토리 구려', '활동성은 없는데, 인테리어는 좋네요.']\n",
    "\n",
    "for sent in test:\n",
    "    pred, _ = classify_text(sent)\n",
    "    print(f'문장: {sent}, 평가: {pred}')\n",
    "    print(\"-\"*10, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3차 결론\n",
    "### 확인\n",
    "- 1차와 2차에 비해서 확실히 부정 표현에 대한 학습이 잘 되는 것으로 확인됨\n",
    "- 다만, 부정 표현 학습과 더불어 긍정 평가도 정확도가 떨어진다는 단점이 있음\n",
    "- 해당 부분은 이후 추가적으로 고려해봐야 할 것 같음\n",
    "\n",
    "### 3차 모델 기초 사항\n",
    "~~~\n",
    "# hugging face 의 trasformers 라이브러리를 사용하여 모델 훈련시킬 때 사용되는 객체 설정 부분\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = './interior_model/check_point/try_3',    # 모델과 훈련 중 생성되는 파일이 저장될 디렉토리 경로\n",
    "    num_train_epochs = 10,              # 훈련 epoch 수\n",
    "    per_device_train_batch_size = 8,    # 장치에 할당된 훈련 배치 크기\n",
    "    per_device_eval_batch_size = 32,    # 장치에 할당된 평가 배치 크기, 모델을 평가할 때 사용되는 배치 크기\n",
    "    logging_dir = './logs',             # 훈련 중 로그 파일이 저장될 디렉토리\n",
    "    logging_steps = 500,                # 로그 출력 빈도, 500 step에 한 번씩 출력 예정\n",
    "    save_total_limit = 2,               # 체크포인트 파일 저장 제한 수\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4차"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_71698/977129007.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  interior_data['content_id'] = interior_data['content_id'].apply(lambda x: x.split(',')[0] if len(str(x)) > 6 else x)\n"
     ]
    }
   ],
   "source": [
    "# labeling 된 데이터 불러오기\n",
    "survey = pd.read_csv(\"./_data/survey.csv\", index_col=0)\n",
    "survey.fillna(0, inplace=True)\n",
    "survey = survey.reset_index()\n",
    "\n",
    "# 데이터 중에서 작업을 하고자 하는 라벨만 가져오기\n",
    "interior_data = survey[['content_id', 'interior']]\n",
    "\n",
    "# content_id 중에서 댓글이 같이 추가된 데이터 정리\n",
    "interior_data['content_id'] = interior_data['content_id'].apply(lambda x: x.split(',')[0] if len(str(x)) > 6 else x)\n",
    "\n",
    "# content_id 가 0인 데이터 제외 -> content_id 모두 int type 으로 변경 (추후 Merge 를 위함)\n",
    "interior_data = interior_data[interior_data['content_id'] != 0].reset_index().drop(columns=['index'])\n",
    "interior_data['content_id'] = interior_data['content_id'].astype(int)\n",
    "\n",
    "# 전체 review data 불러오기\n",
    "review_all = pd.read_csv(\"./_data/reviews.csv\", index_col=0)\n",
    "\n",
    "# 전체 review data 중에서 survey data에 있는 댓글만 가져오기\n",
    "survey_content = review_all.loc[review_all['id'].isin(interior_data['content_id'])][['id', 'content']]\n",
    "# merge 를 위해서 id 컬럼명 통일하기\n",
    "survey_content.columns=['content_id', 'content']\n",
    "\n",
    "# 통일된 content_id 를 기반으로 데이터 merge\n",
    "interior_content = pd.merge(interior_data, survey_content)\n",
    "\n",
    "# 추후 원활한 계산을 위해서 숫자 부분은 모두 int 로 바꿔줌\n",
    "interior_content['interior'] = interior_content['interior'].astype(int)\n",
    "\n",
    "final_df = interior_content[['content', 'interior']]\n",
    "\n",
    "# 부정 표현 학습을 위해 부정어 데이터 증강\n",
    "new_data = [('인테리어 최악', -1), ('인테리어 최악은 아님', 1), ('인테리어는 최악이다.', -1), ('인테리어 디자인 정말 최악 중에 최악이야.', -1),\n",
    "('인테리어 별로임', -1), ('인테리어 별로는 아니야.', 1), ('인테리어 개별로', -1),\n",
    "('인테리어 안 좋음', -1), ('인테리어 안 좋지 않음', 1), ('인테리어 개좋음', 1), ('인테리어 개쩐다', 1), ('인테리어 쩐다', 1),\n",
    "('인테리어 불호', -1), ('인테리어 극호', 1), ('인테리어 개빡침', -1),\n",
    "('인테리어 불유쾌함', -1), ('인테리어 안 유쾌함', -1), ('인테리어 극혐', -1), ('인테리어 유쾌하지 않음', -1),\n",
    "('인테리어 천상임', 1), ('인테리어 생각보다 괜찮음', 1), ('인테리어 단순함', -1), \n",
    "('인테리어 돈 아까움', -1), ('인테리어 그닥....', -1), ('인테리어 억지스러움', -1),\n",
    "('노후화', -1), ('노후화 대박', -1), ('노후화 쩐다', -1), ('노후화 너무 심함', -1),\n",
    "('이것도 인테리어라고 꾸며놓은 건가?', -1), ('무슨 생각으로 만든 인테리어인지 모르겠따.', -1),\n",
    "('색상 조합이 안 좋지 않아 전체적으로 어수선함', -1), ('디자인이 불호를 일으켜 공간이 쾌적하지 않음', -1),\n",
    "('인테리어가 개빡침을 일으키는 수준이다', -1), ('인테리어 스타일이 너무 특이해서 별로임', -1), ('인테리어가 지나치게 다양한 스타일을 혼합하여 일관성이 없음', -1),\n",
    "('인테리어가 공간을 혼란스럽게 만들어 퍼즐 해결이 더 어려웠다', -1), ('퍼즐을 푸는 도중에도 인테리어가 집중을 방해했다', -1),('방탈출 공간의 디자인이 지나치게 복잡해서 불편함을 느꼈다', -1),\n",
    "('방탈출에서의 인테리어는 혼란스럽게 설계돼 어려움을 더 키웠다', -1), ('퍼즐 해결에 집중해야 하는데, 난해한 인테리어 때문에 쉽게 흐트러졌다', -1), ('인테리어 디자인이 퍼즐 풀이를 방해하여 쾌적한 경험을 막았다', -1),\n",
    "('방탈출 공간의 인테리어는 과도하게 혼잡해 퍼즐 해결이 더욱 어려웠다', -1), ('가구의 선택이 퍼즐과 어울리지 않아 감각적인 불편함을 느꼈다', -1),\n",
    "('디자인이 복잡해서 방탈출에서 효과적으로 협력하는 데 어려움을 겪었다', -1), ('퍼즐 해결을 위한 힌트가 인테리어에 묻혀서 찾기가 까다로웠다', -1), ('방탈출 공간의 가구가 공간을 지루하게 만들어 흥미를 잃었다', -1)\n",
    "]\n",
    "new_df = pd.DataFrame(new_data, columns=['content', 'interior'])\n",
    "final_df = pd.concat([final_df, new_df])\n",
    "final_df\n",
    "\n",
    "# 최소한의 전처리\n",
    "def cleaned_content(text):\n",
    "    d = re.sub('\\n', '. ', text) # 줄바꿈 > .\n",
    "    d = re.sub('[^가-힣0-9a-zA-Z ]{2,}', \".\", d) # 특수문자 두개 이상인거 .으로 변경\n",
    "    return d\n",
    "\n",
    "final_df['content'] = final_df['content'].apply(cleaned_content)\n",
    "\n",
    "\n",
    "\n",
    "from kiwipiepy import Kiwi\n",
    "kiwi = Kiwi()\n",
    "\n",
    "def kiwi_clean(text):\n",
    "    get_kiwi_pos = ['NNG', 'NP', 'NNP', 'MM', 'VV', 'VV-I', 'VV-R', 'VA', 'VA-I', 'VA-R', 'VCP', 'VCN', 'MAG', 'MAJ', 'XR']\n",
    "    kiwi_lem = []\n",
    "    for word in kiwi.tokenize(text):\n",
    "        if word.tag in get_kiwi_pos:\n",
    "            kiwi_lem.append(word.lemma)\n",
    "    return ' '.join(kiwi_lem)\n",
    "\n",
    "final_df['content'] = final_df['content'].apply(kiwi_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interior\n",
      " 0    4548\n",
      " 1     459\n",
      "-1      63\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "train_data interior\n",
      " 0    3646\n",
      " 1     362\n",
      "-1      48\n",
      "Name: count, dtype: int64\n",
      "\n",
      " test_data interior\n",
      " 0    870\n",
      " 1     91\n",
      "-1      6\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "중복 제거 전 학습 데이터셋: 4056\n",
      "중복 제거 전 테스트 데이터셋: 967\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "중복 제거 후 학습 데이터셋: 3953\n",
      "중복 제거 후 테스트 데이터셋: 951\n"
     ]
    }
   ],
   "source": [
    "# 라벨별 개수 확인\n",
    "print(final_df['interior'].value_counts())\n",
    "print('\\n')\n",
    "train_data = final_df.sample(frac=0.8, random_state=42).reset_index().drop(columns='index')\n",
    "print('train_data', train_data['interior'].value_counts())\n",
    "test_data = final_df.drop(train_data.index).reset_index().drop(columns='index')\n",
    "print('\\n', 'test_data', test_data['interior'].value_counts())\n",
    "print('\\n')\n",
    "# 중복 데이터 제거(데이터 분리 후 중복이 생길 수 있어서 데이터 분리 후 중복 데이터 처리 진행)\n",
    "\n",
    "# 데이터셋 개수 확인\n",
    "print('중복 제거 전 학습 데이터셋: {}'.format(len(train_data)))\n",
    "print('중복 제거 전 테스트 데이터셋: {}'.format(len(test_data)))\n",
    "print('\\n')\n",
    "# 중복 데이터 제거\n",
    "train_data.drop_duplicates(subset=['content'], inplace=True)\n",
    "test_data.drop_duplicates(subset=['content'], inplace=True)\n",
    "print('\\n')\n",
    "# 데이터셋 개수 확인\n",
    "print('중복 제거 후 학습 데이터셋: {}'.format(len(train_data)))\n",
    "print('중복 제거 후 테스트 데이터셋: {}'.format(len(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-small-v3-discriminator and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(35080, 128)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 토큰에 추가할 단어 -> '방탈출'이라는 도메인 지시기에 근거한 용어, 분리되어서는 안 되기 때문에 별도로 추가 작업 진행\n",
    "addword = ['공테', '약공테', '감테', '창공', '갑툭튀', '삐딱', '삑', '꽝', '삑딱쾅', '삑딱쾅', '삑딱', '쫄', '극쫄',\n",
    "            '극극쫄', '쫄팟', '쫄탱', '쫄보', '극', '약탱', '탱쫄', '극극극', '뉴비', '하드캐리', '극혐', '피지컬',\n",
    "            '어거지', '뚝배기', '뚝문', '셀뚝', '억까', '트롤링', '트롤짓', '흙길', '풀길', '꽃길', '풀꽃', '꽃다발',\n",
    "            '꽃밭', '웰메이드', '인생테마', '머글', '방린이', '방유아', '방세포', '방태아', '방탈러', '과몰입러', '옵저버',\n",
    "            '리트', '연방', '혼방', '혼불', '워킹', '워크인', '장치방', '문제방', '직렬', '병렬', '육각형', '볼드', '볼드충', '에바',\n",
    "            '가이드', '조도', '조명', '밝기', '어두움', '인테리어', '비주얼', '소품', '디자인',\n",
    "            '스토리','기승전결','흐름도','결말','서사','이야기','유니버스','전개','시나리오', '개연성', '명료',\n",
    "            '창의성','창의','신선','독특','참신','발상', '연출','짜임','사실감','구현','현실감','현장감', '활동성','활동력','활동량','움직임','반경',\n",
    "            '규모','스케일','볼륨','사이즈','크기','넓이','공간감','분량', '공포','공테','무서움','담력','스릴러',\n",
    "            '문제', '장치', '기계', '센서', '기구', '불친절',\n",
    "            '메르헨', '커튼콜', '카르텔', '소우주', '풀문', '도고', '플래시', '나우히어', '나비효과', '몽중', '가이드라인',\n",
    "            '연출력', '짜임새', '공포도', '공포감', '공포심', '약공테', '문제퀄']\n",
    "\n",
    "# 사전학습된 bert 모델 사용\n",
    "# num_labels 클래스에 대해서 훈련을 하기 위해서 num_labels=3 할당함, problem_type=\"multi_label_classification\" 를 통해서 모델이 다중 레이블 분류에 해당함을 명시\n",
    "model = ElectraForSequenceClassification.from_pretrained(\"monologg/koelectra-small-v3-discriminator\", num_labels=3, problem_type=\"multi_label_classification\")\n",
    "tokenizer = ElectraTokenizer.from_pretrained(\"monologg/koelectra-base-v3-discriminator\")\n",
    "\n",
    "# token에 새로운 단어 추가 \n",
    "tokenizer.add_tokens(addword)\n",
    "# token에 단어 추가후 기존 모델의 임베딩 레이어에 추가한 단어에 대한 임베딩 벡터가 없을 수 있기 때문\n",
    "# 아래 코드를 통해서 토큰의 개수가 변했음을 모델에 알리고 모델의 임베딩 레이어를 조정하여 새로운 토큰을 수용할 수 있게 함\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train content 토큰화\n",
    "tokenized_train_sentences = tokenizer(\n",
    "    list(train_data['content']),\n",
    "    return_tensors=\"pt\",\n",
    "    max_length=128,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    add_special_tokens=True\n",
    ")\n",
    "\n",
    "# test content 토큰화\n",
    "tokenized_test_sentences = tokenizer(\n",
    "    list(test_data['content']),\n",
    "    return_tensors=\"pt\",\n",
    "    max_length=128,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    add_special_tokens=True\n",
    ")\n",
    "\n",
    "# 분류 모델에 넣기 위해서 1차원으로 구성된 세 개의 클래스를 2차원으로 재구성 후 label 로 투입\n",
    "# -1(부정)=0, 0(중립)=1, 1(긍정)=2\n",
    "\n",
    "train_label = []\n",
    "for label in train_data[\"interior\"].values:\n",
    "    if label == -1:\n",
    "        train_label.append([1., 0., 0.])\n",
    "    elif label == 0:\n",
    "        train_label.append([0., 1., 0.])\n",
    "    elif label == 1:\n",
    "        train_label.append([0., 0., 1.])\n",
    "\n",
    "test_label = []\n",
    "for label in test_data['interior'].values:\n",
    "    if label == 0:\n",
    "        test_label.append([0., 1., 0.])\n",
    "    elif label == -1:\n",
    "        test_label.append([1., 0., 0.])\n",
    "    elif label == 1:\n",
    "        test_label.append([0., 0., 1.])\n",
    "\n",
    "# model 에 넣기 위한 dataset 생성 class\n",
    "class CurseDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "        \n",
    "# bert 모델에 데이터가 들어갈 수 있게 만들어 둔 class를 활용하여 train, test dataset 생성\n",
    "train_dataset = CurseDataset(tokenized_train_sentences, train_label)\n",
    "test_dataset = CurseDataset(tokenized_test_sentences, test_label)\n",
    "\n",
    "# hugging face 의 trasformers 라이브러리를 사용하여 모델 훈련시킬 때 사용되는 객체 설정 부분\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = './interior_model/check_point/try_4',    # 모델과 훈련 중 생성되는 파일이 저장될 디렉토리 경로\n",
    "    num_train_epochs = 30,              # 훈련 epoch 수\n",
    "    per_device_train_batch_size = 16,    # 장치에 할당된 훈련 배치 크기\n",
    "    per_device_eval_batch_size = 64,    # 장치에 할당된 평가 배치 크기, 모델을 평가할 때 사용되는 배치 크기\n",
    "    logging_dir = './logs',             # 훈련 중 로그 파일이 저장될 디렉토리\n",
    "    logging_steps = 500,                # 로그 출력 빈도, 500 step에 한 번씩 출력 예정\n",
    "    save_total_limit = 2,               # 체크포인트 파일 저장 제한 수\n",
    ")\n",
    "\n",
    "# hugging face 의 trasformers 라이브러리를 사용하여 모델 훈련하고 관리하는 객체 설정 부분\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_69248/3586665111.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                   \n",
      " 30%|███       | 2239/7350 [10:46<15:23,  5.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2242, 'learning_rate': 4.663978494623656e-05, 'epoch': 2.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_69248/3586665111.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                   \n",
      " 30%|███       | 2239/7350 [12:14<15:23,  5.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0947, 'learning_rate': 4.327956989247312e-05, 'epoch': 4.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_69248/3586665111.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                   \n",
      " 30%|███       | 2239/7350 [13:43<15:23,  5.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0915, 'learning_rate': 3.991935483870968e-05, 'epoch': 6.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_69248/3586665111.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                   \n",
      " 30%|███       | 2239/7350 [15:11<15:23,  5.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0911, 'learning_rate': 3.655913978494624e-05, 'epoch': 8.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_69248/3586665111.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                   \n",
      " 30%|███       | 2239/7350 [16:40<15:23,  5.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0858, 'learning_rate': 3.31989247311828e-05, 'epoch': 10.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_69248/3586665111.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                   \n",
      " 30%|███       | 2239/7350 [18:08<15:23,  5.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0762, 'learning_rate': 2.9838709677419357e-05, 'epoch': 12.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_69248/3586665111.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                   \n",
      " 30%|███       | 2239/7350 [19:37<15:23,  5.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0603, 'learning_rate': 2.6478494623655913e-05, 'epoch': 14.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_69248/3586665111.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                   \n",
      " 30%|███       | 2239/7350 [21:05<15:23,  5.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0485, 'learning_rate': 2.3118279569892472e-05, 'epoch': 16.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_69248/3586665111.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                   \n",
      " 30%|███       | 2239/7350 [22:34<15:23,  5.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0388, 'learning_rate': 1.975806451612903e-05, 'epoch': 18.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_69248/3586665111.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                   \n",
      " 30%|███       | 2239/7350 [24:02<15:23,  5.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0348, 'learning_rate': 1.639784946236559e-05, 'epoch': 20.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_69248/3586665111.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                   \n",
      " 30%|███       | 2239/7350 [25:30<15:23,  5.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0304, 'learning_rate': 1.3037634408602151e-05, 'epoch': 22.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_69248/3586665111.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                   \n",
      " 30%|███       | 2239/7350 [26:59<15:23,  5.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0282, 'learning_rate': 9.67741935483871e-06, 'epoch': 24.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_69248/3586665111.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                   \n",
      " 30%|███       | 2239/7350 [28:27<15:23,  5.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0257, 'learning_rate': 6.317204301075269e-06, 'epoch': 26.21}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_69248/3586665111.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                   \n",
      " 30%|███       | 2239/7350 [29:56<15:23,  5.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0232, 'learning_rate': 2.9569892473118283e-06, 'epoch': 28.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_69248/3586665111.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                   \n",
      "100%|██████████| 7440/7440 [21:55<00:00,  5.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1315.3735, 'train_samples_per_second': 90.157, 'train_steps_per_second': 5.656, 'train_loss': 0.06545364984902002, 'epoch': 30.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=7440, training_loss=0.06545364984902002, metrics={'train_runtime': 1315.3735, 'train_samples_per_second': 90.157, 'train_steps_per_second': 5.656, 'train_loss': 0.06545364984902002, 'epoch': 30.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train 진행\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./interior_model/try_4/interior_tokenizer4/tokenizer_config.json',\n",
       " './interior_model/try_4/interior_tokenizer4/special_tokens_map.json',\n",
       " './interior_model/try_4/interior_tokenizer4/vocab.txt',\n",
       " './interior_model/try_4/interior_tokenizer4/added_tokens.json')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.save_model(\"./interior_model/try_4/interior_model4\")\n",
    "tokenizer.save_pretrained(\"./interior_model/try_4/interior_tokenizer4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# 저장된 모델과 토크나이저를 불러오기\n",
    "\n",
    "model_path = \"./interior_model/try_4/interior_model4\"\n",
    "tokenizer_path = \"./interior_model/try_4/interior_tokenizer4\"\n",
    "\n",
    "model = ElectraForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer = ElectraTokenizer.from_pretrained(tokenizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 951/951 [00:11<00:00, 85.31it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>interior</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>아기자기 테마 살짝 노후 느낌 있다 그렇다 좋다 테마</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>중간 재밌다 마지막 이 테마 뭐 이다 생각</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>아기자기 귀엽다 인태리어 테마</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>순간 테스터 가다 알다 장치 오류 빈번하다 일어나다 위험 보이다 장치 있다 테마 덜...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>첫날 가다 다행히 장치 오류 없다 엄청 일찍 가다 그런 이다 장치 오류 없다 가정 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>나 너무 어렵다 방탈짬바 있다 추천</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>962</th>\n",
       "      <td>인 각자 하다 뿌듯하다 테마</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>첫 디버프로 초반 절다 보다 못 보다 힌트 쓰다 잘 꾸미다 살짝 장치 오류 아쉽다</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964</th>\n",
       "      <td>인 볼륨 압도 히터 방 빵빵하다 다른 테마 궁금</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>965</th>\n",
       "      <td>인 장치 그거 왜 모르다 장치 속다</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>951 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               content  interior  pred\n",
       "0                        아기자기 테마 살짝 노후 느낌 있다 그렇다 좋다 테마         0     0\n",
       "1                              중간 재밌다 마지막 이 테마 뭐 이다 생각         0     0\n",
       "2                                     아기자기 귀엽다 인태리어 테마         1     1\n",
       "3    순간 테스터 가다 알다 장치 오류 빈번하다 일어나다 위험 보이다 장치 있다 테마 덜...        -1     1\n",
       "4    첫날 가다 다행히 장치 오류 없다 엄청 일찍 가다 그런 이다 장치 오류 없다 가정 ...         0     0\n",
       "..                                                 ...       ...   ...\n",
       "961                                나 너무 어렵다 방탈짬바 있다 추천         0     0\n",
       "962                                    인 각자 하다 뿌듯하다 테마         0     0\n",
       "963      첫 디버프로 초반 절다 보다 못 보다 힌트 쓰다 잘 꾸미다 살짝 장치 오류 아쉽다         1     0\n",
       "964                         인 볼륨 압도 히터 방 빵빵하다 다른 테마 궁금         0     0\n",
       "965                                인 장치 그거 왜 모르다 장치 속다         0     0\n",
       "\n",
       "[951 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문장을 입력했을 때, 예측 값을 도출해주는 함수\n",
    "\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "# 함수 정의\n",
    "def classify_text(text):\n",
    "    # 문장을 토큰화하고 모델에 입력으로 전달\n",
    "    text = cleaned_content(text)\n",
    "    text = kiwi_clean(text)\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "    # 소프트맥스 함수를 사용하여 확률값 계산\n",
    "    probabilities = softmax(outputs.logits, dim=1)\n",
    "\n",
    "    # 가장 높은 확률값에 해당하는 클래스 선택\n",
    "    predicted_class = torch.argmax(probabilities).item()\n",
    "\n",
    "    return predicted_class, probabilities\n",
    "\n",
    "def change_num(num):\n",
    "    if num == 0:\n",
    "        return (-1)\n",
    "    elif num == 1:\n",
    "        return 0\n",
    "    elif num == 2:\n",
    "        return 1\n",
    "\n",
    "pred_list = []\n",
    "for sent in tqdm(test_data['content']):\n",
    "    pred, _ = classify_text(sent)\n",
    "    pred_list.append(pred)\n",
    "\n",
    "test_data['pred'] = pred_list\n",
    "test_data['pred'] = test_data['pred'].apply(change_num)\n",
    "test_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0포함 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      0.17      0.29         6\n",
      "           0       1.00      0.99      0.99       854\n",
      "           1       0.86      0.96      0.91        91\n",
      "\n",
      "    accuracy                           0.98       951\n",
      "   macro avg       0.95      0.70      0.73       951\n",
      "weighted avg       0.98      0.98      0.98       951\n",
      "\n",
      "0 제외 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      0.17      0.29         6\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.95      0.96      0.95        91\n",
      "\n",
      "    accuracy                           0.91        97\n",
      "   macro avg       0.65      0.37      0.41        97\n",
      "weighted avg       0.95      0.91      0.91        97\n",
      "\n",
      "문장: 인테리어 최악이네, 평가: 0\n",
      "---------- \n",
      "\n",
      "문장: 인테리어 개쩔어, 평가: 2\n",
      "---------- \n",
      "\n",
      "문장: 인테리어가 안 좋지는 않았어요., 평가: 0\n",
      "---------- \n",
      "\n",
      "문장: 스토리 구려, 평가: 1\n",
      "---------- \n",
      "\n",
      "문장: 활동성은 없는데, 인테리어는 좋네요., 평가: 2\n",
      "---------- \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/bert_electra/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/bert_electra/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/bert_electra/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('0포함', '\\n', classification_report(test_data['interior'], test_data['pred']))\n",
    "test_data2 = test_data[test_data['interior'] != 0]\n",
    "print('0 제외', '\\n', classification_report(test_data2['interior'], test_data2['pred']))\n",
    "\n",
    "test = ['인테리어 최악이네', '인테리어 개쩔어', '인테리어가 안 좋지는 않았어요.', '스토리 구려', '활동성은 없는데, 인테리어는 좋네요.']\n",
    "\n",
    "for sent in test:\n",
    "    pred, _ = classify_text(sent)\n",
    "    print(f'문장: {sent}, 평가: {pred}')\n",
    "    print(\"-\"*10, '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bert_electra",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
