{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/bert_electra/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import ElectraModel, ElectraTokenizer\n",
    "from transformers import ElectraForSequenceClassification\n",
    "from transformers import AutoTokenizer, AutoModelForSemanticSegmentation, TrainingArguments, Trainer\n",
    "\n",
    "import torch\n",
    "\n",
    "import pandas as pd\n",
    "from konlpy.tag import Mecab\n",
    "import re\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1차 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_71768/2028388394.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  story_data['content_id'] = story_data['content_id'].apply(lambda x: x.split(',')[0] if len(str(x)) > 6 else x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "story\n",
      " 0    4461\n",
      " 1     444\n",
      "-1     118\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "train_data story\n",
      " 0    3560\n",
      " 1     363\n",
      "-1      95\n",
      "Name: count, dtype: int64\n",
      "\n",
      " test_data story\n",
      " 0    909\n",
      " 1     78\n",
      "-1     18\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "중복 제거 전 학습 데이터셋: 4018\n",
      "중복 제거 전 테스트 데이터셋: 1005\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "중복 제거 후 학습 데이터셋: 4003\n",
      "중복 제거 후 테스트 데이터셋: 1001\n"
     ]
    }
   ],
   "source": [
    "# labeling 된 데이터 불러오기\n",
    "survey = pd.read_csv(\"./_data/survey.csv\", index_col=0)\n",
    "survey.fillna(0, inplace=True)\n",
    "survey = survey.reset_index()\n",
    "\n",
    "# 데이터 중에서 작업을 하고자 하는 라벨만 가져오기\n",
    "story_data = survey[['content_id', 'story']]\n",
    "\n",
    "# content_id 중에서 댓글이 같이 추가된 데이터 정리\n",
    "story_data['content_id'] = story_data['content_id'].apply(lambda x: x.split(',')[0] if len(str(x)) > 6 else x)\n",
    "\n",
    "# content_id 가 0인 데이터 제외 -> content_id 모두 int type 으로 변경 (추후 Merge 를 위함)\n",
    "story_data = story_data[story_data['content_id'] != 0].reset_index().drop(columns=['index'])\n",
    "story_data['content_id'] = story_data['content_id'].astype(int)\n",
    "\n",
    "# 전체 review data 불러오기\n",
    "review_all = pd.read_csv(\"./_data/reviews.csv\", index_col=0)\n",
    "\n",
    "# 전체 review data 중에서 survey data에 있는 댓글만 가져오기\n",
    "survey_content = review_all.loc[review_all['id'].isin(story_data['content_id'])][['id', 'content']]\n",
    "# merge 를 위해서 id 컬럼명 통일하기\n",
    "survey_content.columns=['content_id', 'content']\n",
    "\n",
    "# 통일된 content_id 를 기반으로 데이터 merge\n",
    "story_data = pd.merge(story_data, survey_content)\n",
    "\n",
    "# 추후 원활한 계산을 위해서 숫자 부분은 모두 int 로 바꿔줌\n",
    "story_data['story'] = story_data['story'].astype(int)\n",
    "\n",
    "# 최소한의 전처리\n",
    "def cleaned_content(text):\n",
    "    d = re.sub('\\n', '. ', text) # 줄바꿈 > .\n",
    "    d = re.sub('[^가-힣0-9a-zA-Z ]{2,}', \".\", d) # 특수문자 두개 이상인거 .으로 변경\n",
    "    return d\n",
    "\n",
    "story_data['content'] = story_data['content'].apply(cleaned_content)\n",
    "\n",
    "final_df = story_data[['content', 'story']]\n",
    "\n",
    "# 라벨별 개수 확인\n",
    "print(final_df['story'].value_counts())\n",
    "print('\\n')\n",
    "train_data = final_df.sample(frac=0.8, random_state=42).reset_index().drop(columns='index')\n",
    "print('train_data', train_data['story'].value_counts())\n",
    "test_data = final_df.drop(train_data.index).reset_index().drop(columns='index')\n",
    "print('\\n', 'test_data', test_data['story'].value_counts())\n",
    "print('\\n')\n",
    "# 중복 데이터 제거(데이터 분리 후 중복이 생길 수 있어서 데이터 분리 후 중복 데이터 처리 진행)\n",
    "\n",
    "# 데이터셋 개수 확인\n",
    "print('중복 제거 전 학습 데이터셋: {}'.format(len(train_data)))\n",
    "print('중복 제거 전 테스트 데이터셋: {}'.format(len(test_data)))\n",
    "print('\\n')\n",
    "# 중복 데이터 제거\n",
    "train_data.drop_duplicates(subset=['content'], inplace=True)\n",
    "test_data.drop_duplicates(subset=['content'], inplace=True)\n",
    "print('\\n')\n",
    "# 데이터셋 개수 확인\n",
    "print('중복 제거 후 학습 데이터셋: {}'.format(len(train_data)))\n",
    "print('중복 제거 후 테스트 데이터셋: {}'.format(len(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-small-v3-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(35080, 128)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 토큰에 추가할 단어 -> '방탈출'이라는 도메인 지시기에 근거한 용어, 분리되어서는 안 되기 때문에 별도로 추가 작업 진행\n",
    "addword = ['공테', '약공테', '감테', '창공', '갑툭튀', '삐딱', '삑', '꽝', '삑딱쾅', '삑딱쾅', '삑딱', '쫄', '극쫄',\n",
    "            '극극쫄', '쫄팟', '쫄탱', '쫄보', '극', '약탱', '탱쫄', '극극극', '뉴비', '하드캐리', '극혐', '피지컬',\n",
    "            '어거지', '뚝배기', '뚝문', '셀뚝', '억까', '트롤링', '트롤짓', '흙길', '풀길', '꽃길', '풀꽃', '꽃다발',\n",
    "            '꽃밭', '웰메이드', '인생테마', '머글', '방린이', '방유아', '방세포', '방태아', '방탈러', '과몰입러', '옵저버',\n",
    "            '리트', '연방', '혼방', '혼불', '워킹', '워크인', '장치방', '문제방', '직렬', '병렬', '육각형', '볼드', '볼드충', '에바',\n",
    "            '가이드', '조도', '조명', '밝기', '어두움', '인테리어', '비주얼', '소품', '디자인',\n",
    "            '스토리','기승전결','흐름도','결말','서사','이야기','유니버스','전개','시나리오', '개연성', '명료',\n",
    "            '창의성','창의','신선','독특','참신','발상', '연출','짜임','사실감','구현','현실감','현장감', '활동성','활동력','활동량','움직임','반경',\n",
    "            '규모','스케일','볼륨','사이즈','크기','넓이','공간감','분량', '공포','공테','무서움','담력','스릴러',\n",
    "            '문제', '장치', '기계', '센서', '기구', '불친절',\n",
    "            '메르헨', '커튼콜', '카르텔', '소우주', '풀문', '도고', '플래시', '나우히어', '나비효과', '몽중', '가이드라인',\n",
    "            '연출력', '짜임새', '공포도', '공포감', '공포심', '약공테', '문제퀄']\n",
    "\n",
    "# 사전학습된 bert 모델 사용\n",
    "# num_labels 클래스에 대해서 훈련을 하기 위해서 num_labels=3 할당함, problem_type=\"multi_label_classification\" 를 통해서 모델이 다중 레이블 분류에 해당함을 명시\n",
    "model = ElectraForSequenceClassification.from_pretrained(\"monologg/koelectra-small-v3-discriminator\", num_labels=3, problem_type=\"multi_label_classification\")\n",
    "tokenizer = ElectraTokenizer.from_pretrained(\"monologg/koelectra-base-v3-discriminator\")\n",
    "\n",
    "# token에 새로운 단어 추가 \n",
    "tokenizer.add_tokens(addword)\n",
    "# token에 단어 추가후 기존 모델의 임베딩 레이어에 추가한 단어에 대한 임베딩 벡터가 없을 수 있기 때문\n",
    "# 아래 코드를 통해서 토큰의 개수가 변했음을 모델에 알리고 모델의 임베딩 레이어를 조정하여 새로운 토큰을 수용할 수 있게 함\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train content 토큰화\n",
    "tokenized_train_sentences = tokenizer(\n",
    "    list(train_data['content']),\n",
    "    return_tensors=\"pt\",\n",
    "    max_length=128,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    add_special_tokens=True\n",
    ")\n",
    "\n",
    "# test content 토큰화\n",
    "tokenized_test_sentences = tokenizer(\n",
    "    list(test_data['content']),\n",
    "    return_tensors=\"pt\",\n",
    "    max_length=128,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    add_special_tokens=True\n",
    ")\n",
    "\n",
    "# 분류 모델에 넣기 위해서 1차원으로 구성된 세 개의 클래스를 2차원으로 재구성 후 label 로 투입\n",
    "# -1(부정)=0, 0(중립)=1, 1(긍정)=2\n",
    "\n",
    "train_label = []\n",
    "for label in train_data[\"story\"].values:\n",
    "    if label == -1:\n",
    "        train_label.append([1., 0., 0.])\n",
    "    elif label == 0:\n",
    "        train_label.append([0., 1., 0.])\n",
    "    elif label == 1:\n",
    "        train_label.append([0., 0., 1.])\n",
    "\n",
    "test_label = []\n",
    "for label in test_data['story'].values:\n",
    "    if label == 0:\n",
    "        test_label.append([0., 1., 0.])\n",
    "    elif label == -1:\n",
    "        test_label.append([1., 0., 0.])\n",
    "    elif label == 1:\n",
    "        test_label.append([0., 0., 1.])\n",
    "\n",
    "# model 에 넣기 위한 dataset 생성 class\n",
    "class CurseDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "        \n",
    "# bert 모델에 데이터가 들어갈 수 있게 만들어 둔 class를 활용하여 train, test dataset 생성\n",
    "train_dataset = CurseDataset(tokenized_train_sentences, train_label)\n",
    "test_dataset = CurseDataset(tokenized_test_sentences, test_label)\n",
    "\n",
    "# hugging face 의 trasformers 라이브러리를 사용하여 모델 훈련시킬 때 사용되는 객체 설정 부분\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = './story_model/check_point/try_1',    # 모델과 훈련 중 생성되는 파일이 저장될 디렉토리 경로\n",
    "    num_train_epochs = 10,              # 훈련 epoch 수\n",
    "    per_device_train_batch_size = 16,    # 장치에 할당된 훈련 배치 크기\n",
    "    per_device_eval_batch_size = 64,    # 장치에 할당된 평가 배치 크기, 모델을 평가할 때 사용되는 배치 크기\n",
    "    logging_dir = './logs',             # 훈련 중 로그 파일이 저장될 디렉토리\n",
    "    logging_steps = 500,                # 로그 출력 빈도, 500 step에 한 번씩 출력 예정\n",
    "    save_total_limit = 2,               # 체크포인트 파일 저장 제한 수\n",
    ")\n",
    "\n",
    "# hugging face 의 trasformers 라이브러리를 사용하여 모델 훈련하고 관리하는 객체 설정 부분\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2510 [00:00<?, ?it/s]/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_70839/43764513.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 20%|█▉        | 500/2510 [02:03<08:20,  4.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2549, 'learning_rate': 4.00398406374502e-05, 'epoch': 1.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_70839/43764513.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 40%|███▉      | 1000/2510 [04:04<05:56,  4.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1246, 'learning_rate': 3.00796812749004e-05, 'epoch': 3.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_70839/43764513.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 60%|█████▉    | 1500/2510 [06:05<04:04,  4.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1236, 'learning_rate': 2.01195219123506e-05, 'epoch': 5.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_70839/43764513.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 80%|███████▉  | 2000/2510 [08:06<02:02,  4.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1192, 'learning_rate': 1.0159362549800798e-05, 'epoch': 7.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_70839/43764513.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "100%|█████████▉| 2500/2510 [10:07<00:02,  4.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1171, 'learning_rate': 1.99203187250996e-07, 'epoch': 9.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_70839/43764513.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "100%|██████████| 2510/2510 [10:10<00:00,  4.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 610.6622, 'train_samples_per_second': 65.552, 'train_steps_per_second': 4.11, 'train_loss': 0.14768907919347998, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2510, training_loss=0.14768907919347998, metrics={'train_runtime': 610.6622, 'train_samples_per_second': 65.552, 'train_steps_per_second': 4.11, 'train_loss': 0.14768907919347998, 'epoch': 10.0})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train 진행\n",
    "trainer.train() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./story_model/try_1/story_tokenizer1/tokenizer_config.json',\n",
       " './story_model/try_1/story_tokenizer1/special_tokens_map.json',\n",
       " './story_model/try_1/story_tokenizer1/vocab.txt',\n",
       " './story_model/try_1/story_tokenizer1/added_tokens.json')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.save_model(\"./story_model/try_1/story_model1\")\n",
    "tokenizer.save_pretrained(\"./story_model/try_1/story_tokenizer1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# 저장된 모델과 토크나이저를 불러오기\n",
    "\n",
    "model_path = \"./story_model/try_1/story_model1\"\n",
    "tokenizer_path = \"./story_model/try_1/story_tokenizer1\"\n",
    "\n",
    "model = ElectraForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer = ElectraTokenizer.from_pretrained(tokenizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1001/1001 [00:15<00:00, 62.97it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>story</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#1415_20221128_3인. 흐음.잘 열어보지 않으면</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>난.바보야.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>들어가자마자 커피향이 씨게 낫다 좋앗다 하지만 인테리어는 그냥그랫다. 풀정도 되는듯.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3인. 스토리가 잘 감이 안 잡힌다!</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.5/3인. 활동성 있음.추락조심</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>나에겐 너무 어려웠던. 방탈짬바 있는 분들에게 추천</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>2021. 12. 26. (3인) 각자 1인분씩 하고 뿌듯했던 테마.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>첫방 디버프로 초반에 절어버림. 볼것도 못보고 힌트썼는데 잘꾸며놓았다 . 살짝 장치...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>#5 - 2인 - 볼륨에 압도됨 - 히터도 방마다 빵빵함 - 다른 테마도 궁금해짐</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>265, 2인, 장치. 그걸 왜 몰랐냐. 장치에 속지 말자</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1001 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content  story  pred\n",
       "0                      #1415_20221128_3인. 흐음.잘 열어보지 않으면      0     0\n",
       "1                                                난.바보야.      0     0\n",
       "2       들어가자마자 커피향이 씨게 낫다 좋앗다 하지만 인테리어는 그냥그랫다. 풀정도 되는듯.      0     0\n",
       "3                                  3인. 스토리가 잘 감이 안 잡힌다!     -1     1\n",
       "4                                   1.5/3인. 활동성 있음.추락조심      0     0\n",
       "...                                                 ...    ...   ...\n",
       "999                        나에겐 너무 어려웠던. 방탈짬바 있는 분들에게 추천      0     0\n",
       "1000             2021. 12. 26. (3인) 각자 1인분씩 하고 뿌듯했던 테마.      0     0\n",
       "1001  첫방 디버프로 초반에 절어버림. 볼것도 못보고 힌트썼는데 잘꾸며놓았다 . 살짝 장치...      0     0\n",
       "1002      #5 - 2인 - 볼륨에 압도됨 - 히터도 방마다 빵빵함 - 다른 테마도 궁금해짐      0     0\n",
       "1003                   265, 2인, 장치. 그걸 왜 몰랐냐. 장치에 속지 말자      0     0\n",
       "\n",
       "[1001 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문장을 입력했을 때, 예측 값을 도출해주는 함수\n",
    "\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "# 함수 정의\n",
    "def classify_text(text):\n",
    "    # 문장을 토큰화하고 모델에 입력으로 전달\n",
    "    text = cleaned_content(text)\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "    # 소프트맥스 함수를 사용하여 확률값 계산\n",
    "    probabilities = softmax(outputs.logits, dim=1)\n",
    "\n",
    "    # 가장 높은 확률값에 해당하는 클래스 선택\n",
    "    predicted_class = torch.argmax(probabilities).item()\n",
    "\n",
    "    return predicted_class, probabilities\n",
    "\n",
    "def change_num(num):\n",
    "    if num == 0:\n",
    "        return (-1)\n",
    "    elif num == 1:\n",
    "        return 0\n",
    "    elif num == 2:\n",
    "        return 1\n",
    "\n",
    "pred_list = []\n",
    "for sent in tqdm(test_data['content']):\n",
    "    pred, _ = classify_text(sent)\n",
    "    pred_list.append(pred)\n",
    "\n",
    "test_data['pred'] = pred_list\n",
    "test_data['pred'] = test_data['pred'].apply(change_num)\n",
    "test_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 라벨 수 story\n",
      " 0    4461\n",
      " 1     444\n",
      "-1     118\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "train_data 라벨 수 story\n",
      " 0    3545\n",
      " 1     363\n",
      "-1      95\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "test_data 라벨 수 story\n",
      " 0    905\n",
      " 1     78\n",
      "-1     18\n",
      "Name: count, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('전체 라벨 수', final_df['story'].value_counts(), '\\n')\n",
    "print('train_data 라벨 수', train_data['story'].value_counts(), '\\n')\n",
    "print('test_data 라벨 수', test_data['story'].value_counts(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0포함 예측률 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00        18\n",
      "           0       0.99      0.98      0.99       905\n",
      "           1       0.67      0.92      0.77        78\n",
      "\n",
      "    accuracy                           0.96      1001\n",
      "   macro avg       0.55      0.63      0.59      1001\n",
      "weighted avg       0.95      0.96      0.95      1001\n",
      "\n",
      "0제외 예측률 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00        18\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.81      0.92      0.86        78\n",
      "\n",
      "    accuracy                           0.75        96\n",
      "   macro avg       0.27      0.31      0.29        96\n",
      "weighted avg       0.66      0.75      0.70        96\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/bert_electra/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/bert_electra/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/bert_electra/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/bert_electra/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/bert_electra/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/bert_electra/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/bert_electra/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/bert_electra/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/bert_electra/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('0포함 예측률', '\\n', classification_report(test_data['story'], test_data['pred']))\n",
    "test_data2 = test_data[test_data['story'] != 0]\n",
    "print('0제외 예측률', '\\n', classification_report(test_data2['story'], test_data2['pred']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장: 스토리 대박, 평가: 2\n",
      "----------\n",
      "문장: 스토리 좋아요, 평가: 2\n",
      "----------\n",
      "문장: 스토리 개좋음, 평가: 2\n",
      "----------\n",
      "문장: 서비스 무슨 일, 평가: 1\n",
      "----------\n",
      "문장: 이야기 재밌어요, 평가: 1\n",
      "----------\n",
      "문장: 불친절함, 평가: 1\n",
      "----------\n",
      "문장: 스토리 쓰레기네, 평가: 2\n",
      "----------\n",
      "문장: 서비스는 좋은데 재미없었어요., 평가: 1\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "test = [\n",
    "    '스토리 대박',\n",
    "    '스토리 좋아요',\n",
    "    '스토리 개좋음',\n",
    "    '서비스 무슨 일',\n",
    "    '이야기 재밌어요',\n",
    "    '불친절함',\n",
    "    '스토리 쓰레기네',\n",
    "    '서비스는 좋은데 재미없었어요.',\n",
    "]\n",
    "\n",
    "for sent in test:\n",
    "    pred, _ = classify_text(sent)\n",
    "    print(f'문장: {sent}, 평가: {pred}')\n",
    "    print(\"-\"*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1차 모델 결과\n",
    "- 아쉬움"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2차 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_72976/2028388394.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  story_data['content_id'] = story_data['content_id'].apply(lambda x: x.split(',')[0] if len(str(x)) > 6 else x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "story\n",
      " 0    4461\n",
      " 1     444\n",
      "-1     118\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "train_data story\n",
      " 0    3560\n",
      " 1     363\n",
      "-1      95\n",
      "Name: count, dtype: int64\n",
      "\n",
      " test_data story\n",
      " 0    909\n",
      " 1     78\n",
      "-1     18\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "중복 제거 전 학습 데이터셋: 4018\n",
      "중복 제거 전 테스트 데이터셋: 1005\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "중복 제거 후 학습 데이터셋: 4003\n",
      "중복 제거 후 테스트 데이터셋: 1001\n"
     ]
    }
   ],
   "source": [
    "# labeling 된 데이터 불러오기\n",
    "survey = pd.read_csv(\"./_data/survey.csv\", index_col=0)\n",
    "survey.fillna(0, inplace=True)\n",
    "survey = survey.reset_index()\n",
    "\n",
    "# 데이터 중에서 작업을 하고자 하는 라벨만 가져오기\n",
    "story_data = survey[['content_id', 'story']]\n",
    "\n",
    "# content_id 중에서 댓글이 같이 추가된 데이터 정리\n",
    "story_data['content_id'] = story_data['content_id'].apply(lambda x: x.split(',')[0] if len(str(x)) > 6 else x)\n",
    "\n",
    "# content_id 가 0인 데이터 제외 -> content_id 모두 int type 으로 변경 (추후 Merge 를 위함)\n",
    "story_data = story_data[story_data['content_id'] != 0].reset_index().drop(columns=['index'])\n",
    "story_data['content_id'] = story_data['content_id'].astype(int)\n",
    "\n",
    "# 전체 review data 불러오기\n",
    "review_all = pd.read_csv(\"./_data/reviews.csv\", index_col=0)\n",
    "\n",
    "# 전체 review data 중에서 survey data에 있는 댓글만 가져오기\n",
    "survey_content = review_all.loc[review_all['id'].isin(story_data['content_id'])][['id', 'content']]\n",
    "# merge 를 위해서 id 컬럼명 통일하기\n",
    "survey_content.columns=['content_id', 'content']\n",
    "\n",
    "# 통일된 content_id 를 기반으로 데이터 merge\n",
    "story_data = pd.merge(story_data, survey_content)\n",
    "\n",
    "# 추후 원활한 계산을 위해서 숫자 부분은 모두 int 로 바꿔줌\n",
    "story_data['story'] = story_data['story'].astype(int)\n",
    "\n",
    "# 최소한의 전처리\n",
    "def cleaned_content(text):\n",
    "    d = re.sub('\\n', '. ', text) # 줄바꿈 > .\n",
    "    d = re.sub('[^가-힣0-9a-zA-Z ]{2,}', \".\", d) # 특수문자 두개 이상인거 .으로 변경\n",
    "    return d\n",
    "\n",
    "story_data['content'] = story_data['content'].apply(cleaned_content)\n",
    "\n",
    "final_df = story_data[['content', 'story']]\n",
    "\n",
    "# 라벨별 개수 확인\n",
    "print(final_df['story'].value_counts())\n",
    "print('\\n')\n",
    "train_data = final_df.sample(frac=0.8, random_state=42).reset_index().drop(columns='index')\n",
    "print('train_data', train_data['story'].value_counts())\n",
    "test_data = final_df.drop(train_data.index).reset_index().drop(columns='index')\n",
    "print('\\n', 'test_data', test_data['story'].value_counts())\n",
    "print('\\n')\n",
    "# 중복 데이터 제거(데이터 분리 후 중복이 생길 수 있어서 데이터 분리 후 중복 데이터 처리 진행)\n",
    "\n",
    "# 데이터셋 개수 확인\n",
    "print('중복 제거 전 학습 데이터셋: {}'.format(len(train_data)))\n",
    "print('중복 제거 전 테스트 데이터셋: {}'.format(len(test_data)))\n",
    "print('\\n')\n",
    "# 중복 데이터 제거\n",
    "train_data.drop_duplicates(subset=['content'], inplace=True)\n",
    "test_data.drop_duplicates(subset=['content'], inplace=True)\n",
    "print('\\n')\n",
    "# 데이터셋 개수 확인\n",
    "print('중복 제거 후 학습 데이터셋: {}'.format(len(train_data)))\n",
    "print('중복 제거 후 테스트 데이터셋: {}'.format(len(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-small-v3-discriminator and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(35080, 128)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 토큰에 추가할 단어 -> '방탈출'이라는 도메인 지시기에 근거한 용어, 분리되어서는 안 되기 때문에 별도로 추가 작업 진행\n",
    "addword = ['공테', '약공테', '감테', '창공', '갑툭튀', '삐딱', '삑', '꽝', '삑딱쾅', '삑딱쾅', '삑딱', '쫄', '극쫄',\n",
    "            '극극쫄', '쫄팟', '쫄탱', '쫄보', '극', '약탱', '탱쫄', '극극극', '뉴비', '하드캐리', '극혐', '피지컬',\n",
    "            '어거지', '뚝배기', '뚝문', '셀뚝', '억까', '트롤링', '트롤짓', '흙길', '풀길', '꽃길', '풀꽃', '꽃다발',\n",
    "            '꽃밭', '웰메이드', '인생테마', '머글', '방린이', '방유아', '방세포', '방태아', '방탈러', '과몰입러', '옵저버',\n",
    "            '리트', '연방', '혼방', '혼불', '워킹', '워크인', '장치방', '문제방', '직렬', '병렬', '육각형', '볼드', '볼드충', '에바',\n",
    "            '가이드', '조도', '조명', '밝기', '어두움', '인테리어', '비주얼', '소품', '디자인',\n",
    "            '스토리','기승전결','흐름도','결말','서사','이야기','유니버스','전개','시나리오', '개연성', '명료',\n",
    "            '창의성','창의','신선','독특','참신','발상', '연출','짜임','사실감','구현','현실감','현장감', '활동성','활동력','활동량','움직임','반경',\n",
    "            '규모','스케일','볼륨','사이즈','크기','넓이','공간감','분량', '공포','공테','무서움','담력','스릴러',\n",
    "            '문제', '장치', '기계', '센서', '기구', '불친절',\n",
    "            '메르헨', '커튼콜', '카르텔', '소우주', '풀문', '도고', '플래시', '나우히어', '나비효과', '몽중', '가이드라인',\n",
    "            '연출력', '짜임새', '공포도', '공포감', '공포심', '약공테', '문제퀄']\n",
    "\n",
    "# 사전학습된 bert 모델 사용\n",
    "# num_labels 클래스에 대해서 훈련을 하기 위해서 num_labels=3 할당함, problem_type=\"multi_label_classification\" 를 통해서 모델이 다중 레이블 분류에 해당함을 명시\n",
    "model = ElectraForSequenceClassification.from_pretrained(\"monologg/koelectra-small-v3-discriminator\", num_labels=3, problem_type=\"multi_label_classification\")\n",
    "tokenizer = ElectraTokenizer.from_pretrained(\"monologg/koelectra-base-v3-discriminator\")\n",
    "\n",
    "# token에 새로운 단어 추가 \n",
    "tokenizer.add_tokens(addword)\n",
    "# token에 단어 추가후 기존 모델의 임베딩 레이어에 추가한 단어에 대한 임베딩 벡터가 없을 수 있기 때문\n",
    "# 아래 코드를 통해서 토큰의 개수가 변했음을 모델에 알리고 모델의 임베딩 레이어를 조정하여 새로운 토큰을 수용할 수 있게 함\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train content 토큰화\n",
    "tokenized_train_sentences = tokenizer(\n",
    "    list(train_data['content']),\n",
    "    return_tensors=\"pt\",\n",
    "    max_length=128,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    add_special_tokens=True\n",
    ")\n",
    "\n",
    "# test content 토큰화\n",
    "tokenized_test_sentences = tokenizer(\n",
    "    list(test_data['content']),\n",
    "    return_tensors=\"pt\",\n",
    "    max_length=128,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    add_special_tokens=True\n",
    ")\n",
    "\n",
    "# 분류 모델에 넣기 위해서 1차원으로 구성된 세 개의 클래스를 2차원으로 재구성 후 label 로 투입\n",
    "# -1(부정)=0, 0(중립)=1, 1(긍정)=2\n",
    "\n",
    "train_label = []\n",
    "for label in train_data[\"story\"].values:\n",
    "    if label == -1:\n",
    "        train_label.append([1., 0., 0.])\n",
    "    elif label == 0:\n",
    "        train_label.append([0., 1., 0.])\n",
    "    elif label == 1:\n",
    "        train_label.append([0., 0., 1.])\n",
    "\n",
    "test_label = []\n",
    "for label in test_data['story'].values:\n",
    "    if label == 0:\n",
    "        test_label.append([0., 1., 0.])\n",
    "    elif label == -1:\n",
    "        test_label.append([1., 0., 0.])\n",
    "    elif label == 1:\n",
    "        test_label.append([0., 0., 1.])\n",
    "\n",
    "# model 에 넣기 위한 dataset 생성 class\n",
    "class CurseDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "        \n",
    "# bert 모델에 데이터가 들어갈 수 있게 만들어 둔 class를 활용하여 train, test dataset 생성\n",
    "train_dataset = CurseDataset(tokenized_train_sentences, train_label)\n",
    "test_dataset = CurseDataset(tokenized_test_sentences, test_label)\n",
    "\n",
    "# hugging face 의 trasformers 라이브러리를 사용하여 모델 훈련시킬 때 사용되는 객체 설정 부분\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = './story_model/check_point/try_2',    # 모델과 훈련 중 생성되는 파일이 저장될 디렉토리 경로\n",
    "    num_train_epochs = 15,              # 훈련 epoch 수\n",
    "    per_device_train_batch_size = 16,    # 장치에 할당된 훈련 배치 크기\n",
    "    per_device_eval_batch_size = 64,    # 장치에 할당된 평가 배치 크기, 모델을 평가할 때 사용되는 배치 크기\n",
    "    logging_dir = './logs',             # 훈련 중 로그 파일이 저장될 디렉토리\n",
    "    logging_steps = 500,                # 로그 출력 빈도, 500 step에 한 번씩 출력 예정\n",
    "    save_total_limit = 2,               # 체크포인트 파일 저장 제한 수\n",
    ")\n",
    "\n",
    "# hugging face 의 trasformers 라이브러리를 사용하여 모델 훈련하고 관리하는 객체 설정 부분\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3765 [00:00<?, ?it/s]/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_71881/2899839487.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 13%|█▎        | 500/3765 [02:02<13:11,  4.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2562, 'learning_rate': 4.335989375830013e-05, 'epoch': 1.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_71881/2899839487.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 27%|██▋       | 1000/3765 [04:02<11:16,  4.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1235, 'learning_rate': 3.671978751660027e-05, 'epoch': 3.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_71881/2899839487.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 40%|███▉      | 1500/3765 [06:03<09:03,  4.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1281, 'learning_rate': 3.00796812749004e-05, 'epoch': 5.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_71881/2899839487.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 53%|█████▎    | 2000/3765 [08:04<07:03,  4.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1229, 'learning_rate': 2.3439575033200534e-05, 'epoch': 7.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_71881/2899839487.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 66%|██████▋   | 2500/3765 [10:04<05:06,  4.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1208, 'learning_rate': 1.6799468791500664e-05, 'epoch': 9.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_71881/2899839487.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 80%|███████▉  | 3000/3765 [12:05<03:02,  4.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1091, 'learning_rate': 1.0159362549800798e-05, 'epoch': 11.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_71881/2899839487.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 93%|█████████▎| 3500/3765 [14:05<01:03,  4.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0957, 'learning_rate': 3.51925630810093e-06, 'epoch': 13.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_71881/2899839487.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "100%|██████████| 3765/3765 [15:09<00:00,  4.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 909.9668, 'train_samples_per_second': 65.986, 'train_steps_per_second': 4.138, 'train_loss': 0.13310016008962197, 'epoch': 15.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3765, training_loss=0.13310016008962197, metrics={'train_runtime': 909.9668, 'train_samples_per_second': 65.986, 'train_steps_per_second': 4.138, 'train_loss': 0.13310016008962197, 'epoch': 15.0})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train 진행\n",
    "trainer.train() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./story_model/try_2/story_tokenizer2/tokenizer_config.json',\n",
       " './story_model/try_2/story_tokenizer2/special_tokens_map.json',\n",
       " './story_model/try_2/story_tokenizer2/vocab.txt',\n",
       " './story_model/try_2/story_tokenizer2/added_tokens.json')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.save_model(\"./story_model/try_2/story_model2\")\n",
    "tokenizer.save_pretrained(\"./story_model/try_2/story_tokenizer2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# 저장된 모델과 토크나이저를 불러오기\n",
    "\n",
    "model_path = \"./story_model/try_2/story_model2\"\n",
    "tokenizer_path = \"./story_model/try_2/story_tokenizer2\"\n",
    "\n",
    "model = ElectraForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer = ElectraTokenizer.from_pretrained(tokenizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1001/1001 [00:15<00:00, 62.89it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>story</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#1415_20221128_3인. 흐음.잘 열어보지 않으면</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>난.바보야.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>들어가자마자 커피향이 씨게 낫다 좋앗다 하지만 인테리어는 그냥그랫다. 풀정도 되는듯.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3인. 스토리가 잘 감이 안 잡힌다!</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.5/3인. 활동성 있음.추락조심</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>나에겐 너무 어려웠던. 방탈짬바 있는 분들에게 추천</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>2021. 12. 26. (3인) 각자 1인분씩 하고 뿌듯했던 테마.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>첫방 디버프로 초반에 절어버림. 볼것도 못보고 힌트썼는데 잘꾸며놓았다 . 살짝 장치...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>#5 - 2인 - 볼륨에 압도됨 - 히터도 방마다 빵빵함 - 다른 테마도 궁금해짐</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>265, 2인, 장치. 그걸 왜 몰랐냐. 장치에 속지 말자</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1001 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content  story  pred\n",
       "0                      #1415_20221128_3인. 흐음.잘 열어보지 않으면      0     0\n",
       "1                                                난.바보야.      0     0\n",
       "2       들어가자마자 커피향이 씨게 낫다 좋앗다 하지만 인테리어는 그냥그랫다. 풀정도 되는듯.      0     0\n",
       "3                                  3인. 스토리가 잘 감이 안 잡힌다!     -1     1\n",
       "4                                   1.5/3인. 활동성 있음.추락조심      0     0\n",
       "...                                                 ...    ...   ...\n",
       "999                        나에겐 너무 어려웠던. 방탈짬바 있는 분들에게 추천      0     0\n",
       "1000             2021. 12. 26. (3인) 각자 1인분씩 하고 뿌듯했던 테마.      0     0\n",
       "1001  첫방 디버프로 초반에 절어버림. 볼것도 못보고 힌트썼는데 잘꾸며놓았다 . 살짝 장치...      0     0\n",
       "1002      #5 - 2인 - 볼륨에 압도됨 - 히터도 방마다 빵빵함 - 다른 테마도 궁금해짐      0     0\n",
       "1003                   265, 2인, 장치. 그걸 왜 몰랐냐. 장치에 속지 말자      0     0\n",
       "\n",
       "[1001 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문장을 입력했을 때, 예측 값을 도출해주는 함수\n",
    "\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "# 함수 정의\n",
    "def classify_text(text):\n",
    "    # 문장을 토큰화하고 모델에 입력으로 전달\n",
    "    text = cleaned_content(text)\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "    # 소프트맥스 함수를 사용하여 확률값 계산\n",
    "    probabilities = softmax(outputs.logits, dim=1)\n",
    "\n",
    "    # 가장 높은 확률값에 해당하는 클래스 선택\n",
    "    predicted_class = torch.argmax(probabilities).item()\n",
    "\n",
    "    return predicted_class, probabilities\n",
    "\n",
    "def change_num(num):\n",
    "    if num == 0:\n",
    "        return (-1)\n",
    "    elif num == 1:\n",
    "        return 0\n",
    "    elif num == 2:\n",
    "        return 1\n",
    "\n",
    "pred_list = []\n",
    "for sent in tqdm(test_data['content']):\n",
    "    pred, _ = classify_text(sent)\n",
    "    pred_list.append(pred)\n",
    "\n",
    "test_data['pred'] = pred_list\n",
    "test_data['pred'] = test_data['pred'].apply(change_num)\n",
    "test_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 라벨 수 story\n",
      " 0    4461\n",
      " 1     444\n",
      "-1     118\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "train_data 라벨 수 story\n",
      " 0    3545\n",
      " 1     363\n",
      "-1      95\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "test_data 라벨 수 story\n",
      " 0    905\n",
      " 1     78\n",
      "-1     18\n",
      "Name: count, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('전체 라벨 수', final_df['story'].value_counts(), '\\n')\n",
    "print('train_data 라벨 수', train_data['story'].value_counts(), '\\n')\n",
    "print('test_data 라벨 수', test_data['story'].value_counts(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0포함 예측률 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00        18\n",
      "           0       0.99      0.98      0.99       905\n",
      "           1       0.70      0.94      0.80        78\n",
      "\n",
      "    accuracy                           0.96      1001\n",
      "   macro avg       0.56      0.64      0.60      1001\n",
      "weighted avg       0.95      0.96      0.95      1001\n",
      "\n",
      "0제외 예측률 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00        18\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.84      0.94      0.88        78\n",
      "\n",
      "    accuracy                           0.76        96\n",
      "   macro avg       0.28      0.31      0.29        96\n",
      "weighted avg       0.68      0.76      0.72        96\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/bert_electra/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/bert_electra/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/bert_electra/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/bert_electra/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/bert_electra/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/bert_electra/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/bert_electra/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/bert_electra/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/bert_electra/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('0포함 예측률', '\\n', classification_report(test_data['story'], test_data['pred']))\n",
    "test_data2 = test_data[test_data['story'] != 0]\n",
    "print('0제외 예측률', '\\n', classification_report(test_data2['story'], test_data2['pred']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장: 스토리 대박, 평가: 2\n",
      "----------\n",
      "문장: 스토리 좋아요, 평가: 2\n",
      "----------\n",
      "문장: 스토리 개좋음, 평가: 2\n",
      "----------\n",
      "문장: 서비스 무슨 일, 평가: 1\n",
      "----------\n",
      "문장: 이야기 재밌어요, 평가: 2\n",
      "----------\n",
      "문장: 불친절함, 평가: 1\n",
      "----------\n",
      "문장: 스토리 쓰레기네, 평가: 2\n",
      "----------\n",
      "문장: 서비스는 좋은데 재미없었어요., 평가: 1\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "test = [\n",
    "    '스토리 대박',\n",
    "    '스토리 좋아요',\n",
    "    '스토리 개좋음',\n",
    "    '서비스 무슨 일',\n",
    "    '이야기 재밌어요',\n",
    "    '불친절함',\n",
    "    '스토리 쓰레기네',\n",
    "    '서비스는 좋은데 재미없었어요.',\n",
    "]\n",
    "\n",
    "for sent in test:\n",
    "    pred, _ = classify_text(sent)\n",
    "    print(f'문장: {sent}, 평가: {pred}')\n",
    "    print(\"-\"*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3차 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_74868/2028388394.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  story_data['content_id'] = story_data['content_id'].apply(lambda x: x.split(',')[0] if len(str(x)) > 6 else x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "story\n",
      " 0    4461\n",
      " 1     444\n",
      "-1     118\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "train_data story\n",
      " 0    3560\n",
      " 1     363\n",
      "-1      95\n",
      "Name: count, dtype: int64\n",
      "\n",
      " test_data story\n",
      " 0    909\n",
      " 1     78\n",
      "-1     18\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "중복 제거 전 학습 데이터셋: 4018\n",
      "중복 제거 전 테스트 데이터셋: 1005\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "중복 제거 후 학습 데이터셋: 4003\n",
      "중복 제거 후 테스트 데이터셋: 1001\n"
     ]
    }
   ],
   "source": [
    "# labeling 된 데이터 불러오기\n",
    "survey = pd.read_csv(\"./_data/survey.csv\", index_col=0)\n",
    "survey.fillna(0, inplace=True)\n",
    "survey = survey.reset_index()\n",
    "\n",
    "# 데이터 중에서 작업을 하고자 하는 라벨만 가져오기\n",
    "story_data = survey[['content_id', 'story']]\n",
    "\n",
    "# content_id 중에서 댓글이 같이 추가된 데이터 정리\n",
    "story_data['content_id'] = story_data['content_id'].apply(lambda x: x.split(',')[0] if len(str(x)) > 6 else x)\n",
    "\n",
    "# content_id 가 0인 데이터 제외 -> content_id 모두 int type 으로 변경 (추후 Merge 를 위함)\n",
    "story_data = story_data[story_data['content_id'] != 0].reset_index().drop(columns=['index'])\n",
    "story_data['content_id'] = story_data['content_id'].astype(int)\n",
    "\n",
    "# 전체 review data 불러오기\n",
    "review_all = pd.read_csv(\"./_data/reviews.csv\", index_col=0)\n",
    "\n",
    "# 전체 review data 중에서 survey data에 있는 댓글만 가져오기\n",
    "survey_content = review_all.loc[review_all['id'].isin(story_data['content_id'])][['id', 'content']]\n",
    "# merge 를 위해서 id 컬럼명 통일하기\n",
    "survey_content.columns=['content_id', 'content']\n",
    "\n",
    "# 통일된 content_id 를 기반으로 데이터 merge\n",
    "story_data = pd.merge(story_data, survey_content)\n",
    "\n",
    "# 추후 원활한 계산을 위해서 숫자 부분은 모두 int 로 바꿔줌\n",
    "story_data['story'] = story_data['story'].astype(int)\n",
    "\n",
    "# 최소한의 전처리\n",
    "def cleaned_content(text):\n",
    "    d = re.sub('\\n', '. ', text) # 줄바꿈 > .\n",
    "    d = re.sub('[^가-힣0-9a-zA-Z ]{2,}', \".\", d) # 특수문자 두개 이상인거 .으로 변경\n",
    "    return d\n",
    "\n",
    "story_data['content'] = story_data['content'].apply(cleaned_content)\n",
    "\n",
    "final_df = story_data[['content', 'story']]\n",
    "\n",
    "# 라벨별 개수 확인\n",
    "print(final_df['story'].value_counts())\n",
    "print('\\n')\n",
    "train_data = final_df.sample(frac=0.8, random_state=42).reset_index().drop(columns='index')\n",
    "print('train_data', train_data['story'].value_counts())\n",
    "test_data = final_df.drop(train_data.index).reset_index().drop(columns='index')\n",
    "print('\\n', 'test_data', test_data['story'].value_counts())\n",
    "print('\\n')\n",
    "# 중복 데이터 제거(데이터 분리 후 중복이 생길 수 있어서 데이터 분리 후 중복 데이터 처리 진행)\n",
    "\n",
    "# 데이터셋 개수 확인\n",
    "print('중복 제거 전 학습 데이터셋: {}'.format(len(train_data)))\n",
    "print('중복 제거 전 테스트 데이터셋: {}'.format(len(test_data)))\n",
    "print('\\n')\n",
    "# 중복 데이터 제거\n",
    "train_data.drop_duplicates(subset=['content'], inplace=True)\n",
    "test_data.drop_duplicates(subset=['content'], inplace=True)\n",
    "print('\\n')\n",
    "# 데이터셋 개수 확인\n",
    "print('중복 제거 후 학습 데이터셋: {}'.format(len(train_data)))\n",
    "print('중복 제거 후 테스트 데이터셋: {}'.format(len(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-small-v3-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(35080, 128)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 토큰에 추가할 단어 -> '방탈출'이라는 도메인 지시기에 근거한 용어, 분리되어서는 안 되기 때문에 별도로 추가 작업 진행\n",
    "addword = ['공테', '약공테', '감테', '창공', '갑툭튀', '삐딱', '삑', '꽝', '삑딱쾅', '삑딱쾅', '삑딱', '쫄', '극쫄',\n",
    "            '극극쫄', '쫄팟', '쫄탱', '쫄보', '극', '약탱', '탱쫄', '극극극', '뉴비', '하드캐리', '극혐', '피지컬',\n",
    "            '어거지', '뚝배기', '뚝문', '셀뚝', '억까', '트롤링', '트롤짓', '흙길', '풀길', '꽃길', '풀꽃', '꽃다발',\n",
    "            '꽃밭', '웰메이드', '인생테마', '머글', '방린이', '방유아', '방세포', '방태아', '방탈러', '과몰입러', '옵저버',\n",
    "            '리트', '연방', '혼방', '혼불', '워킹', '워크인', '장치방', '문제방', '직렬', '병렬', '육각형', '볼드', '볼드충', '에바',\n",
    "            '가이드', '조도', '조명', '밝기', '어두움', '인테리어', '비주얼', '소품', '디자인',\n",
    "            '스토리','기승전결','흐름도','결말','서사','이야기','유니버스','전개','시나리오', '개연성', '명료',\n",
    "            '창의성','창의','신선','독특','참신','발상', '연출','짜임','사실감','구현','현실감','현장감', '활동성','활동력','활동량','움직임','반경',\n",
    "            '규모','스케일','볼륨','사이즈','크기','넓이','공간감','분량', '공포','공테','무서움','담력','스릴러',\n",
    "            '문제', '장치', '기계', '센서', '기구', '불친절',\n",
    "            '메르헨', '커튼콜', '카르텔', '소우주', '풀문', '도고', '플래시', '나우히어', '나비효과', '몽중', '가이드라인',\n",
    "            '연출력', '짜임새', '공포도', '공포감', '공포심', '약공테', '문제퀄']\n",
    "\n",
    "# 사전학습된 bert 모델 사용\n",
    "# num_labels 클래스에 대해서 훈련을 하기 위해서 num_labels=3 할당함, problem_type=\"multi_label_classification\" 를 통해서 모델이 다중 레이블 분류에 해당함을 명시\n",
    "model = ElectraForSequenceClassification.from_pretrained(\"monologg/koelectra-small-v3-discriminator\", num_labels=3, problem_type=\"multi_label_classification\")\n",
    "tokenizer = ElectraTokenizer.from_pretrained(\"monologg/koelectra-base-v3-discriminator\")\n",
    "\n",
    "# token에 새로운 단어 추가 \n",
    "tokenizer.add_tokens(addword)\n",
    "# token에 단어 추가후 기존 모델의 임베딩 레이어에 추가한 단어에 대한 임베딩 벡터가 없을 수 있기 때문\n",
    "# 아래 코드를 통해서 토큰의 개수가 변했음을 모델에 알리고 모델의 임베딩 레이어를 조정하여 새로운 토큰을 수용할 수 있게 함\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train content 토큰화\n",
    "tokenized_train_sentences = tokenizer(\n",
    "    list(train_data['content']),\n",
    "    return_tensors=\"pt\",\n",
    "    max_length=128,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    add_special_tokens=True\n",
    ")\n",
    "\n",
    "# test content 토큰화\n",
    "tokenized_test_sentences = tokenizer(\n",
    "    list(test_data['content']),\n",
    "    return_tensors=\"pt\",\n",
    "    max_length=128,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    add_special_tokens=True\n",
    ")\n",
    "\n",
    "# 분류 모델에 넣기 위해서 1차원으로 구성된 세 개의 클래스를 2차원으로 재구성 후 label 로 투입\n",
    "# -1(부정)=0, 0(중립)=1, 1(긍정)=2\n",
    "\n",
    "train_label = []\n",
    "for label in train_data[\"story\"].values:\n",
    "    if label == -1:\n",
    "        train_label.append([1., 0., 0.])\n",
    "    elif label == 0:\n",
    "        train_label.append([0., 1., 0.])\n",
    "    elif label == 1:\n",
    "        train_label.append([0., 0., 1.])\n",
    "\n",
    "test_label = []\n",
    "for label in test_data['story'].values:\n",
    "    if label == 0:\n",
    "        test_label.append([0., 1., 0.])\n",
    "    elif label == -1:\n",
    "        test_label.append([1., 0., 0.])\n",
    "    elif label == 1:\n",
    "        test_label.append([0., 0., 1.])\n",
    "\n",
    "# model 에 넣기 위한 dataset 생성 class\n",
    "class CurseDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "        \n",
    "# bert 모델에 데이터가 들어갈 수 있게 만들어 둔 class를 활용하여 train, test dataset 생성\n",
    "train_dataset = CurseDataset(tokenized_train_sentences, train_label)\n",
    "test_dataset = CurseDataset(tokenized_test_sentences, test_label)\n",
    "\n",
    "# hugging face 의 trasformers 라이브러리를 사용하여 모델 훈련시킬 때 사용되는 객체 설정 부분\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = './story_model/check_point/try_3',    # 모델과 훈련 중 생성되는 파일이 저장될 디렉토리 경로\n",
    "    num_train_epochs = 20,              # 훈련 epoch 수\n",
    "    per_device_train_batch_size = 16,    # 장치에 할당된 훈련 배치 크기\n",
    "    per_device_eval_batch_size = 64,    # 장치에 할당된 평가 배치 크기, 모델을 평가할 때 사용되는 배치 크기\n",
    "    logging_dir = './logs',             # 훈련 중 로그 파일이 저장될 디렉토리\n",
    "    logging_steps = 500,                # 로그 출력 빈도, 500 step에 한 번씩 출력 예정\n",
    "    save_total_limit = 2,               # 체크포인트 파일 저장 제한 수\n",
    ")\n",
    "\n",
    "# hugging face 의 trasformers 라이브러리를 사용하여 모델 훈련하고 관리하는 객체 설정 부분\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5020 [00:00<?, ?it/s]/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_72976/4108461832.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 10%|▉         | 500/5020 [02:03<18:22,  4.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.268, 'learning_rate': 4.50199203187251e-05, 'epoch': 1.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_72976/4108461832.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 20%|█▉        | 1000/5020 [04:06<16:10,  4.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1255, 'learning_rate': 4.00398406374502e-05, 'epoch': 3.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_72976/4108461832.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 30%|██▉       | 1500/5020 [06:08<14:05,  4.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1259, 'learning_rate': 3.50597609561753e-05, 'epoch': 5.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_72976/4108461832.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 40%|███▉      | 2000/5020 [08:10<12:25,  4.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1164, 'learning_rate': 3.00796812749004e-05, 'epoch': 7.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_72976/4108461832.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 50%|████▉     | 2500/5020 [10:12<10:20,  4.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1098, 'learning_rate': 2.50996015936255e-05, 'epoch': 9.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_72976/4108461832.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 60%|█████▉    | 3000/5020 [12:15<08:12,  4.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1005, 'learning_rate': 2.01195219123506e-05, 'epoch': 11.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_72976/4108461832.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 70%|██████▉   | 3500/5020 [14:16<06:03,  4.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0936, 'learning_rate': 1.5139442231075698e-05, 'epoch': 13.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_72976/4108461832.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 80%|███████▉  | 4000/5020 [16:18<04:00,  4.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0913, 'learning_rate': 1.0159362549800798e-05, 'epoch': 15.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_72976/4108461832.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 90%|████████▉ | 4500/5020 [18:20<02:06,  4.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.088, 'learning_rate': 5.179282868525897e-06, 'epoch': 17.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_72976/4108461832.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "100%|█████████▉| 5000/5020 [20:22<00:04,  4.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0864, 'learning_rate': 1.99203187250996e-07, 'epoch': 19.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_72976/4108461832.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "100%|██████████| 5020/5020 [20:28<00:00,  4.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1228.2852, 'train_samples_per_second': 65.18, 'train_steps_per_second': 4.087, 'train_loss': 0.12041076200891776, 'epoch': 20.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5020, training_loss=0.12041076200891776, metrics={'train_runtime': 1228.2852, 'train_samples_per_second': 65.18, 'train_steps_per_second': 4.087, 'train_loss': 0.12041076200891776, 'epoch': 20.0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train 진행\n",
    "trainer.train() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./story_model/try_3/story_tokenizer3/tokenizer_config.json',\n",
       " './story_model/try_3/story_tokenizer3/special_tokens_map.json',\n",
       " './story_model/try_3/story_tokenizer3/vocab.txt',\n",
       " './story_model/try_3/story_tokenizer3/added_tokens.json')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.save_model(\"./story_model/try_3/story_model3\")\n",
    "tokenizer.save_pretrained(\"./story_model/try_3/story_tokenizer3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# 저장된 모델과 토크나이저를 불러오기\n",
    "\n",
    "model_path = \"./story_model/try_3/story_model3\"\n",
    "tokenizer_path = \"./story_model/try_3/story_tokenizer3\"\n",
    "\n",
    "model = ElectraForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer = ElectraTokenizer.from_pretrained(tokenizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1001/1001 [00:14<00:00, 69.71it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>story</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#1415_20221128_3인. 흐음.잘 열어보지 않으면</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>난.바보야.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>들어가자마자 커피향이 씨게 낫다 좋앗다 하지만 인테리어는 그냥그랫다. 풀정도 되는듯.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3인. 스토리가 잘 감이 안 잡힌다!</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.5/3인. 활동성 있음.추락조심</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>나에겐 너무 어려웠던. 방탈짬바 있는 분들에게 추천</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>2021. 12. 26. (3인) 각자 1인분씩 하고 뿌듯했던 테마.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>첫방 디버프로 초반에 절어버림. 볼것도 못보고 힌트썼는데 잘꾸며놓았다 . 살짝 장치...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>#5 - 2인 - 볼륨에 압도됨 - 히터도 방마다 빵빵함 - 다른 테마도 궁금해짐</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>265, 2인, 장치. 그걸 왜 몰랐냐. 장치에 속지 말자</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1001 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content  story  pred\n",
       "0                      #1415_20221128_3인. 흐음.잘 열어보지 않으면      0     0\n",
       "1                                                난.바보야.      0     0\n",
       "2       들어가자마자 커피향이 씨게 낫다 좋앗다 하지만 인테리어는 그냥그랫다. 풀정도 되는듯.      0     0\n",
       "3                                  3인. 스토리가 잘 감이 안 잡힌다!     -1     1\n",
       "4                                   1.5/3인. 활동성 있음.추락조심      0     0\n",
       "...                                                 ...    ...   ...\n",
       "999                        나에겐 너무 어려웠던. 방탈짬바 있는 분들에게 추천      0     0\n",
       "1000             2021. 12. 26. (3인) 각자 1인분씩 하고 뿌듯했던 테마.      0     0\n",
       "1001  첫방 디버프로 초반에 절어버림. 볼것도 못보고 힌트썼는데 잘꾸며놓았다 . 살짝 장치...      0     0\n",
       "1002      #5 - 2인 - 볼륨에 압도됨 - 히터도 방마다 빵빵함 - 다른 테마도 궁금해짐      0     0\n",
       "1003                   265, 2인, 장치. 그걸 왜 몰랐냐. 장치에 속지 말자      0     0\n",
       "\n",
       "[1001 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문장을 입력했을 때, 예측 값을 도출해주는 함수\n",
    "\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "# 함수 정의\n",
    "def classify_text(text):\n",
    "    # 문장을 토큰화하고 모델에 입력으로 전달\n",
    "    text = cleaned_content(text)\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "    # 소프트맥스 함수를 사용하여 확률값 계산\n",
    "    probabilities = softmax(outputs.logits, dim=1)\n",
    "\n",
    "    # 가장 높은 확률값에 해당하는 클래스 선택\n",
    "    predicted_class = torch.argmax(probabilities).item()\n",
    "\n",
    "    return predicted_class, probabilities\n",
    "\n",
    "def change_num(num):\n",
    "    if num == 0:\n",
    "        return (-1)\n",
    "    elif num == 1:\n",
    "        return 0\n",
    "    elif num == 2:\n",
    "        return 1\n",
    "\n",
    "pred_list = []\n",
    "for sent in tqdm(test_data['content']):\n",
    "    pred, _ = classify_text(sent)\n",
    "    pred_list.append(pred)\n",
    "\n",
    "test_data['pred'] = pred_list\n",
    "test_data['pred'] = test_data['pred'].apply(change_num)\n",
    "test_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 라벨 수 story\n",
      " 0    4461\n",
      " 1     444\n",
      "-1     118\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "train_data 라벨 수 story\n",
      " 0    3545\n",
      " 1     363\n",
      "-1      95\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "test_data 라벨 수 story\n",
      " 0    905\n",
      " 1     78\n",
      "-1     18\n",
      "Name: count, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('전체 라벨 수', final_df['story'].value_counts(), '\\n')\n",
    "print('train_data 라벨 수', train_data['story'].value_counts(), '\\n')\n",
    "print('test_data 라벨 수', test_data['story'].value_counts(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0포함 예측률 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00        18\n",
      "           0       1.00      0.97      0.99       905\n",
      "           1       0.66      0.99      0.79        78\n",
      "\n",
      "    accuracy                           0.96      1001\n",
      "   macro avg       0.55      0.65      0.59      1001\n",
      "weighted avg       0.95      0.96      0.95      1001\n",
      "\n",
      "0제외 예측률 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00        18\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.82      0.99      0.90        78\n",
      "\n",
      "    accuracy                           0.80        96\n",
      "   macro avg       0.27      0.33      0.30        96\n",
      "weighted avg       0.67      0.80      0.73        96\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/bert_electra/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/bert_electra/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/bert_electra/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/bert_electra/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/bert_electra/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/bert_electra/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/bert_electra/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/bert_electra/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/bert_electra/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('0포함 예측률', '\\n', classification_report(test_data['story'], test_data['pred']))\n",
    "test_data2 = test_data[test_data['story'] != 0]\n",
    "print('0제외 예측률', '\\n', classification_report(test_data2['story'], test_data2['pred']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장: 스토리 대박, 평가: 2\n",
      "----------\n",
      "문장: 스토리 좋아요, 평가: 2\n",
      "----------\n",
      "문장: 스토리 개좋음, 평가: 2\n",
      "----------\n",
      "문장: 서비스 무슨 일, 평가: 1\n",
      "----------\n",
      "문장: 이야기 재밌어요, 평가: 2\n",
      "----------\n",
      "문장: 불친절함, 평가: 1\n",
      "----------\n",
      "문장: 스토리 쓰레기네, 평가: 2\n",
      "----------\n",
      "문장: 서비스는 좋은데 재미없었어요., 평가: 1\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "test = [\n",
    "    '스토리 대박',\n",
    "    '스토리 좋아요',\n",
    "    '스토리 개좋음',\n",
    "    '서비스 무슨 일',\n",
    "    '이야기 재밌어요',\n",
    "    '불친절함',\n",
    "    '스토리 쓰레기네',\n",
    "    '서비스는 좋은데 재미없었어요.',\n",
    "]\n",
    "\n",
    "for sent in test:\n",
    "    pred, _ = classify_text(sent)\n",
    "    print(f'문장: {sent}, 평가: {pred}')\n",
    "    print(\"-\"*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4차 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_77380/2028388394.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  story_data['content_id'] = story_data['content_id'].apply(lambda x: x.split(',')[0] if len(str(x)) > 6 else x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "story\n",
      " 0    4461\n",
      " 1     444\n",
      "-1     118\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "train_data story\n",
      " 0    3560\n",
      " 1     363\n",
      "-1      95\n",
      "Name: count, dtype: int64\n",
      "\n",
      " test_data story\n",
      " 0    909\n",
      " 1     78\n",
      "-1     18\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "중복 제거 전 학습 데이터셋: 4018\n",
      "중복 제거 전 테스트 데이터셋: 1005\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "중복 제거 후 학습 데이터셋: 4003\n",
      "중복 제거 후 테스트 데이터셋: 1001\n"
     ]
    }
   ],
   "source": [
    "# labeling 된 데이터 불러오기\n",
    "survey = pd.read_csv(\"./_data/survey.csv\", index_col=0)\n",
    "survey.fillna(0, inplace=True)\n",
    "survey = survey.reset_index()\n",
    "\n",
    "# 데이터 중에서 작업을 하고자 하는 라벨만 가져오기\n",
    "story_data = survey[['content_id', 'story']]\n",
    "\n",
    "# content_id 중에서 댓글이 같이 추가된 데이터 정리\n",
    "story_data['content_id'] = story_data['content_id'].apply(lambda x: x.split(',')[0] if len(str(x)) > 6 else x)\n",
    "\n",
    "# content_id 가 0인 데이터 제외 -> content_id 모두 int type 으로 변경 (추후 Merge 를 위함)\n",
    "story_data = story_data[story_data['content_id'] != 0].reset_index().drop(columns=['index'])\n",
    "story_data['content_id'] = story_data['content_id'].astype(int)\n",
    "\n",
    "# 전체 review data 불러오기\n",
    "review_all = pd.read_csv(\"./_data/reviews.csv\", index_col=0)\n",
    "\n",
    "# 전체 review data 중에서 survey data에 있는 댓글만 가져오기\n",
    "survey_content = review_all.loc[review_all['id'].isin(story_data['content_id'])][['id', 'content']]\n",
    "# merge 를 위해서 id 컬럼명 통일하기\n",
    "survey_content.columns=['content_id', 'content']\n",
    "\n",
    "# 통일된 content_id 를 기반으로 데이터 merge\n",
    "story_data = pd.merge(story_data, survey_content)\n",
    "\n",
    "# 추후 원활한 계산을 위해서 숫자 부분은 모두 int 로 바꿔줌\n",
    "story_data['story'] = story_data['story'].astype(int)\n",
    "\n",
    "# 최소한의 전처리\n",
    "def cleaned_content(text):\n",
    "    d = re.sub('\\n', '. ', text) # 줄바꿈 > .\n",
    "    d = re.sub('[^가-힣0-9a-zA-Z ]{2,}', \".\", d) # 특수문자 두개 이상인거 .으로 변경\n",
    "    return d\n",
    "\n",
    "story_data['content'] = story_data['content'].apply(cleaned_content)\n",
    "\n",
    "final_df = story_data[['content', 'story']]\n",
    "\n",
    "# 라벨별 개수 확인\n",
    "print(final_df['story'].value_counts())\n",
    "print('\\n')\n",
    "train_data = final_df.sample(frac=0.8, random_state=42).reset_index().drop(columns='index')\n",
    "print('train_data', train_data['story'].value_counts())\n",
    "test_data = final_df.drop(train_data.index).reset_index().drop(columns='index')\n",
    "print('\\n', 'test_data', test_data['story'].value_counts())\n",
    "print('\\n')\n",
    "# 중복 데이터 제거(데이터 분리 후 중복이 생길 수 있어서 데이터 분리 후 중복 데이터 처리 진행)\n",
    "\n",
    "# 데이터셋 개수 확인\n",
    "print('중복 제거 전 학습 데이터셋: {}'.format(len(train_data)))\n",
    "print('중복 제거 전 테스트 데이터셋: {}'.format(len(test_data)))\n",
    "print('\\n')\n",
    "# 중복 데이터 제거\n",
    "train_data.drop_duplicates(subset=['content'], inplace=True)\n",
    "test_data.drop_duplicates(subset=['content'], inplace=True)\n",
    "print('\\n')\n",
    "# 데이터셋 개수 확인\n",
    "print('중복 제거 후 학습 데이터셋: {}'.format(len(train_data)))\n",
    "print('중복 제거 후 테스트 데이터셋: {}'.format(len(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-small-v3-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(35080, 128)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 토큰에 추가할 단어 -> '방탈출'이라는 도메인 지시기에 근거한 용어, 분리되어서는 안 되기 때문에 별도로 추가 작업 진행\n",
    "addword = ['공테', '약공테', '감테', '창공', '갑툭튀', '삐딱', '삑', '꽝', '삑딱쾅', '삑딱쾅', '삑딱', '쫄', '극쫄',\n",
    "            '극극쫄', '쫄팟', '쫄탱', '쫄보', '극', '약탱', '탱쫄', '극극극', '뉴비', '하드캐리', '극혐', '피지컬',\n",
    "            '어거지', '뚝배기', '뚝문', '셀뚝', '억까', '트롤링', '트롤짓', '흙길', '풀길', '꽃길', '풀꽃', '꽃다발',\n",
    "            '꽃밭', '웰메이드', '인생테마', '머글', '방린이', '방유아', '방세포', '방태아', '방탈러', '과몰입러', '옵저버',\n",
    "            '리트', '연방', '혼방', '혼불', '워킹', '워크인', '장치방', '문제방', '직렬', '병렬', '육각형', '볼드', '볼드충', '에바',\n",
    "            '가이드', '조도', '조명', '밝기', '어두움', '인테리어', '비주얼', '소품', '디자인',\n",
    "            '스토리','기승전결','흐름도','결말','서사','이야기','유니버스','전개','시나리오', '개연성', '명료',\n",
    "            '창의성','창의','신선','독특','참신','발상', '연출','짜임','사실감','구현','현실감','현장감', '활동성','활동력','활동량','움직임','반경',\n",
    "            '규모','스케일','볼륨','사이즈','크기','넓이','공간감','분량', '공포','공테','무서움','담력','스릴러',\n",
    "            '문제', '장치', '기계', '센서', '기구', '불친절',\n",
    "            '메르헨', '커튼콜', '카르텔', '소우주', '풀문', '도고', '플래시', '나우히어', '나비효과', '몽중', '가이드라인',\n",
    "            '연출력', '짜임새', '공포도', '공포감', '공포심', '약공테', '문제퀄']\n",
    "\n",
    "# 사전학습된 bert 모델 사용\n",
    "# num_labels 클래스에 대해서 훈련을 하기 위해서 num_labels=3 할당함, problem_type=\"multi_label_classification\" 를 통해서 모델이 다중 레이블 분류에 해당함을 명시\n",
    "model = ElectraForSequenceClassification.from_pretrained(\"monologg/koelectra-small-v3-discriminator\", num_labels=3, problem_type=\"multi_label_classification\")\n",
    "tokenizer = ElectraTokenizer.from_pretrained(\"monologg/koelectra-base-v3-discriminator\")\n",
    "\n",
    "# token에 새로운 단어 추가 \n",
    "tokenizer.add_tokens(addword)\n",
    "# token에 단어 추가후 기존 모델의 임베딩 레이어에 추가한 단어에 대한 임베딩 벡터가 없을 수 있기 때문\n",
    "# 아래 코드를 통해서 토큰의 개수가 변했음을 모델에 알리고 모델의 임베딩 레이어를 조정하여 새로운 토큰을 수용할 수 있게 함\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train content 토큰화\n",
    "tokenized_train_sentences = tokenizer(\n",
    "    list(train_data['content']),\n",
    "    return_tensors=\"pt\",\n",
    "    max_length=128,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    add_special_tokens=True\n",
    ")\n",
    "\n",
    "# test content 토큰화\n",
    "tokenized_test_sentences = tokenizer(\n",
    "    list(test_data['content']),\n",
    "    return_tensors=\"pt\",\n",
    "    max_length=128,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    add_special_tokens=True\n",
    ")\n",
    "\n",
    "# 분류 모델에 넣기 위해서 1차원으로 구성된 세 개의 클래스를 2차원으로 재구성 후 label 로 투입\n",
    "# -1(부정)=0, 0(중립)=1, 1(긍정)=2\n",
    "\n",
    "train_label = []\n",
    "for label in train_data[\"story\"].values:\n",
    "    if label == -1:\n",
    "        train_label.append([1., 0., 0.])\n",
    "    elif label == 0:\n",
    "        train_label.append([0., 1., 0.])\n",
    "    elif label == 1:\n",
    "        train_label.append([0., 0., 1.])\n",
    "\n",
    "test_label = []\n",
    "for label in test_data['story'].values:\n",
    "    if label == 0:\n",
    "        test_label.append([0., 1., 0.])\n",
    "    elif label == -1:\n",
    "        test_label.append([1., 0., 0.])\n",
    "    elif label == 1:\n",
    "        test_label.append([0., 0., 1.])\n",
    "\n",
    "# model 에 넣기 위한 dataset 생성 class\n",
    "class CurseDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "        \n",
    "# bert 모델에 데이터가 들어갈 수 있게 만들어 둔 class를 활용하여 train, test dataset 생성\n",
    "train_dataset = CurseDataset(tokenized_train_sentences, train_label)\n",
    "test_dataset = CurseDataset(tokenized_test_sentences, test_label)\n",
    "\n",
    "# hugging face 의 trasformers 라이브러리를 사용하여 모델 훈련시킬 때 사용되는 객체 설정 부분\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = './story_model/check_point/try_4',    # 모델과 훈련 중 생성되는 파일이 저장될 디렉토리 경로\n",
    "    num_train_epochs = 25,              # 훈련 epoch 수\n",
    "    per_device_train_batch_size = 16,    # 장치에 할당된 훈련 배치 크기\n",
    "    per_device_eval_batch_size = 64,    # 장치에 할당된 평가 배치 크기, 모델을 평가할 때 사용되는 배치 크기\n",
    "    logging_dir = './logs',             # 훈련 중 로그 파일이 저장될 디렉토리\n",
    "    logging_steps = 500,                # 로그 출력 빈도, 500 step에 한 번씩 출력 예정\n",
    "    save_total_limit = 2,               # 체크포인트 파일 저장 제한 수\n",
    ")\n",
    "\n",
    "# hugging face 의 trasformers 라이브러리를 사용하여 모델 훈련하고 관리하는 객체 설정 부분\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6275 [00:00<?, ?it/s]/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_75698/2000432520.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "  8%|▊         | 500/6275 [01:27<16:37,  5.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2535, 'learning_rate': 4.601593625498008e-05, 'epoch': 1.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_75698/2000432520.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 16%|█▌        | 1000/6275 [02:54<15:44,  5.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1266, 'learning_rate': 4.203187250996016e-05, 'epoch': 3.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_75698/2000432520.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 24%|██▍       | 1500/6275 [04:23<14:20,  5.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1271, 'learning_rate': 3.804780876494024e-05, 'epoch': 5.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_75698/2000432520.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 32%|███▏      | 2000/6275 [05:51<12:29,  5.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1192, 'learning_rate': 3.406374501992032e-05, 'epoch': 7.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_75698/2000432520.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 40%|███▉      | 2500/6275 [07:20<11:17,  5.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.107, 'learning_rate': 3.00796812749004e-05, 'epoch': 9.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_75698/2000432520.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 48%|████▊     | 3000/6275 [08:49<09:40,  5.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0942, 'learning_rate': 2.609561752988048e-05, 'epoch': 11.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_75698/2000432520.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 56%|█████▌    | 3500/6275 [10:18<08:10,  5.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0794, 'learning_rate': 2.2111553784860558e-05, 'epoch': 13.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_75698/2000432520.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 64%|██████▎   | 4000/6275 [11:46<06:35,  5.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0664, 'learning_rate': 1.812749003984064e-05, 'epoch': 15.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_75698/2000432520.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 72%|███████▏  | 4500/6275 [13:16<05:22,  5.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0564, 'learning_rate': 1.4143426294820719e-05, 'epoch': 17.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_75698/2000432520.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 80%|███████▉  | 5000/6275 [14:45<03:41,  5.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0515, 'learning_rate': 1.0159362549800798e-05, 'epoch': 19.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_75698/2000432520.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 88%|████████▊ | 5500/6275 [16:14<02:14,  5.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0468, 'learning_rate': 6.175298804780877e-06, 'epoch': 21.91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_75698/2000432520.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 96%|█████████▌| 6000/6275 [17:43<00:47,  5.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0404, 'learning_rate': 2.1912350597609563e-06, 'epoch': 23.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_75698/2000432520.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "100%|██████████| 6275/6275 [18:32<00:00,  5.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1112.1577, 'train_samples_per_second': 89.983, 'train_steps_per_second': 5.642, 'train_loss': 0.09475747735376852, 'epoch': 25.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=6275, training_loss=0.09475747735376852, metrics={'train_runtime': 1112.1577, 'train_samples_per_second': 89.983, 'train_steps_per_second': 5.642, 'train_loss': 0.09475747735376852, 'epoch': 25.0})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train 진행\n",
    "trainer.train() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./story_model/try_4/story_tokenizer4/tokenizer_config.json',\n",
       " './story_model/try_4/story_tokenizer4/special_tokens_map.json',\n",
       " './story_model/try_4/story_tokenizer4/vocab.txt',\n",
       " './story_model/try_4/story_tokenizer4/added_tokens.json')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.save_model(\"./story_model/try_4/story_model4\")\n",
    "tokenizer.save_pretrained(\"./story_model/try_4/story_tokenizer4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# 저장된 모델과 토크나이저를 불러오기\n",
    "\n",
    "model_path = \"./story_model/try_4/story_model4\"\n",
    "tokenizer_path = \"./story_model/try_4/story_tokenizer4\"\n",
    "\n",
    "model = ElectraForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer = ElectraTokenizer.from_pretrained(tokenizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1001/1001 [00:11<00:00, 84.15it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>story</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#1415_20221128_3인. 흐음.잘 열어보지 않으면</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>난.바보야.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>들어가자마자 커피향이 씨게 낫다 좋앗다 하지만 인테리어는 그냥그랫다. 풀정도 되는듯.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3인. 스토리가 잘 감이 안 잡힌다!</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.5/3인. 활동성 있음.추락조심</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>나에겐 너무 어려웠던. 방탈짬바 있는 분들에게 추천</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>2021. 12. 26. (3인) 각자 1인분씩 하고 뿌듯했던 테마.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>첫방 디버프로 초반에 절어버림. 볼것도 못보고 힌트썼는데 잘꾸며놓았다 . 살짝 장치...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>#5 - 2인 - 볼륨에 압도됨 - 히터도 방마다 빵빵함 - 다른 테마도 궁금해짐</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>265, 2인, 장치. 그걸 왜 몰랐냐. 장치에 속지 말자</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1001 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content  story  pred\n",
       "0                      #1415_20221128_3인. 흐음.잘 열어보지 않으면      0     0\n",
       "1                                                난.바보야.      0     0\n",
       "2       들어가자마자 커피향이 씨게 낫다 좋앗다 하지만 인테리어는 그냥그랫다. 풀정도 되는듯.      0     0\n",
       "3                                  3인. 스토리가 잘 감이 안 잡힌다!     -1     1\n",
       "4                                   1.5/3인. 활동성 있음.추락조심      0     0\n",
       "...                                                 ...    ...   ...\n",
       "999                        나에겐 너무 어려웠던. 방탈짬바 있는 분들에게 추천      0     0\n",
       "1000             2021. 12. 26. (3인) 각자 1인분씩 하고 뿌듯했던 테마.      0     0\n",
       "1001  첫방 디버프로 초반에 절어버림. 볼것도 못보고 힌트썼는데 잘꾸며놓았다 . 살짝 장치...      0     0\n",
       "1002      #5 - 2인 - 볼륨에 압도됨 - 히터도 방마다 빵빵함 - 다른 테마도 궁금해짐      0     0\n",
       "1003                   265, 2인, 장치. 그걸 왜 몰랐냐. 장치에 속지 말자      0     0\n",
       "\n",
       "[1001 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문장을 입력했을 때, 예측 값을 도출해주는 함수\n",
    "\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "# 함수 정의\n",
    "def classify_text(text):\n",
    "    # 문장을 토큰화하고 모델에 입력으로 전달\n",
    "    text = cleaned_content(text)\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "    # 소프트맥스 함수를 사용하여 확률값 계산\n",
    "    probabilities = softmax(outputs.logits, dim=1)\n",
    "\n",
    "    # 가장 높은 확률값에 해당하는 클래스 선택\n",
    "    predicted_class = torch.argmax(probabilities).item()\n",
    "\n",
    "    return predicted_class, probabilities\n",
    "\n",
    "def change_num(num):\n",
    "    if num == 0:\n",
    "        return (-1)\n",
    "    elif num == 1:\n",
    "        return 0\n",
    "    elif num == 2:\n",
    "        return 1\n",
    "\n",
    "pred_list = []\n",
    "for sent in tqdm(test_data['content']):\n",
    "    pred, _ = classify_text(sent)\n",
    "    pred_list.append(pred)\n",
    "\n",
    "test_data['pred'] = pred_list\n",
    "test_data['pred'] = test_data['pred'].apply(change_num)\n",
    "test_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 라벨 수 story\n",
      " 0    4461\n",
      " 1     444\n",
      "-1     118\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "train_data 라벨 수 story\n",
      " 0    3545\n",
      " 1     363\n",
      "-1      95\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "test_data 라벨 수 story\n",
      " 0    905\n",
      " 1     78\n",
      "-1     18\n",
      "Name: count, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('전체 라벨 수', final_df['story'].value_counts(), '\\n')\n",
    "print('train_data 라벨 수', train_data['story'].value_counts(), '\\n')\n",
    "print('test_data 라벨 수', test_data['story'].value_counts(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0포함 예측률 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.80      0.44      0.57        18\n",
      "           0       1.00      0.99      0.99       905\n",
      "           1       0.82      0.96      0.89        78\n",
      "\n",
      "    accuracy                           0.98      1001\n",
      "   macro avg       0.87      0.80      0.82      1001\n",
      "weighted avg       0.98      0.98      0.98      1001\n",
      "\n",
      "0제외 예측률 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      0.44      0.62        18\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.89      0.96      0.93        78\n",
      "\n",
      "    accuracy                           0.86        96\n",
      "   macro avg       0.63      0.47      0.51        96\n",
      "weighted avg       0.91      0.86      0.87        96\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/bert_electra/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/bert_electra/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/bert_electra/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('0포함 예측률', '\\n', classification_report(test_data['story'], test_data['pred']))\n",
    "test_data2 = test_data[test_data['story'] != 0]\n",
    "print('0제외 예측률', '\\n', classification_report(test_data2['story'], test_data2['pred']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장: 스토리 대박, 평가: 2\n",
      "----------\n",
      "문장: 스토리 좋아요, 평가: 2\n",
      "----------\n",
      "문장: 스토리 개좋음, 평가: 2\n",
      "----------\n",
      "문장: 서비스 무슨 일, 평가: 1\n",
      "----------\n",
      "문장: 이야기 재밌어요, 평가: 1\n",
      "----------\n",
      "문장: 불친절함, 평가: 1\n",
      "----------\n",
      "문장: 스토리 쓰레기네, 평가: 0\n",
      "----------\n",
      "문장: 서비스는 좋은데 재미없었어요., 평가: 1\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "test = [\n",
    "    '스토리 대박',\n",
    "    '스토리 좋아요',\n",
    "    '스토리 개좋음',\n",
    "    '서비스 무슨 일',\n",
    "    '이야기 재밌어요',\n",
    "    '불친절함',\n",
    "    '스토리 쓰레기네',\n",
    "    '서비스는 좋은데 재미없었어요.',\n",
    "]\n",
    "\n",
    "for sent in test:\n",
    "    pred, _ = classify_text(sent)\n",
    "    print(f'문장: {sent}, 평가: {pred}')\n",
    "    print(\"-\"*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4차 모델 결과\n",
    "- 에폭 올리니까 부정 평가 올라감"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5차 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_33219/3816692337.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  story_data['content_id'] = story_data['content_id'].apply(lambda x: x.split(',')[0] if len(str(x)) > 6 else x)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>story</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>오류장치 . . . 옵으로 다시 참여. 그 땐 문제도 못 풀었지만 100방 이상 쌓...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>390. 조도 무슨일이야.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4인. 309번째 심연으로 떠납니다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4인. 극악의 조도. 그게 다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>조도가 낮은게 아니라 없는 수준이라고 하던데, 확실히 느꼈다. 조도도 낮은데 관찰력...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5018</th>\n",
       "      <td>2021. 12. 26. (3인) 각자 1인분씩 하고 뿌듯했던 테마.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5019</th>\n",
       "      <td>첫방 디버프로 초반에 절어버림. 볼것도 못보고 힌트썼는데 잘꾸며놓았다 . 살짝 장치...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5020</th>\n",
       "      <td>#5 - 2인 - 볼륨에 압도됨 - 히터도 방마다 빵빵함 - 다른 테마도 궁금해짐</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5021</th>\n",
       "      <td>265, 2인, 장치. 그걸 왜 몰랐냐. 장치에 속지 말자</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5022</th>\n",
       "      <td>265, 2인, 장치. 그걸 왜 몰랐냐. 장치에 속지 말자</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5023 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content  story\n",
       "0     오류장치 . . . 옵으로 다시 참여. 그 땐 문제도 못 풀었지만 100방 이상 쌓...      0\n",
       "1                                        390. 조도 무슨일이야.      0\n",
       "2                                   4인. 309번째 심연으로 떠납니다      0\n",
       "3                                     4인. 극악의 조도. 그게 다.      0\n",
       "4     조도가 낮은게 아니라 없는 수준이라고 하던데, 확실히 느꼈다. 조도도 낮은데 관찰력...      0\n",
       "...                                                 ...    ...\n",
       "5018             2021. 12. 26. (3인) 각자 1인분씩 하고 뿌듯했던 테마.      0\n",
       "5019  첫방 디버프로 초반에 절어버림. 볼것도 못보고 힌트썼는데 잘꾸며놓았다 . 살짝 장치...      0\n",
       "5020      #5 - 2인 - 볼륨에 압도됨 - 히터도 방마다 빵빵함 - 다른 테마도 궁금해짐      0\n",
       "5021                   265, 2인, 장치. 그걸 왜 몰랐냐. 장치에 속지 말자      0\n",
       "5022                   265, 2인, 장치. 그걸 왜 몰랐냐. 장치에 속지 말자      0\n",
       "\n",
       "[5023 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# labeling 된 데이터 불러오기\n",
    "survey = pd.read_csv(\"./_data/survey.csv\", index_col=0)\n",
    "survey.fillna(0, inplace=True)\n",
    "survey = survey.reset_index()\n",
    "\n",
    "# 데이터 중에서 작업을 하고자 하는 라벨만 가져오기\n",
    "story_data = survey[['content_id', 'story']]\n",
    "\n",
    "# content_id 중에서 댓글이 같이 추가된 데이터 정리\n",
    "story_data['content_id'] = story_data['content_id'].apply(lambda x: x.split(',')[0] if len(str(x)) > 6 else x)\n",
    "\n",
    "# content_id 가 0인 데이터 제외 -> content_id 모두 int type 으로 변경 (추후 Merge 를 위함)\n",
    "story_data = story_data[story_data['content_id'] != 0].reset_index().drop(columns=['index'])\n",
    "story_data['content_id'] = story_data['content_id'].astype(int)\n",
    "\n",
    "# 전체 review data 불러오기\n",
    "review_all = pd.read_csv(\"./_data/reviews.csv\", index_col=0)\n",
    "\n",
    "# 전체 review data 중에서 survey data에 있는 댓글만 가져오기\n",
    "survey_content = review_all.loc[review_all['id'].isin(story_data['content_id'])][['id', 'content']]\n",
    "# merge 를 위해서 id 컬럼명 통일하기\n",
    "survey_content.columns=['content_id', 'content']\n",
    "\n",
    "# 통일된 content_id 를 기반으로 데이터 merge\n",
    "story_data = pd.merge(story_data, survey_content)\n",
    "\n",
    "# 추후 원활한 계산을 위해서 숫자 부분은 모두 int 로 바꿔줌\n",
    "story_data['story'] = story_data['story'].astype(int)\n",
    "\n",
    "# 최소한의 전처리\n",
    "def cleaned_content(text):\n",
    "    d = re.sub('\\n', '. ', text) # 줄바꿈 > .\n",
    "    d = re.sub('[^가-힣0-9a-zA-Z ]{2,}', \".\", d) # 특수문자 두개 이상인거 .으로 변경\n",
    "    return d\n",
    "\n",
    "story_data['content'] = story_data['content'].apply(cleaned_content)\n",
    "\n",
    "final_df = story_data[['content', 'story']]\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_33219/2282027481.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df['content'] = final_df['content'].apply(kiwi_clean)\n"
     ]
    }
   ],
   "source": [
    "from kiwipiepy import Kiwi\n",
    "kiwi = Kiwi()\n",
    "\n",
    "def kiwi_clean(text):\n",
    "    get_kiwi_pos = ['NNG', 'NP', 'NNP', 'MM', 'VV', 'VV-I', 'VV-R', 'VA', 'VA-I', 'VA-R', 'VCP', 'VCN', 'MAG', 'MAJ', 'XR']\n",
    "    kiwi_lem = []\n",
    "    for word in kiwi.tokenize(text):\n",
    "        if word.tag in get_kiwi_pos:\n",
    "            kiwi_lem.append(word.lemma)\n",
    "    return ' '.join(kiwi_lem)\n",
    "\n",
    "final_df['content'] = final_df['content'].apply(kiwi_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "story\n",
      " 0    4461\n",
      " 1     444\n",
      "-1     118\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "train_data story\n",
      " 0    3560\n",
      " 1     363\n",
      "-1      95\n",
      "Name: count, dtype: int64\n",
      "\n",
      " test_data story\n",
      " 0    909\n",
      " 1     78\n",
      "-1     18\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "중복 제거 전 학습 데이터셋: 4018\n",
      "중복 제거 전 테스트 데이터셋: 1005\n",
      "\n",
      "\n",
      "중복 제거 후 학습 데이터셋: 3919\n",
      "중복 제거 후 테스트 데이터셋: 989\n"
     ]
    }
   ],
   "source": [
    "# 라벨별 개수 확인\n",
    "print(final_df['story'].value_counts())\n",
    "print('\\n')\n",
    "train_data = final_df.sample(frac=0.8, random_state=42).reset_index().drop(columns='index')\n",
    "print('train_data', train_data['story'].value_counts())\n",
    "test_data = final_df.drop(train_data.index).reset_index().drop(columns='index')\n",
    "print('\\n', 'test_data', test_data['story'].value_counts())\n",
    "print('\\n')\n",
    "# 중복 데이터 제거(데이터 분리 후 중복이 생길 수 있어서 데이터 분리 후 중복 데이터 처리 진행)\n",
    "\n",
    "# 데이터셋 개수 확인\n",
    "print('중복 제거 전 학습 데이터셋: {}'.format(len(train_data)))\n",
    "print('중복 제거 전 테스트 데이터셋: {}'.format(len(test_data)))\n",
    "print('\\n')\n",
    "# 중복 데이터 제거\n",
    "train_data.drop_duplicates(subset=['content'], inplace=True)\n",
    "test_data.drop_duplicates(subset=['content'], inplace=True)\n",
    "# 데이터셋 개수 확인\n",
    "print('중복 제거 후 학습 데이터셋: {}'.format(len(train_data)))\n",
    "print('중복 제거 후 테스트 데이터셋: {}'.format(len(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-small-v3-discriminator and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(35080, 128)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 토큰에 추가할 단어 -> '방탈출'이라는 도메인 지시기에 근거한 용어, 분리되어서는 안 되기 때문에 별도로 추가 작업 진행\n",
    "addword = ['공테', '약공테', '감테', '창공', '갑툭튀', '삐딱', '삑', '꽝', '삑딱쾅', '삑딱쾅', '삑딱', '쫄', '극쫄',\n",
    "            '극극쫄', '쫄팟', '쫄탱', '쫄보', '극', '약탱', '탱쫄', '극극극', '뉴비', '하드캐리', '극혐', '피지컬',\n",
    "            '어거지', '뚝배기', '뚝문', '셀뚝', '억까', '트롤링', '트롤짓', '흙길', '풀길', '꽃길', '풀꽃', '꽃다발',\n",
    "            '꽃밭', '웰메이드', '인생테마', '머글', '방린이', '방유아', '방세포', '방태아', '방탈러', '과몰입러', '옵저버',\n",
    "            '리트', '연방', '혼방', '혼불', '워킹', '워크인', '장치방', '문제방', '직렬', '병렬', '육각형', '볼드', '볼드충', '에바',\n",
    "            '가이드', '조도', '조명', '밝기', '어두움', '인테리어', '비주얼', '소품', '디자인',\n",
    "            '스토리','기승전결','흐름도','결말','서사','이야기','유니버스','전개','시나리오', '개연성', '명료',\n",
    "            '창의성','창의','신선','독특','참신','발상', '연출','짜임','사실감','구현','현실감','현장감', '활동성','활동력','활동량','움직임','반경',\n",
    "            '규모','스케일','볼륨','사이즈','크기','넓이','공간감','분량', '공포','공테','무서움','담력','스릴러',\n",
    "            '문제', '장치', '기계', '센서', '기구', '불친절',\n",
    "            '메르헨', '커튼콜', '카르텔', '소우주', '풀문', '도고', '플래시', '나우히어', '나비효과', '몽중', '가이드라인',\n",
    "            '연출력', '짜임새', '공포도', '공포감', '공포심', '약공테', '문제퀄']\n",
    "\n",
    "# 사전학습된 bert 모델 사용\n",
    "# num_labels 클래스에 대해서 훈련을 하기 위해서 num_labels=3 할당함, problem_type=\"multi_label_classification\" 를 통해서 모델이 다중 레이블 분류에 해당함을 명시\n",
    "model = ElectraForSequenceClassification.from_pretrained(\"monologg/koelectra-small-v3-discriminator\", num_labels=3, problem_type=\"multi_label_classification\")\n",
    "tokenizer = ElectraTokenizer.from_pretrained(\"monologg/koelectra-base-v3-discriminator\")\n",
    "\n",
    "# token에 새로운 단어 추가 \n",
    "tokenizer.add_tokens(addword)\n",
    "# token에 단어 추가후 기존 모델의 임베딩 레이어에 추가한 단어에 대한 임베딩 벡터가 없을 수 있기 때문\n",
    "# 아래 코드를 통해서 토큰의 개수가 변했음을 모델에 알리고 모델의 임베딩 레이어를 조정하여 새로운 토큰을 수용할 수 있게 함\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train content 토큰화\n",
    "tokenized_train_sentences = tokenizer(\n",
    "    list(train_data['content']),\n",
    "    return_tensors=\"pt\",\n",
    "    max_length=128,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    add_special_tokens=True\n",
    ")\n",
    "\n",
    "# test content 토큰화\n",
    "tokenized_test_sentences = tokenizer(\n",
    "    list(test_data['content']),\n",
    "    return_tensors=\"pt\",\n",
    "    max_length=128,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    add_special_tokens=True\n",
    ")\n",
    "\n",
    "# 분류 모델에 넣기 위해서 1차원으로 구성된 세 개의 클래스를 2차원으로 재구성 후 label 로 투입\n",
    "# -1(부정)=0, 0(중립)=1, 1(긍정)=2\n",
    "\n",
    "train_label = []\n",
    "for label in train_data[\"story\"].values:\n",
    "    if label == -1:\n",
    "        train_label.append([1., 0., 0.])\n",
    "    elif label == 0:\n",
    "        train_label.append([0., 1., 0.])\n",
    "    elif label == 1:\n",
    "        train_label.append([0., 0., 1.])\n",
    "\n",
    "test_label = []\n",
    "for label in test_data['story'].values:\n",
    "    if label == 0:\n",
    "        test_label.append([0., 1., 0.])\n",
    "    elif label == -1:\n",
    "        test_label.append([1., 0., 0.])\n",
    "    elif label == 1:\n",
    "        test_label.append([0., 0., 1.])\n",
    "\n",
    "# model 에 넣기 위한 dataset 생성 class\n",
    "class CurseDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "        \n",
    "# bert 모델에 데이터가 들어갈 수 있게 만들어 둔 class를 활용하여 train, test dataset 생성\n",
    "train_dataset = CurseDataset(tokenized_train_sentences, train_label)\n",
    "test_dataset = CurseDataset(tokenized_test_sentences, test_label)\n",
    "\n",
    "# hugging face 의 trasformers 라이브러리를 사용하여 모델 훈련시킬 때 사용되는 객체 설정 부분\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = './story_model/check_point/try_5',    # 모델과 훈련 중 생성되는 파일이 저장될 디렉토리 경로\n",
    "    num_train_epochs = 30,              # 훈련 epoch 수\n",
    "    per_device_train_batch_size = 16,    # 장치에 할당된 훈련 배치 크기\n",
    "    per_device_eval_batch_size = 64,    # 장치에 할당된 평가 배치 크기, 모델을 평가할 때 사용되는 배치 크기\n",
    "    logging_dir = './logs',             # 훈련 중 로그 파일이 저장될 디렉토리\n",
    "    logging_steps = 500,                # 로그 출력 빈도, 500 step에 한 번씩 출력 예정\n",
    "    save_total_limit = 2,               # 체크포인트 파일 저장 제한 수\n",
    ")\n",
    "\n",
    "# hugging face 의 trasformers 라이브러리를 사용하여 모델 훈련하고 관리하는 객체 설정 부분\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7350 [00:00<?, ?it/s]/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_29129/2023398528.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "  7%|▋         | 500/7350 [01:28<20:04,  5.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2509, 'learning_rate': 4.6598639455782315e-05, 'epoch': 2.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_29129/2023398528.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 14%|█▎        | 1000/7350 [02:56<18:40,  5.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1291, 'learning_rate': 4.319727891156463e-05, 'epoch': 4.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_29129/2023398528.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 20%|██        | 1500/7350 [04:24<17:14,  5.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1251, 'learning_rate': 3.979591836734694e-05, 'epoch': 6.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_29129/2023398528.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 27%|██▋       | 2000/7350 [05:53<15:44,  5.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1216, 'learning_rate': 3.639455782312925e-05, 'epoch': 8.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_29129/2023398528.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 34%|███▍      | 2500/7350 [07:21<14:37,  5.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1045, 'learning_rate': 3.2993197278911564e-05, 'epoch': 10.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_29129/2023398528.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 41%|████      | 3000/7350 [08:50<12:45,  5.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0967, 'learning_rate': 2.959183673469388e-05, 'epoch': 12.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_29129/2023398528.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 48%|████▊     | 3500/7350 [10:19<11:28,  5.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.078, 'learning_rate': 2.6190476190476192e-05, 'epoch': 14.29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_29129/2023398528.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 54%|█████▍    | 4000/7350 [11:47<09:57,  5.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0711, 'learning_rate': 2.2789115646258505e-05, 'epoch': 16.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_29129/2023398528.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 61%|██████    | 4500/7350 [13:16<08:14,  5.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.063, 'learning_rate': 1.9387755102040817e-05, 'epoch': 18.37}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_29129/2023398528.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 68%|██████▊   | 5000/7350 [14:44<06:57,  5.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0539, 'learning_rate': 1.5986394557823133e-05, 'epoch': 20.41}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_29129/2023398528.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 75%|███████▍  | 5500/7350 [16:12<05:28,  5.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.045, 'learning_rate': 1.2585034013605443e-05, 'epoch': 22.45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_29129/2023398528.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 82%|████████▏ | 6000/7350 [17:39<03:54,  5.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0395, 'learning_rate': 9.183673469387756e-06, 'epoch': 24.49}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_29129/2023398528.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 88%|████████▊ | 6500/7350 [19:06<02:28,  5.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0349, 'learning_rate': 5.782312925170069e-06, 'epoch': 26.53}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_29129/2023398528.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 95%|█████████▌| 7000/7350 [20:33<01:00,  5.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0332, 'learning_rate': 2.3809523809523808e-06, 'epoch': 28.57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_29129/2023398528.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "100%|██████████| 7350/7350 [21:35<00:00,  5.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1295.2862, 'train_samples_per_second': 90.768, 'train_steps_per_second': 5.674, 'train_loss': 0.08618645207411578, 'epoch': 30.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=7350, training_loss=0.08618645207411578, metrics={'train_runtime': 1295.2862, 'train_samples_per_second': 90.768, 'train_steps_per_second': 5.674, 'train_loss': 0.08618645207411578, 'epoch': 30.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train 진행\n",
    "trainer.train() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./story_model/try_5/story_tokenizer5/tokenizer_config.json',\n",
       " './story_model/try_5/story_tokenizer5/special_tokens_map.json',\n",
       " './story_model/try_5/story_tokenizer5/vocab.txt',\n",
       " './story_model/try_5/story_tokenizer5/added_tokens.json')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.save_model(\"./story_model/try_5/story_model5\")\n",
    "tokenizer.save_pretrained(\"./story_model/try_5/story_tokenizer5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# 저장된 모델과 토크나이저를 불러오기\n",
    "\n",
    "model_path = \"./story_model/try_5/story_model5\"\n",
    "tokenizer_path = \"./story_model/try_5/story_tokenizer5\"\n",
    "\n",
    "model = ElectraForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer = ElectraTokenizer.from_pretrained(tokenizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 989/989 [00:10<00:00, 95.81it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>story</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>잘 열다</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>나 바보 이다</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>들어가다 커피 향 씨 낫다 좋다 하지만 인테리어 그냥 그렇다 풀 정도 되다</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>인 스토리 잘 감 안 잡히다</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>인 활동 있다 추락 조심</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>나 너무 어렵다 방탈짬바 있다 추천</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>인 각자 하다 뿌듯하다 테마</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>첫 디버프로 초반 절다 보다 못 보다 힌트 쓰다 잘 꾸미다 살짝 장치 오류 아쉽다</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>인 볼륨 압도 히터 방 빵빵하다 다른 테마 궁금</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>인 장치 그거 왜 모르다 장치 속다</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>989 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            content  story  pred\n",
       "0                                              잘 열다      0     0\n",
       "1                                           나 바보 이다      0     0\n",
       "2         들어가다 커피 향 씨 낫다 좋다 하지만 인테리어 그냥 그렇다 풀 정도 되다      0     0\n",
       "3                                   인 스토리 잘 감 안 잡히다     -1     1\n",
       "4                                     인 활동 있다 추락 조심      0     0\n",
       "...                                             ...    ...   ...\n",
       "999                             나 너무 어렵다 방탈짬바 있다 추천      0     0\n",
       "1000                                인 각자 하다 뿌듯하다 테마      0     0\n",
       "1001  첫 디버프로 초반 절다 보다 못 보다 힌트 쓰다 잘 꾸미다 살짝 장치 오류 아쉽다      0     0\n",
       "1002                     인 볼륨 압도 히터 방 빵빵하다 다른 테마 궁금      0     0\n",
       "1003                            인 장치 그거 왜 모르다 장치 속다      0     0\n",
       "\n",
       "[989 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문장을 입력했을 때, 예측 값을 도출해주는 함수\n",
    "\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "# 함수 정의\n",
    "def classify_text(text):\n",
    "    # 문장을 토큰화하고 모델에 입력으로 전달\n",
    "    text = cleaned_content(text)\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "    # 소프트맥스 함수를 사용하여 확률값 계산\n",
    "    probabilities = softmax(outputs.logits, dim=1)\n",
    "\n",
    "    # 가장 높은 확률값에 해당하는 클래스 선택\n",
    "    predicted_class = torch.argmax(probabilities).item()\n",
    "\n",
    "    return predicted_class, probabilities\n",
    "\n",
    "def change_num(num):\n",
    "    if num == 0:\n",
    "        return (-1)\n",
    "    elif num == 1:\n",
    "        return 0\n",
    "    elif num == 2:\n",
    "        return 1\n",
    "\n",
    "pred_list = []\n",
    "for sent in tqdm(test_data['content']):\n",
    "    pred, _ = classify_text(sent)\n",
    "    pred_list.append(pred)\n",
    "\n",
    "test_data['pred'] = pred_list\n",
    "test_data['pred'] = test_data['pred'].apply(change_num)\n",
    "test_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 라벨 수 story\n",
      " 0    4461\n",
      " 1     444\n",
      "-1     118\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "train_data 라벨 수 story\n",
      " 0    3462\n",
      " 1     362\n",
      "-1      95\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "test_data 라벨 수 story\n",
      " 0    893\n",
      " 1     78\n",
      "-1     18\n",
      "Name: count, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('전체 라벨 수', final_df['story'].value_counts(), '\\n')\n",
    "print('train_data 라벨 수', train_data['story'].value_counts(), '\\n')\n",
    "print('test_data 라벨 수', test_data['story'].value_counts(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0포함 예측률 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.82      0.50      0.62        18\n",
      "           0       1.00      0.99      0.99       893\n",
      "           1       0.82      0.96      0.89        78\n",
      "\n",
      "    accuracy                           0.98       989\n",
      "   macro avg       0.88      0.82      0.83       989\n",
      "weighted avg       0.98      0.98      0.98       989\n",
      "\n",
      "0제외 예측률 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      0.50      0.67        18\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.90      0.96      0.93        78\n",
      "\n",
      "    accuracy                           0.88        96\n",
      "   macro avg       0.63      0.49      0.53        96\n",
      "weighted avg       0.92      0.88      0.88        96\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/bert_electra/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/bert_electra/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/bert_electra/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('0포함 예측률', '\\n', classification_report(test_data['story'], test_data['pred']))\n",
    "test_data2 = test_data[test_data['story'] != 0]\n",
    "print('0제외 예측률', '\\n', classification_report(test_data2['story'], test_data2['pred']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장: 스토리 대박, 평가: 2\n",
      "----------\n",
      "문장: 스토리 좋아요, 평가: 2\n",
      "----------\n",
      "문장: 스토리 개좋음, 평가: 2\n",
      "----------\n",
      "문장: 서비스 무슨 일, 평가: 1\n",
      "----------\n",
      "문장: 이야기 재밌어요, 평가: 2\n",
      "----------\n",
      "문장: 불친절함, 평가: 1\n",
      "----------\n",
      "문장: 스토리 쓰레기네, 평가: 0\n",
      "----------\n",
      "문장: 서비스는 좋은데 재미없었어요., 평가: 1\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "test = [\n",
    "    '스토리 대박',\n",
    "    '스토리 좋아요',\n",
    "    '스토리 개좋음',\n",
    "    '서비스 무슨 일',\n",
    "    '이야기 재밌어요',\n",
    "    '불친절함',\n",
    "    '스토리 쓰레기네',\n",
    "    '서비스는 좋은데 재미없었어요.',\n",
    "]\n",
    "\n",
    "for sent in test:\n",
    "    pred, _ = classify_text(sent)\n",
    "    print(f'문장: {sent}, 평가: {pred}')\n",
    "    print(\"-\"*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6차 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_37889/4128575971.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  story_data['content_id'] = story_data['content_id'].apply(lambda x: x.split(',')[0] if len(str(x)) > 6 else x)\n",
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_37889/4128575971.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df['content'] = final_df['content'].apply(kiwi_clean)\n"
     ]
    }
   ],
   "source": [
    "# labeling 된 데이터 불러오기\n",
    "survey = pd.read_csv(\"./_data/survey.csv\", index_col=0)\n",
    "survey.fillna(0, inplace=True)\n",
    "survey = survey.reset_index()\n",
    "\n",
    "# 데이터 중에서 작업을 하고자 하는 라벨만 가져오기\n",
    "story_data = survey[['content_id', 'story']]\n",
    "\n",
    "# content_id 중에서 댓글이 같이 추가된 데이터 정리\n",
    "story_data['content_id'] = story_data['content_id'].apply(lambda x: x.split(',')[0] if len(str(x)) > 6 else x)\n",
    "\n",
    "# content_id 가 0인 데이터 제외 -> content_id 모두 int type 으로 변경 (추후 Merge 를 위함)\n",
    "story_data = story_data[story_data['content_id'] != 0].reset_index().drop(columns=['index'])\n",
    "story_data['content_id'] = story_data['content_id'].astype(int)\n",
    "\n",
    "# 전체 review data 불러오기\n",
    "review_all = pd.read_csv(\"./_data/reviews.csv\", index_col=0)\n",
    "\n",
    "# 전체 review data 중에서 survey data에 있는 댓글만 가져오기\n",
    "survey_content = review_all.loc[review_all['id'].isin(story_data['content_id'])][['id', 'content']]\n",
    "# merge 를 위해서 id 컬럼명 통일하기\n",
    "survey_content.columns=['content_id', 'content']\n",
    "\n",
    "# 통일된 content_id 를 기반으로 데이터 merge\n",
    "story_data = pd.merge(story_data, survey_content)\n",
    "\n",
    "# 추후 원활한 계산을 위해서 숫자 부분은 모두 int 로 바꿔줌\n",
    "story_data['story'] = story_data['story'].astype(int)\n",
    "\n",
    "# 최소한의 전처리\n",
    "def cleaned_content(text):\n",
    "    d = re.sub('\\n', '. ', text) # 줄바꿈 > .\n",
    "    d = re.sub('[^가-힣0-9a-zA-Z ]{2,}', \".\", d) # 특수문자 두개 이상인거 .으로 변경\n",
    "    return d\n",
    "\n",
    "story_data['content'] = story_data['content'].apply(cleaned_content)\n",
    "\n",
    "final_df = story_data[['content', 'story']]\n",
    "\n",
    "from kiwipiepy import Kiwi\n",
    "kiwi = Kiwi()\n",
    "\n",
    "def kiwi_clean(text):\n",
    "    kiwi_lem = []\n",
    "    for word in kiwi.tokenize(text):\n",
    "        kiwi_lem.append(word.lemma)\n",
    "    return ' '.join(kiwi_lem)\n",
    "\n",
    "final_df['content'] = final_df['content'].apply(kiwi_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "story\n",
      " 0    4461\n",
      " 1     444\n",
      "-1     118\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "train_data story\n",
      " 0    3560\n",
      " 1     363\n",
      "-1      95\n",
      "Name: count, dtype: int64\n",
      "\n",
      " test_data story\n",
      " 0    909\n",
      " 1     78\n",
      "-1     18\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "중복 제거 전 학습 데이터셋: 4018\n",
      "중복 제거 전 테스트 데이터셋: 1005\n",
      "\n",
      "\n",
      "중복 제거 후 학습 데이터셋: 4003\n",
      "중복 제거 후 테스트 데이터셋: 1001\n"
     ]
    }
   ],
   "source": [
    "# 라벨별 개수 확인\n",
    "print(final_df['story'].value_counts())\n",
    "print('\\n')\n",
    "train_data = final_df.sample(frac=0.8, random_state=42).reset_index().drop(columns='index')\n",
    "print('train_data', train_data['story'].value_counts())\n",
    "test_data = final_df.drop(train_data.index).reset_index().drop(columns='index')\n",
    "print('\\n', 'test_data', test_data['story'].value_counts())\n",
    "print('\\n')\n",
    "# 중복 데이터 제거(데이터 분리 후 중복이 생길 수 있어서 데이터 분리 후 중복 데이터 처리 진행)\n",
    "\n",
    "# 데이터셋 개수 확인\n",
    "print('중복 제거 전 학습 데이터셋: {}'.format(len(train_data)))\n",
    "print('중복 제거 전 테스트 데이터셋: {}'.format(len(test_data)))\n",
    "print('\\n')\n",
    "# 중복 데이터 제거\n",
    "train_data.drop_duplicates(subset=['content'], inplace=True)\n",
    "test_data.drop_duplicates(subset=['content'], inplace=True)\n",
    "# 데이터셋 개수 확인\n",
    "print('중복 제거 후 학습 데이터셋: {}'.format(len(train_data)))\n",
    "print('중복 제거 후 테스트 데이터셋: {}'.format(len(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-small-v3-discriminator and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(35080, 128)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 토큰에 추가할 단어 -> '방탈출'이라는 도메인 지시기에 근거한 용어, 분리되어서는 안 되기 때문에 별도로 추가 작업 진행\n",
    "addword = ['공테', '약공테', '감테', '창공', '갑툭튀', '삐딱', '삑', '꽝', '삑딱쾅', '삑딱쾅', '삑딱', '쫄', '극쫄',\n",
    "            '극극쫄', '쫄팟', '쫄탱', '쫄보', '극', '약탱', '탱쫄', '극극극', '뉴비', '하드캐리', '극혐', '피지컬',\n",
    "            '어거지', '뚝배기', '뚝문', '셀뚝', '억까', '트롤링', '트롤짓', '흙길', '풀길', '꽃길', '풀꽃', '꽃다발',\n",
    "            '꽃밭', '웰메이드', '인생테마', '머글', '방린이', '방유아', '방세포', '방태아', '방탈러', '과몰입러', '옵저버',\n",
    "            '리트', '연방', '혼방', '혼불', '워킹', '워크인', '장치방', '문제방', '직렬', '병렬', '육각형', '볼드', '볼드충', '에바',\n",
    "            '가이드', '조도', '조명', '밝기', '어두움', '인테리어', '비주얼', '소품', '디자인',\n",
    "            '스토리','기승전결','흐름도','결말','서사','이야기','유니버스','전개','시나리오', '개연성', '명료',\n",
    "            '창의성','창의','신선','독특','참신','발상', '연출','짜임','사실감','구현','현실감','현장감', '활동성','활동력','활동량','움직임','반경',\n",
    "            '규모','스케일','볼륨','사이즈','크기','넓이','공간감','분량', '공포','공테','무서움','담력','스릴러',\n",
    "            '문제', '장치', '기계', '센서', '기구', '불친절',\n",
    "            '메르헨', '커튼콜', '카르텔', '소우주', '풀문', '도고', '플래시', '나우히어', '나비효과', '몽중', '가이드라인',\n",
    "            '연출력', '짜임새', '공포도', '공포감', '공포심', '약공테', '문제퀄']\n",
    "\n",
    "# 사전학습된 bert 모델 사용\n",
    "# num_labels 클래스에 대해서 훈련을 하기 위해서 num_labels=3 할당함, problem_type=\"multi_label_classification\" 를 통해서 모델이 다중 레이블 분류에 해당함을 명시\n",
    "model = ElectraForSequenceClassification.from_pretrained(\"monologg/koelectra-small-v3-discriminator\", num_labels=3, problem_type=\"multi_label_classification\")\n",
    "tokenizer = ElectraTokenizer.from_pretrained(\"monologg/koelectra-base-v3-discriminator\")\n",
    "\n",
    "# token에 새로운 단어 추가 \n",
    "tokenizer.add_tokens(addword)\n",
    "# token에 단어 추가후 기존 모델의 임베딩 레이어에 추가한 단어에 대한 임베딩 벡터가 없을 수 있기 때문\n",
    "# 아래 코드를 통해서 토큰의 개수가 변했음을 모델에 알리고 모델의 임베딩 레이어를 조정하여 새로운 토큰을 수용할 수 있게 함\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train content 토큰화\n",
    "tokenized_train_sentences = tokenizer(\n",
    "    list(train_data['content']),\n",
    "    return_tensors=\"pt\",\n",
    "    max_length=128,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    add_special_tokens=True\n",
    ")\n",
    "\n",
    "# test content 토큰화\n",
    "tokenized_test_sentences = tokenizer(\n",
    "    list(test_data['content']),\n",
    "    return_tensors=\"pt\",\n",
    "    max_length=128,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    add_special_tokens=True\n",
    ")\n",
    "\n",
    "# 분류 모델에 넣기 위해서 1차원으로 구성된 세 개의 클래스를 2차원으로 재구성 후 label 로 투입\n",
    "# -1(부정)=0, 0(중립)=1, 1(긍정)=2\n",
    "\n",
    "train_label = []\n",
    "for label in train_data[\"story\"].values:\n",
    "    if label == -1:\n",
    "        train_label.append([1., 0., 0.])\n",
    "    elif label == 0:\n",
    "        train_label.append([0., 1., 0.])\n",
    "    elif label == 1:\n",
    "        train_label.append([0., 0., 1.])\n",
    "\n",
    "test_label = []\n",
    "for label in test_data['story'].values:\n",
    "    if label == 0:\n",
    "        test_label.append([0., 1., 0.])\n",
    "    elif label == -1:\n",
    "        test_label.append([1., 0., 0.])\n",
    "    elif label == 1:\n",
    "        test_label.append([0., 0., 1.])\n",
    "\n",
    "# model 에 넣기 위한 dataset 생성 class\n",
    "class CurseDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "        \n",
    "# bert 모델에 데이터가 들어갈 수 있게 만들어 둔 class를 활용하여 train, test dataset 생성\n",
    "train_dataset = CurseDataset(tokenized_train_sentences, train_label)\n",
    "test_dataset = CurseDataset(tokenized_test_sentences, test_label)\n",
    "\n",
    "# hugging face 의 trasformers 라이브러리를 사용하여 모델 훈련시킬 때 사용되는 객체 설정 부분\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = './story_model/check_point/try_6',    # 모델과 훈련 중 생성되는 파일이 저장될 디렉토리 경로\n",
    "    num_train_epochs = 30,              # 훈련 epoch 수\n",
    "    per_device_train_batch_size = 16,    # 장치에 할당된 훈련 배치 크기\n",
    "    per_device_eval_batch_size = 64,    # 장치에 할당된 평가 배치 크기, 모델을 평가할 때 사용되는 배치 크기\n",
    "    logging_dir = './logs',             # 훈련 중 로그 파일이 저장될 디렉토리\n",
    "    logging_steps = 500,                # 로그 출력 빈도, 500 step에 한 번씩 출력 예정\n",
    "    save_total_limit = 2,               # 체크포인트 파일 저장 제한 수\n",
    ")\n",
    "\n",
    "# hugging face 의 trasformers 라이브러리를 사용하여 모델 훈련하고 관리하는 객체 설정 부분\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7530 [00:00<?, ?it/s]/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_36251/3530546526.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "  7%|▋         | 500/7530 [01:29<20:29,  5.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2689, 'learning_rate': 4.6679946879150064e-05, 'epoch': 1.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_36251/3530546526.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 13%|█▎        | 1000/7530 [02:59<19:26,  5.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.125, 'learning_rate': 4.335989375830013e-05, 'epoch': 3.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_36251/3530546526.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 20%|█▉        | 1500/7530 [04:31<18:00,  5.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1258, 'learning_rate': 4.00398406374502e-05, 'epoch': 5.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_36251/3530546526.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 27%|██▋       | 2000/7530 [06:01<16:50,  5.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1226, 'learning_rate': 3.671978751660027e-05, 'epoch': 7.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_36251/3530546526.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 33%|███▎      | 2500/7530 [07:31<14:52,  5.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1255, 'learning_rate': 3.339973439575033e-05, 'epoch': 9.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_36251/3530546526.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 40%|███▉      | 3000/7530 [09:00<13:17,  5.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1165, 'learning_rate': 3.00796812749004e-05, 'epoch': 11.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_36251/3530546526.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 46%|████▋     | 3500/7530 [10:29<11:49,  5.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1011, 'learning_rate': 2.6759628154050465e-05, 'epoch': 13.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_36251/3530546526.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 53%|█████▎    | 4000/7530 [11:58<10:25,  5.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0937, 'learning_rate': 2.3439575033200534e-05, 'epoch': 15.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_36251/3530546526.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 60%|█████▉    | 4500/7530 [13:29<09:09,  5.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0864, 'learning_rate': 2.01195219123506e-05, 'epoch': 17.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_36251/3530546526.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 66%|██████▋   | 5000/7530 [15:01<07:24,  5.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.087, 'learning_rate': 1.6799468791500664e-05, 'epoch': 19.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_36251/3530546526.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 73%|███████▎  | 5500/7530 [16:32<06:01,  5.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.081, 'learning_rate': 1.3479415670650731e-05, 'epoch': 21.91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_36251/3530546526.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 80%|███████▉  | 6000/7530 [18:03<04:30,  5.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0745, 'learning_rate': 1.0159362549800798e-05, 'epoch': 23.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_36251/3530546526.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 86%|████████▋ | 6500/7530 [19:34<03:02,  5.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0648, 'learning_rate': 6.839309428950863e-06, 'epoch': 25.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_36251/3530546526.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      " 93%|█████████▎| 7000/7530 [21:05<01:35,  5.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0622, 'learning_rate': 3.51925630810093e-06, 'epoch': 27.89}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_36251/3530546526.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "100%|█████████▉| 7500/7530 [22:35<00:05,  5.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0562, 'learning_rate': 1.99203187250996e-07, 'epoch': 29.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_36251/3530546526.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "100%|██████████| 7530/7530 [22:41<00:00,  5.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1361.6545, 'train_samples_per_second': 88.194, 'train_steps_per_second': 5.53, 'train_loss': 0.10596233155147963, 'epoch': 30.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=7530, training_loss=0.10596233155147963, metrics={'train_runtime': 1361.6545, 'train_samples_per_second': 88.194, 'train_steps_per_second': 5.53, 'train_loss': 0.10596233155147963, 'epoch': 30.0})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train 진행\n",
    "trainer.train() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./story_model/try_6/story_tokenizer6/tokenizer_config.json',\n",
       " './story_model/try_6/story_tokenizer6/special_tokens_map.json',\n",
       " './story_model/try_6/story_tokenizer6/vocab.txt',\n",
       " './story_model/try_6/story_tokenizer6/added_tokens.json')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.save_model(\"./story_model/try_6/story_model6\")\n",
    "tokenizer.save_pretrained(\"./story_model/try_6/story_tokenizer6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# 저장된 모델과 토크나이저를 불러오기\n",
    "\n",
    "model_path = \"./story_model/try_6/story_model6\"\n",
    "tokenizer_path = \"./story_model/try_6/story_tokenizer6\"\n",
    "\n",
    "model = ElectraForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer = ElectraTokenizer.from_pretrained(tokenizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1001/1001 [00:11<00:00, 84.40it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>story</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#1415_20221128_3인 . 흐음 . 잘 열다 어 보다 지 않다 으면</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>나 ᆫ . 바보 이다 야 .</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>들어가다 자마자 커피 향 이 씨 것 이 낫다 다 좋다 앗 다 하지만 인테리어 는 그...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3 인 . 스토리 가 잘 감 이 안 잡히다 ᆫ다 !</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.5 / 3 인 . 활동 성 있다 음 . 추락 조심</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>나 에게 ᆫ 너무 어렵다 었 던 . 방탈짬바 있다 는 분 들 에게 추천</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>2021. 12. 26.  ( 3 인 ) 각자 1 인분 씩 하다 고 뿌듯하다 었 던...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>첫 방 디버프로 초반 에 절다 어 버리다 ᆷ . 보다 ᆯ 것 도 못 보다 고 힌트 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>#5 - 2 인 - 볼륨 에 압도 되 ᆷ - 히터 도 방 마다 빵빵하다 ᆷ - 다른...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>265 , 2 인 , 장치 . 그거 ᆯ 왜 모르다 었 냐 . 장치 에 속다 지 말다 자</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1001 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content  story  pred\n",
       "0            #1415_20221128_3인 . 흐음 . 잘 열다 어 보다 지 않다 으면      0     0\n",
       "1                                       나 ᆫ . 바보 이다 야 .      0     0\n",
       "2     들어가다 자마자 커피 향 이 씨 것 이 낫다 다 좋다 앗 다 하지만 인테리어 는 그...      0     0\n",
       "3                          3 인 . 스토리 가 잘 감 이 안 잡히다 ᆫ다 !     -1     1\n",
       "4                         1.5 / 3 인 . 활동 성 있다 음 . 추락 조심      0     0\n",
       "...                                                 ...    ...   ...\n",
       "999             나 에게 ᆫ 너무 어렵다 었 던 . 방탈짬바 있다 는 분 들 에게 추천      0     0\n",
       "1000  2021. 12. 26.  ( 3 인 ) 각자 1 인분 씩 하다 고 뿌듯하다 었 던...      0     0\n",
       "1001  첫 방 디버프로 초반 에 절다 어 버리다 ᆷ . 보다 ᆯ 것 도 못 보다 고 힌트 ...      0     0\n",
       "1002  #5 - 2 인 - 볼륨 에 압도 되 ᆷ - 히터 도 방 마다 빵빵하다 ᆷ - 다른...      0     0\n",
       "1003   265 , 2 인 , 장치 . 그거 ᆯ 왜 모르다 었 냐 . 장치 에 속다 지 말다 자      0     0\n",
       "\n",
       "[1001 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문장을 입력했을 때, 예측 값을 도출해주는 함수\n",
    "\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "# 함수 정의\n",
    "def classify_text(text):\n",
    "    # 문장을 토큰화하고 모델에 입력으로 전달\n",
    "    text = cleaned_content(text)\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "    # 소프트맥스 함수를 사용하여 확률값 계산\n",
    "    probabilities = softmax(outputs.logits, dim=1)\n",
    "\n",
    "    # 가장 높은 확률값에 해당하는 클래스 선택\n",
    "    predicted_class = torch.argmax(probabilities).item()\n",
    "\n",
    "    return predicted_class, probabilities\n",
    "\n",
    "def change_num(num):\n",
    "    if num == 0:\n",
    "        return (-1)\n",
    "    elif num == 1:\n",
    "        return 0\n",
    "    elif num == 2:\n",
    "        return 1\n",
    "\n",
    "pred_list = []\n",
    "for sent in tqdm(test_data['content']):\n",
    "    pred, _ = classify_text(sent)\n",
    "    pred_list.append(pred)\n",
    "\n",
    "test_data['pred'] = pred_list\n",
    "test_data['pred'] = test_data['pred'].apply(change_num)\n",
    "test_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 라벨 수 story\n",
      " 0    4461\n",
      " 1     444\n",
      "-1     118\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "train_data 라벨 수 story\n",
      " 0    3545\n",
      " 1     363\n",
      "-1      95\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "test_data 라벨 수 story\n",
      " 0    905\n",
      " 1     78\n",
      "-1     18\n",
      "Name: count, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('전체 라벨 수', final_df['story'].value_counts(), '\\n')\n",
    "print('train_data 라벨 수', train_data['story'].value_counts(), '\\n')\n",
    "print('test_data 라벨 수', test_data['story'].value_counts(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0포함 예측률 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      0.22      0.36        18\n",
      "           0       0.99      0.99      0.99       905\n",
      "           1       0.79      0.97      0.87        78\n",
      "\n",
      "    accuracy                           0.98      1001\n",
      "   macro avg       0.93      0.73      0.74      1001\n",
      "weighted avg       0.98      0.98      0.97      1001\n",
      "\n",
      "0제외 예측률 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      0.22      0.36        18\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.87      0.97      0.92        78\n",
      "\n",
      "    accuracy                           0.83        96\n",
      "   macro avg       0.62      0.40      0.43        96\n",
      "weighted avg       0.90      0.83      0.82        96\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/bert_electra/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/bert_electra/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/bert_electra/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('0포함 예측률', '\\n', classification_report(test_data['story'], test_data['pred']))\n",
    "test_data2 = test_data[test_data['story'] != 0]\n",
    "print('0제외 예측률', '\\n', classification_report(test_data2['story'], test_data2['pred']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장: 스토리 대박, 평가: 2\n",
      "----------\n",
      "문장: 스토리 좋아요, 평가: 2\n",
      "----------\n",
      "문장: 스토리 개좋음, 평가: 2\n",
      "----------\n",
      "문장: 서비스 무슨 일, 평가: 1\n",
      "----------\n",
      "문장: 이야기 재밌어요, 평가: 2\n",
      "----------\n",
      "문장: 불친절함, 평가: 1\n",
      "----------\n",
      "문장: 스토리 쓰레기네, 평가: 2\n",
      "----------\n",
      "문장: 서비스는 좋은데 재미없었어요., 평가: 1\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "test = [\n",
    "    '스토리 대박',\n",
    "    '스토리 좋아요',\n",
    "    '스토리 개좋음',\n",
    "    '서비스 무슨 일',\n",
    "    '이야기 재밌어요',\n",
    "    '불친절함',\n",
    "    '스토리 쓰레기네',\n",
    "    '서비스는 좋은데 재미없었어요.',\n",
    "]\n",
    "\n",
    "for sent in test:\n",
    "    pred, _ = classify_text(sent)\n",
    "    print(f'문장: {sent}, 평가: {pred}')\n",
    "    print(\"-\"*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bert_electra",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
